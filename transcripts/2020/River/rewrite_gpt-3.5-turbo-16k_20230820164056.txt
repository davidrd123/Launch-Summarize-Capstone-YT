Welcome everyone! Thank you for joining us today for the presentation of River. My name is Katrina, and I'm here with my teammate Mark. Today, we'll be introducing River, a drop-in real-time service for web applications. River is cloud-native, easy to deploy, and ready to scale according to your needs. Throughout the development of this project, we had a great time, and we hope to share our enthusiasm with you today.

Before we dive in, let's quickly touch on the concept of being cloud-native. Cloud-native means that River was specifically designed and built with cloud services in mind. Cloud computing has many associated buzzwords and intriguing ideas, some of which we will explore further during this presentation.

Now, let's discuss who would benefit from using River, as well as how it can be utilized. River is targeted at application developers and is meant to be used alongside existing applications. It allows developers to easily publish events from their backend APIs, making these events available to web clients in real-time. 

To give you an overview of what to expect from this presentation, let's briefly outline the topics we'll cover. We will start by clarifying the concept of real-time in the context of web applications and discuss the specific use cases we had in mind when designing River. Next, we'll explore why a separate real-time service may be beneficial, followed by a practical example of adding real-time functionality to an existing app. We will then examine existing solutions before diving into the details of how River was built and the automation of its deployment. Lastly, we will provide information on how you can incorporate River into your own projects.

When discussing a real-time service, the first question we need to address is: what is real-time? Real-time encompasses a broad spectrum, and for the purposes of web applications, we'll focus on the fast exchange of messages. When a change occurs within our system, other parts of the system should be immediately notified. However, the definition of "immediately" can vary depending on the context. While some systems require microsecond-level latency and consider a missed deadline a failure, web applications typically don't have such stringent requirements. In the world of web apps, latency tolerance differs based on the application's sensitivity to delays. For example, gaming or financial stock trading apps require low latency, but collaborative apps like Google Docs or Slack can tolerate higher latency without detrimental consequences. River was built with these collaborative applications in mind.

Now, let's consider the options for message exchange within the context of real-time communication. It is important to note that the connection always starts with a normal HTTP request from the client. The first option is XHR polling, wherein the client periodically sends a request to check for new data. Another option is Server-Sent Events (SSE), which involves a one-way server-to-client streaming of text-based data. Finally, WebSockets enable bi-directional message-oriented streaming of both text and binary data between client and server. We selected WebSockets because we required a bi-directional communication channel.

Now let's discuss the advantages of using WebSockets over HTTP in terms of metadata overhead. With WebSockets, the metadata overhead per message sent ranges from 2 to 14 bytes, compared to 5 bytes with Server-Sent Events and 500 to 800 bytes with HTTP for each request and response. The significant reduction in metadata overhead greatly improves performance and user experience.

To summarize, over the past few decades, we have witnessed the transition from static web pages to dynamic and interactive web applications. However, HTTP, the protocol originally designed for the web, is not optimal for real-time communication due to its simplicity and excessive metadata overhead. To enhance performance and user experience, we need a new mode of communication where the server can send data to the client without the client first requesting it. WebSockets offer a viable solution, but they come with challenges such as compatibility and scale. Adding real-time functionality to an existing discussion forum application can be achieved by implementing a websocket connection between the client and the server. This websocket connection enables the server to send updates to the client in real-time, eliminating the need for the client to manually refresh their browser. 

In the existing discussion forum application, when a client wants to add a new message, they send an HTTP POST request to the server. The server validates the request, saves it to the database, and sends back a response with a new webpage containing the client's post. This process works as expected for a single client.

However, when a second client makes a post, the first client is not aware of it unless they refresh their browser. This lack of real-time communication between the server and the first client can be resolved by establishing an open channel of communication through a websocket connection.

By opening this websocket connection, the server can send updates to the first client whenever there is a new message, without requiring the client to refresh their browser. The updates are sent as websocket messages over the open connection, ensuring that the first client stays up-to-date with the latest messages.

The process of adding real-time functionality involves two steps. First, the client needs to open a websocket connection with a separate real-time service, which we'll call River. This connection allows the client to receive updates in real-time without needing to refresh their browser. Second, the client needs to specify which messages they want to receive updates for. This ensures that the client only receives updates relevant to the discussion forum they are currently viewing.

To accomplish this, the client subscribes to a specific channel, in this case, the channel for the "dogs" discussion forum. By subscribing to the "dogs" channel, the client will only receive updates for new posts in the "dogs" forum and not for any other forums.

When the client makes a new post in the usual way, via an HTTP POST request to the server, the server saves the post to its database. However, to notify River of this new post in the "dogs" forum, the server publishes an event to the "dogs" channel. This publication of the event can be thought of as an alert that is sent to all subscribed clients, including the first client, who will receive the update of the new post without needing to refresh their browser.

River acts as a separate real-time service that allows for the addition of real-time functionality to the existing discussion forum. It does not modify the existing HTTP communication paths of the application. Rather, it provides a publish-subscribe model where the application publishes events to River, and clients open persistent websocket connections to subscribe to and receive events from River.

River is agnostic to the specific clients that are subscribing and the back-end services that are publishing. Its main function is to accept publish events on specific channels and broadcast those events to the subscribed clients. It simplifies the implementation of real-time functionality by handling the communication between the clients and the back-end services.

River can be integrated into an existing application by establishing a websocket connection with it and specifying which channels or discussions the client wants to receive updates for. By following this browser-facing publish-subscribe model, the application can add real-time functionality without extensively modifying its existing infrastructure.

While River provides a straightforward solution for adding real-time functionality to an application, there are also existing solutions in this problem space. These solutions can be categorized into two main categories: open-source libraries and commercial services.

Open-source libraries, such as Centrifugal, provide scalable real-time messaging servers that run as separate services. These libraries offer a similar functionality as River, but they require more configuration and deployment complexity. They are often highly customizable but may require additional effort to scale.

On the other hand, there are commercial services, such as Pusher, which offer easy-to-use real-time APIs with strong guarantees on reliability. These services provide user-friendly interfaces and libraries for multiple programming languages. However, they come at a cost, especially for high-traffic applications, where the free plans may be limited, and higher subscription tiers can be expensive.

Considering these options, we decided to build River as a simplified open-source alternative to services like Pusher. Our main goals were to make it easy to deploy and ready to scale. To achieve this, we made trade-offs in terms of feature set and options. River focuses on the core functionality of publish-subscribe and doesn't offer many additional features beyond that. 

We also took inspiration from a non-open source solution, namely "Bobby" used by the sports streaming company The Zone. This solution showcased a similar use case to ours, with the need to publish updates to millions of users and handle high traffic on a global scale. It demonstrated the viability of the browser-facing publish-subscribe model we aimed to implement with River.

In terms of infrastructure, River is built as a Node.js process running a WebSocket server. Initially, we deployed River within an EC2 instance, which is an Amazon Web Services (AWS) virtual private server. This configuration allowed River to function as a single process on a single machine, providing the necessary functionality.

To make River resilient and ready to scale, we added an additional EC2 instance. This setup allowed us to have multiple instances of the River server running concurrently. This redundancy ensures that if one server goes down, another server is available to serve clients while the first server recovers. Additionally, having multiple instances enables horizontal scaling to handle increased traffic.

However, introducing a second EC2 instance posed a challenge: how to handle communication between the nodes. We solved this problem by incorporating Amazon's Elasticache for Redis service. Redis, typically known as a key-value cache, also offers a powerful built-in publish-subscribe mechanism. In River's case, the nodes, or EC2 instances, act as both publishers and subscribers, communicating with each other through Redis.

To handle client traffic and provide a single entry point for clients and services, we introduced an Application Load Balancer. This load balancer distributes traffic between the EC2 instances running River and provides a unified point of access. It ensures that clients are connected to available instances and that the load is balanced across them.

While River had separate entry points for WebSocket connections and HTTP publish requests, we recognized the need for a separation of concerns. Mixing WebSocket and HTTP within the Node.js processes was not ideal. To address this, we added a backchannel for publishing events via HTTP. This backchannel involved using the API Gateway service, which provides a public URL. When a publish event is received via an HTTP POST request, a lambda function validates the request and sends the event to Redis, which in turn publishes it to the subscribed nodes and, subsequently, the connected clients.

By employing these design and architectural choices, we have created a robust system that is easy to deploy, ready to scale, and keeps concerns separated. River makes use of Amazon Web Services, leverages Redis for publish-subscribe functionality, and uses an application load balancer for traffic distribution. The final design of River allows for seamless integration into existing applications, adding real-time functionality without a significant impact on the application's infrastructure.

As for authentication and security within River, the transcript does not provide specific details on the implementation, but it does mention that this problem will be addressed further in the presentation. We made significant improvements to our system during the Capstone project. Initially, we had one EC2 instance to handle the traffic, but we soon realized that we needed to scale horizontally to accommodate more users. However, this introduced a problem - how would the EC2 instances communicate with each other?

To solve this issue, we added Amazon's Elasticache for Redis service. Redis is commonly used as a key-value cache, but in our case, we utilized its powerful built-in publish-subscribe mechanism. The EC2 instances became the publishers and subscribers, allowing them to communicate through Redis. It's important to note that this is an internal, backend service and not the same pattern as the browser-facing publish-subscribe service.

While this solved one problem, we encountered another challenge. We didn't want clients to have to access different URLs to use our system. To address this, we added an application load balancer as a subservice of AWS's Elastic Load Balancing service. This load balancer distributes traffic between our EC2 instances and provides a single entry point for clients and services.

Despite these improvements, we realized that our node processes were handling both WebSocket connections and HTTP requests for publishing events. Mixing these two protocols was not ideal. We needed to separate the concerns. Since Redis was acting as our publish-subscribe mechanism, we explored the possibility of publishing events directly to Redis.

To achieve this separation, we added a back channel for publishing events via HTTP. Now, our system has two entry points - one for WebSocket connections and one for HTTP-based event publishing. WebSocket connections are completely decoupled from HTTP publish requests. When an event is published via an HTTP POST request, the API Gateway service validates the request, sends a publish event to Redis, and then Redis publishes the event to the subscribers, finally reaching the connected clients.

We were pleased with the robustness of our system at this point, but we still had concerns regarding ease of use and deployment. Managing EC2 instances required ongoing updates, security patches, and server maintenance. We wanted to abstract all of this complexity away to provide a user-friendly experience for River's users. To accomplish this, we containerized our Node.js process and migrated to Amazon's Elastic Container Service (ECS).

In the final version of our infrastructure, we replaced the EC2 instances with ECS. We containerized our WebSocket server using Docker, allowing us to focus solely on the business logic of River without worrying about server maintenance. We no longer needed to concern ourselves with node version conflicts or managing logs. We could easily deploy our Docker container with all dependencies handled by ECS.

ECS offers two launch types: EC2 launch type and Fargate launch type. We chose the Fargate launch type, which AWS describes as "serverless compute for containers". Additionally, we moved our internal infrastructure inside a Virtual Private Cloud (VPC). This provided us with a logically isolated environment within the AWS cloud, giving us complete control over the virtual network.

The EC2 launch type requires manual provisioning, scaling, and server management - the exact issues we were trying to avoid. However, with the Fargate launch type, all of the server infrastructure management is abstracted away. We only need to define our tasks and services, letting Fargate handle everything else. This decision allowed us to achieve our goal of making River both easy to deploy and easy to use.

Now I will pass the discussion to Catherine to talk about our automated deployment process and the challenges we faced.

During the development of River, we encountered significant challenges. However, our ultimate goal was not just to build River for ourselves but also to automate the deployment process so that others can easily use it. This is where the concept of being "cloud native" comes into play.

Becoming cloud native involves utilizing containers, container orchestration, and serverless functions - all of which are key advantages. These technologies allow us to build resilient and easily manageable systems. When combined with automation, engineers can make high-impact changes more easily. Declarative code, which describes the desired outcome rather than the specific instructions on how to achieve it, is another key element of cloud native systems.

In the context of AWS, there are different ways to interact with the cloud, ranging from manual to fully automated approaches. The AWS Management Console serves as a good entry point but lacks automation capabilities. Software Development Kits (SDKs) provide the ability to write scripts, but managing resources in a specific order and ensuring their interaction can be complex.

To address these challenges, "blueprints" - such as AWS CloudFormation templates - emerged. These templates allow you to describe the desired resources and their configurations, making deployments consistent and repeatable. However, they can be verbose and not very user-friendly, often requiring lines of code for default settings.

An interesting alternative we discovered was the AWS Cloud Development Kit (CDK). With the CDK, you can write code in familiar languages like JavaScript or Python to model your infrastructure using object-oriented code. The CDK generates CloudFormation templates with sensible defaults, making it easy to customize and share infrastructure components. This approach simplifies the deployment and teardown of the entire infrastructure. However, since the CDK is relatively new, resources and examples are limited, requiring more effort for specific configurations.

For our deployment process, we found the CDK to be a clear winner. With just a single command, "cdk deploy", after cloning the repository, all resources are created on your AWS account. This process may take some time but only needs to be done once. The ability to roll back changes with a single command makes it easy to test River's compatibility with your needs.

Additionally, we provide libraries that offer a clean and straightforward interface for interacting with River. On the server side, integrating River into an existing Express app is as simple as including the River library module. Initializing it with the API Gateway endpoint and a key allows easy publishing of messages.

On the client side, including River as a module enables you to provide the Load Balancer endpoint and a valid JSON Web Token. You can subscribe to specific channels and define how River should react to specific events using event names and callbacks.

With just a few lines of code, your existing application becomes a real-time application. Multiple users in different locations can collaborate seamlessly, with updates immediately reflected on all connected clients. There's no need for constant HTTP requests; River takes care of all the real-time communication.

Finally, let's touch upon authentication and load testing results. To ensure secure connections, we implemented JSON Web Tokens (JWT) for authentication. River generates a 256-bit secret key for signing JWTs. When a client connects, it requests a token from the application server, which verifies the client's identity using cookies. The server then generates a valid token signed with the River secret. This token allows the client to establish a secure connection with River.

Regarding load testing, we conducted extensive tests to ensure River's performance and scalability. We simulated high traffic with multiple clients and measured the system's response time and resource consumption. The results were extremely promising, demonstrating River's ability to handle significant loads without compromising performance.

In conclusion, River offers a robust and user-friendly solution for real-time communication within existing applications. Deploying River is as simple as running a single command, and its libraries provide an intuitive interface for interacting with the system. By leveraging cloud-native technologies and automation, River removes the complexity of infrastructure management. We hope that River becomes a valuable asset for developers looking to enhance their applications with real-time capabilities. In order to make it easier for you to test if River is a good fit for your needs, we have rolled back all the changes. As mentioned earlier, River is designed to be used alongside an existing application. So, in addition to deploying it, you also need to interact with it. This is where the outputs come in. We provide libraries with a clean and simple interface to facilitate interaction with River.

Here's an example Express app on the server side. You can simply include the River library as a module and initialize it with your own API gateway endpoint and a key. Whenever you want to publish a message, you just need to add one line of code. In this case, every time a post request is received for the "add task" path, that event will be published.

Similarly, on the client side, you can include River as a module. You provide your load balancer endpoint and a valid JSON Web Token. You can subscribe to any channel you want and instruct River on how it should react to specific events with an event name and a callback.

This is a very simple demo, but with just a few lines of code, your existing application becomes a real-time application. The example shows two different browser tabs representing two users who could be in different cities. When one user updates the state of the application, the UI gets immediately updated for both users without the need for an HTTP request.

Now, I will let Mark speak about authentication and our load testing results before we close the presentation.

Thank you, Catherine. Previously, we discussed the challenge of how River would know who is connecting to it and how to ensure that only certain clients can establish a connection. The solution lies in JSON Web Tokens. When River is deployed, a 256-bit secret key is generated to sign the tokens. These tokens enable River to be decoupled from the application server while still authenticating clients.

Let's look at an example of how these tokens might be generated and passed around in our triangular pattern. After River generates the secret, it is shared with the existing application. Before attempting to connect to River, the client requests a token from the application server. The server verifies the client's identity based on its cookies and generates a valid token signed with the River secret. The client then establishes a connection with River and sends the token as a WebSocket message. River verifies the token using the secret and notifies the client of successful authentication. River adds the client to its pool of authenticated clients, allowing it to subscribe to channels and receive messages.

It's important to note that River does not impose any specific requirements on token issuance or expiration. The responsibility for issuing and managing tokens lies with the application developer. All River expects is a valid JSON Web Token within the first 15 seconds of connection.

Now, let's discuss load testing. One of our primary goals for River was scalability. To determine if we achieved this goal, we conducted load tests to simulate real-world conditions for a small to medium web application. We set specific targets, including having thousands of stable concurrent open WebSocket connections, thousands of messages per second sent by the server, and the ability to handle 100 new connections per second.

To generate clients for testing, we utilized the artillery.io testing library, which has native support for Socket.IO, the underlying WebSocket engine for River. We set up two EC2 instances on AWS to run the artillery tests. We chose two instances instead of one to avoid CPU limitations that could skew the results. We split the load between the instances to mimic real-world scenarios.

To generate WebSocket messages, we utilized the concept of a presence channel. When a client subscribes to this channel, the server sends a message to all existing subscribers. As the number of subscribers grows, the number of messages sent per second increases exponentially.

So, how did River perform? We were able to support 20,000 concurrent connections without any errors. At the beginning of the test, River could add 100 new connections per second. However, as the presence channel messages peaked, the rate decreased to approximately 15 new connections per second. We estimate that during the peak of the presence channel messages, River was sending around 300,000 messages per second. It's crucial to note that these messages were lightweight, text-based, and consumed very little bandwidth.

While we did not meet our goal of steadily adding 100 users per second throughout the test, we believe that River successfully fulfilled our overall objective of being a real-time service for small to medium web applications.

We are continuously working on River and have some ideas for future improvements. Firstly, we aim to automate the process of enabling secure web sockets by adding an option during deployment to customize the application load balancer with encryption keys and a custom domain. Additionally, we plan to leverage Amazon Web Services' Cognito service for stronger security in terms of JSON Web Token authorization for the API gateway and Secrets Manager for a rotating and robust secret for our WebSocket server. Finally, we intend to implement a feature that allows dropped connections to seamlessly resume where they left off by accessing River's cache of recent messages.

Thank you all for joining us in this presentation on River. We will now open the floor to questions.

Q: Melissa - Can you provide details about the cost during testing and average expenses with AWS billing?
A: While it's challenging to anticipate costs precisely, we received our AWS bill at the end of last month, which included various costs related to development and setup. Since River is a robust infrastructure, there will always be a cost associated with it. However, we strive to keep River as cost-effective as possible, and the short-term costs are low. We appreciate the suggestion of providing clearer cost extrapolations to offer potential users a better understanding and comparison with other solutions.

Q: Derek - What unique challenges and benefits did you experience as a team of two compared to three?
A: Working as a team of two had both challenges and benefits. On the positive side, we found it easier to agree on decisions as there were only two opinions to consider. We had a great collaborative relationship and respected each other's ideas. On the downside, the workload was heavier as we had to handle all the tasks ourselves. At times, it would have been helpful to have a third team member to share the workload. Overall, though, it was a positive and enjoyable experience working together.

Q: Danielle - Catherine, you mentioned inner resistance to AWS. What were the reasons, and how were you convinced otherwise? Is it possible for River to work with different cloud services?
A: My initial resistance to using AWS stemmed from a reluctance to go with the mainstream player and a desire to explore more niche options. However, after thorough research and discussions with Mark, I realized that my extensive exploration was straying too far from our project's goals. Eventually, I embraced AWS and discovered its power and potential for individual developers. AWS offers a robust infrastructure that enables developers to build from their home offices. As for using River with different cloud services, it is indeed possible since River's WebSocket server inside a Docker container can be integrated with any cloud service. After contemplating the topic for a few intense months, I have numerous reflections that I plan to share soon. I came across Danielle's question on Slack, which asks Catherine about her inner resistance towards AWS and how she was convinced otherwise. Additionally, Danielle inquired about the process of working with different cloud services. I will address these two questions, starting with the origin of my inner resistance and then discussing working with alternative cloud services.

In terms of inner resistance, I must admit that it may not have been entirely justified. It took me quite a long time to be convinced about going with AWS. Part of this resistance may have been due to my inner adolescent, who resisted the idea of aligning with the mainstream player. We spent a significant amount of time exploring other options, and personally, I dedicated several weeks to exploring more unconventional ideas and researching various topics. However, I eventually realized that I was veering too far from my familiar mental model.

These fringe topics were fascinating, but as mentioned in Zlatan's comment, the Capstone project is about finding a balance between different factors. We need to achieve certain goals within a given timeframe, make sure it resonates well with our teammates, and consider its appeal in the job market. So, at some point, I recognized that my research was straying too far from these goals. Mark played a crucial role in convincing me to give AWS a try, and once I started using it, my initial resistance became irrelevant. AWS proved to be a powerful model, as also discussed on Slack. Furthermore, the resistance was not solely related to AWS but rather to cloud services in general. Suddenly, my resistance transformed into fascination, realizing the immense power it grants individual developers. It made us feel like we could build an empire from the comfort of our own small home office. Exploring AWS or any other cloud service is definitely worth considering, while keeping in mind the different goals you want to achieve with your project.

Having addressed the first question at length, Mark now moves on to the second question regarding the hypothetical possibility of working with a different cloud service. He mentions that there are several reusable components in our project, such as the websocket server running inside a docker container. So, any cloud service that supports docker can be directly used in our case, along with the libraries that interact with the docker container. However, when it comes to replicating our setup with a different cloud service, Mark admits his limited experience, having only worked with AWS. Setting up and automating the deployment of our AWS infrastructure was quite a laborious task. Therefore, Mark assumes that setting up something similar on an alternative cloud service would be equally challenging and time-consuming.

A question is raised in the chat by Ronnie, who commends their work and inquires about the decision to have a 15-second connection window and its security implications. Catherine responds, mentioning that they based their decision on existing industry standards. It became evident during their research that many existing solutions followed this practice. The 15-second connection window is not an arbitrary choice but an industry standard that allows clients to send their message containing the JSON Web Token (JWT). This similarity can be observed in different libraries that work with JWTs and websockets. It provides an opportunity for the client to authenticate itself within a limited timeframe. Catherine also acknowledges that the 15-second window does leave a vulnerability, allowing potential DDoS attacks within that timeframe. However, this trade-off had to be made, considering the practicality of the project and the need for authentication.

With no further questions, Catherine concludes the session by expressing her gratitude to everyone in attendance and acknowledging the other members of the Capstone cohort, specifically Team Maestro and Team Jade. She commends their impressive work and emphasizes the value of collaboration in projects like these. Catherine acknowledges the pleasure she had working with her talented teammates, particularly Mark. She thanks the host, Sir John, for facilitating the session and encourages anyone with questions or technical inquiries to reach out to them. While it is challenging to cover every aspect of the project in a presentation, they are more than happy to engage in discussions and address any queries that may arise.