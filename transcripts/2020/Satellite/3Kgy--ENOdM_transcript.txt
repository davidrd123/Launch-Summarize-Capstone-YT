welcome everyone thank you all for coming to our presentation we are satellite a graphql backend as a service satellite makes it easy for front-end developers to build applications in today's presentation first we'll talk about the architecture of a typical web app then we'll move on to the challenges of building a specific type of application and get into what a backend as a service is from there we'll move on to the architecture of a single satellite and after talk about how we allow for multiple satellites on one deployment last we'll walk you through a demo how to use satellite applications can be thought of as having two parts front end and a back end the front end is what the user sees and interacts with the back end handles the business logic and data to support the front end and all of its functionality in modern apps a common practice is to completely separate the front end from the back end apps that use this kind of architecture require some way for the front end and the back end to communicate this communication is done through something called an api the backend produces the api and the front-end consumes it this kind of architecture allows front-end and back-end teams to work independently and facilitates development of different front-end client apps using the same back end one recent innovation in api development occurred at facebook with a news feed api in 2011 facebook decided to completely rewrite their native ios app and immediately hit issues when trying to reuse the existing api for the news feed feature this was the first time they tried to develop an application like this where the backend was responsible for just returning data and the front end was responsible for all the user interactions and for facebook's news feed it isn't as simple as retrieving a story who wrote it what it says the list of comments and who's liked the post each story is interconnected nested and recursive the existing apis weren't designed to allow developers to expose a rich news feed like experience on mobile they didn't have a hierarchical nature or let developers select the exact data that they needed they were in fact designed to return html back to a web browser what this meant was that the client application would need to make several round trips to the api to get the info that it wanted for example i might have to first get one story and from that story figure out what other stories it needed to request to complete the feed and keep on repeating that process over and over until i got all the information that it needed not only did this result in a large amount of round trips but each response would contain a lot of data that wasn't needed both of these factors combined resulted in unacceptable network performance for the new app at this point it was clear to facebook that they needed to design a better api for the news feed feature to improve the mobile experience nick schrock one of the co-creators of this new api that we now know of as graphql said that their goal for building this new api was to design what they thought would be the ideal api for front-end developers and then work backwards to develop the underlying technology the key feature of this new api is that it allows front-end clients to specify exactly the information it needs for given requests eliminating the issues of over fetching and preventing the need for multiple round trips this networking performance improvement was critical for mobile apps which have limited bandwidth and require fast response times one other key feature of graphql that has led to its widespread adoption and multitude of client-side tools is that a graphql api uses a strongly typed system to describe its capabilities this allows clients to use a process called introspection to see exactly what they're able to do with the api making graphql effectively self-documenting graphql was initially developed by facebook to solve a very specific problem rebuilding their news feed api used as an internal tool by facebook from 2012 until 2015 it ended up spreading and covering most of their mobile app due to its strengths an open source version of graphql was released in 2015 soon after it was open sourced graphql began being used by many other companies like airbnb twitter netflix and github and has continued to grow in adoption ever since so what exactly is graphql at a very high level graphql is referred to as a query language for apis to be just a little more specific it's actually a specification that describes the type system and query language we'll get into these in more detail soon but for now all you need to know is that the specification can be implemented in any programming language it's not specific to any one particular application or architecture there are in fact server-side implementations of the graphql spec in just about any programming language you could want these server-side software implementations are known as graphql servers when a graphql server receives a request it comes in as a string sent from the client to the server over http the graphql server is responsible for parsing the request into an abstract syntax tree which you can think of as a heavily nested object that can be traversed programmatically the graphql server walks this tree and figures out how to respond to the request this is essentially what allows for the overall structure of an api interaction using graphql the data available on the server is described using the type system which allows clients to ask for exactly the information that they want which then leads to the client getting exactly that information having said all that you might be interested in building your next app using a graphql api while graphql certainly has its place in enabling front-end development there's a lot to consider when it comes to building the back end of an application in general and a graphql application in particular first let's look at the basic setup for a back end they usually follow something like the three tier architecture a web server acts as an entry point to the back end the web server serves static files to clients who request them and acts as a reverse proxy for requests requiring dynamic data an app server executes the business logic that powers the application the application server is where requests for dynamic data end up and is responsible for processing and fulfilling those requests lastly we have a database for data persistence this is where the long-lived data of the application resides now that we understand what kind of architecture a back-end requires we can start to imagine all the different things that a backend might need to do there's a wide range of different tasks an application might need its backend to perform all of which require configuration and programming to enable for the backend of a graphql application one of the key features is actually producing the graphql api as seen here both individual developers and large companies like paypal have acknowledged the complexity in creating a graphql api on the next few slides lewis is going to dig into what actually goes into making a graphql api thanks jordan i'll start my section by talking about a little bit about what goes into making a graphql api the first thing is that you need a graphql server to serve the api the server is responsible for receiving and responding to graphql requests in a graphql server the functionality is specified or defined by two main components the schema and the resolvers at a high level the schema defines what the graphql server can do and the resolver functions tell the server how to do it they tell it how to fetch the data from the database the next slides will talk about how the schema is defined and how the resolvers are written and structured as i mentioned the schema declarity declaratively defines the api's functionality or what it can do the schema is made up of types and each type has one or more fields the code snippet here shows a simple schema definition it shows a few of the types that can be defined the first is a custom object type an object is a unit of data which the api user can create or access the second is a query type and it defines how data of the person type can be accessed and then the third is a mutation type and it defines how data of the person type can be created or changed here it can all be created the code here only shows what data types what data types are defined and what the api can do but it says nothing about how those things are done that's the job of resolvers on the next slide while the schema defines what the api can do resolvers are functions that tell the graphql server how to respond to requests unlike the schema which has to strictly follow the api specification the resolvers are flexible they can be written however they need to to get the job done they can also be changed depending on how the underlying database needs to be queried the only requirement is that the resolvers have to return the data that the schema specifies should be returned in this code example the query and mutation resolvers correspond to the query mutation types that were defined in the schema in the previous slide the last few slides gave a big picture overview of what goes into making a graphql api but to fully uh to make a fully functioning graphical backend though there's still a lot that needs to be done meaning that along with the graphql server you need the standard components and configuration that would go into a generic back end now if you're a front end developer who wants to get a graphql based application up and running quickly all the things mentioned up until now could be a lot to think about ideally if you're focused on building a front-end app with graphql functionality you probably wouldn't want to worry about things like the back-end architecture the configuration of standard back-end features or low-level graphql configuration like writing resolver functions a common way to deal with this complexity on the back end is to use a back end as a service being able to treat the back end like a service means you can focus on the front end and not worry too much about details of how your back end is built with that said i'll get into how back-end as a service works and what we found when we looked at existing options like we said a back end as a service provides a layer of abstraction or encapsulation over all the standard backend components along with some pre-configured essential features like ssl and static front-end hosting in the back end as a service all those things are created like a black box and accessed through an api so in a solution you just ask for a back end to be created and then all the components are set up and configured automatically then you're provided with an endpoint to access it the reasons you'd want to use a backend as a service are that it reduces development time and complexity for the front end developers and maybe that all sounds great but like with anything convenient there tend to be trade-offs so what this chart shows is when talking about treating computing as a service an infrastructure as a service like ec2 gives you a high amount of control but you have to set up everything yourself in between is a platform as a service like heroku which is which just provides the operating system and then last is a back end as a service which abstracts away the most which makes it easy to use but you're also trading away most of your control building satellite we researched to see what already existed and as you might imagine there are many back-ends as a service already out there you tend to fall into two categories the managed services and open source products managed services tend to have lots of features and a high amount of support but they're also proprietary and generally not open source so they can risk vendor lock-in if your project grow outgrows a backend as a service they don't always also provide a graphql api or if they do it can require extra setup the second category is open source options like parse and many other lesser-known ones they're not proprietary and some have lots of features but they tend to be complicated to set up and to use like the last side mentioned the existing graphql backend of the service options have many useful features but also have their own set of trade-offs for example with managed services you don't have to deploy them yourself and they're easy to use but they're of course not fully open source or with the open source solutions you retain control of your data but you have more complicated deployment and setup you might need to select and configure your own database for example they can also take time to learn after you set them up at this point we saw an opportunity for an easy to use self-hosted open source graphql backend as a service we wanted something that's simple to use like a managed service but also uh able to be self-hosted and retain control of your data like one of the open source options since satellite does focus on simplicity of setup and use what it trades off is not having lots of features our reasoning was that other features could be integrated later if they are needed for example it doesn't use it doesn't include user authentication but there are lots of there are tools like auth0 that could be integrated without too much trouble the relative simplicity of satellite means that it won't be a good option for every application but it should be a good fit for developers who want to quickly build a graphql-based application without having to worry too much about the back end to elaborate on that we built satellite for a development team who needs a sandbox environment for front-end developers in this situation satellite could be deployed by a system administrator then it would provide easy access for one or more front-end developers who can log into satellite deployment and create and use their own back-ends where each back end can host a different front-end application so that was an overview of what satellite is and what problems it was meant to address so now i'll have a hand it over to will who will talk about how it works all right thanks luis uh yeah so now that we've established where satellite fits as a graphql backend as a service we'll talk about what makes up the satellite core application so first of all what is satellite well the core application of satellite provides client applications a graphql api for accessing the underlying data store and static file serving for front-end hosting these features are made possible using several components under the hood an nginx web server is used for serving static files and routing incoming requests a nodejs express application server provides a way for administrative actions to be made on the satellite instance and a d graph graph database is used as the data store in the rest of this section i'll explain the decisions that led to this architecture and the components in it and how they work together so when we first started building satellite we were immediately faced with a question and that was how do we build a graphql back-end that works for any application without knowing what kind of data that application will require ahead of time essentially we needed to build a generic graphql backend that would work for any application to answer that question first we had to understand what does it even mean to define an application's data typically the backend for a graphql application will require some kind of persistent data store a common database that is good for storing the kind of interrelated data that a graphql application will likely use is a relational database a relational database requires a schema of its own to define how the data in addition to the graphql schema required to define the api requiring a database schema in addition to the graphql schema would add another piece of configuration that would have to be provided to the backend which is something we wanted to minimize in order to keep satellite easy to use to prevent the need for an additional schema definition in order to use satellite at this point we thought we could come up with a way to generate a relational database schema from a graphql schema this would eliminate the need for two schemas and make it possible to define the backend's data using only a graphql schema now we wondered is it even possible to convert a graphql schema to a relational database schema while taking a very simple graphql schema as an example it's pretty easy to see how this would work for a graphql schema with a single object type with just a few fields we could generate a database schema defining a table corresponding to the object with all the necessary columns to represent the fields of the object the logic for this kind of hypothetical conversion process should be relatively straightforward matter of just converting strings so for now we were ready to proceed to the next challenge now that we had a way to define the data of an application we needed a way to access the data as we've mentioned making the data available for a graphql backend requires a graphql server to serve the api and that graphql server needs to contain resolver functions to know how to respond to the requests the thing is writing these resolver functions requires the developer to go under the hood and edit the back-ends code which is also something we needed to avoid in order to keep satellite easy to use as a possible solution we thought we could take a similar approach as we had for converting the graphql schema to a database schema we could try to automatically generate resolver functions for the most common actions you might want to take with your applications data like creating reading updating or deleting things and automatically initialize a graphql server with those generated functions once again would it even be possible to do this well we need four resolvers for each object type in the schema one for reading the data with a query type and three mutations one for creating updating and deleting now this was starting to get significantly more complicated but still seem doable since all the resolvers followed a similar pattern and we should be able to generate the correct function signatures and require database actions to make it work at least for a very simple schema like this our imagined schema converter would no longer just be a matter of converting strings now it would need to generate functions as well but we still felt confident enough to proceed down this path we could now envision a hypothetical architecture for our graphql backend requiring only the very simple schema that we've been looking so far as an input the graphql schema would be provided to the schema converter which would generate a database schema and create the database and also generate the necessary resolvers to initialize the graphql server the graphql server would then produce the graphql api that could receive and respond to graphql requests from front-end applications so far we'd only looked at a very simple schema too simple really to make a very interesting application out of when we started experimenting with more complicated schema the difficulty in creating the database schema and resolver functions increased dramatically for a more complicated example like we see here we would need to define multiple tables foreign keys and constraints in order to make the database work for the data represented by the graphql schema not to mention ensure that our generated resolver functions were sophisticated enough to interact with that database although we were confident that it would still be at least theoretically possible to pull this off we thought that now would be a good time to take a step back and consider alternatives this led us to other kinds of databases and ultimately we ended up at graph databases graph databases are databases specialized to handle highly interconnected data they do this by treating their data as a graph which is similar to how graphql treats its data in fact some graph databases have integrations with graphql to generate resolvers from a graph fuel schema which is exactly what we were looking for two graph databases with graphql integrations are neo4j and d graph negra neo4j is probably the most widely used graph database but its graphql integration involves using an add-on to the database which is more complicated setup than we were hoping for d-graph is less well-known than neo4j but it has a native graphical integration meaning you don't have to install any add-ons and you even get the graphql api directly from the database because of its native graphql support we ultimately chose d graph for the database of satellite we could now simplify our hypothetical architecture with d graph accepting a graphql schema as an input and generating the graphql api we would no longer need the schema converter to generate a database schema and resolvers or a separate application server to actually serve the api so we were able to remove those components from the architecture what we would now have is the entire backend being created based only on the graphql schema provided to draft although the majority of the heavy lifting was done we had a couple of additional problems to solve before we could get to the final architecture of satellite's core application in addition to the graphql endpoint dgaf exposes administrative endpoints for interacting with this graphql schema such as updating the schema and inspecting the currently loaded schema we knew that the front-end developer would need to access these administrative endpoints as they work with satellite but that these endpoints shouldn't be accessible from the public internet as it was we had no way of making only the graphql endpoint public to the internet while keeping the admin endpoint private in addition we currently have no way to upload or serve static files files that a front-end developer is likely going to need for the web applications to solve both of these problems we needed a couple of more components the two components we needed were an nginx web server to serve static files and act as a reverse proxy to the graphql api endpoint of dgraph and a node.js application to provide a way for the developer to upload their static files and perform administrative actions to draft's admin endpoint nginx was an obvious choice for an efficient and battle tested web server to act as the internet facing entry point to a satellite back end and node.js running a simple express application server worked perfectly for providing a private api that the front-end developer could access to upload their static files and work with the graphql schema loaded to draft and this brings us to the final architecture for the satellite core application which we can now see in a little more detail the nginx web server acts as a web facing entry point to the back end reverse processing graphql requests to draft or serving static files the node.js application provides a private entry point for the developer to perform administrative actions to their backend like uploading static files or updating the graphql schema now that we've explained all the necessary components of a single satellite instance we can discuss how we made deployment easier as it stands to get a single satellite instance running you'd have to manually download and configure each component individually specific to whatever operating system you're trying to run it on this would be a very time consuming and generally just difficult process the problem we now faced was how can we package all of the components of a single satellite application and their dependencies in a way so that it can be deployed easily wherever it's needed the solution of this problem was containers why would you use containers well they provide a way to package an application with its dependencies in an isolated and consistent way this means if you start for example a node.js container that container has all the requirements to run node packaged with it and you no longer have to worry about manually installing it and setting everything up the isolation of containers means that whatever is going on inside the container doesn't interfere with the host system so if you run a container with one it won't interfere with your host installation of node another good thing about containers is that they are lighter weight than some other options like virtual machines now virtual machines actually require running an entire guest operating system while containers run directly within the host operating system and use less resources this makes containers faster to deploy which is a great fit for satellite and since docker is the most popular way to package applications using containers we chose to use docker containers to package the component of satellite packaging satellite using docker containers greatly simplified the deployment of each individual component but since each satellite consists of multiple components it's still required manually starting and stopping each container for the application our final optimization for running a single satellite instance was to eliminate this need for starting each container individually fortunately docker provides a tool called docker compose which is designed specifically for defining and running multi-container docker applications compose uses a gaml file to declaratively describe the containers you want to run which the docker compose tool then uses to launch the containers with the required configurations our docker compose configuration for launching a single containerized satellite instance looks something like what is pictured here as you can see the compose file also allows for specifying various other options that are required for satellite to run like environment variables and storage volumes used by the containers to store their data and now i'll turn it over to alias to discuss the multi-instance architecture thank you will i'll talk about the multi-instance architecture after deploying a single satellite we turned our attention to how we could deploy several satellites supporting multiple satellites is essential since front-end developers may want the ability to develop several applications or several versions of the same application so the challenge was how can we transform our current architecture which supports only one satellite instance into an architecture that supports multiple satellite instances the type of architecture we chose as a solution is a multi-instance architecture in this architecture multiple instances of a software application run on a machine each instance shares the machine's hardware and system resources and is self-contained we wanted self-contained instances since each application will want its own schema and front-end files for hosting let's see how we designed our multi-instance architecture we have several tasks to complete in creating a multi-instance architecture first actually being able to spin up and tear down satellites second making sure that containers within a single satellite instance like the nginx server express api and d graph can communicate with one another third routing requests from the internet to the correct satellite lastly we want to make managing individual satellites easy so we'll need some kind of admin panel where front-end developers can log in and create satellites update schema upload files for hosting and introspect schema the first challenge we set to tackle is spinning up and tearing down individual instances of a back end the naive solution is to just run multiple compose files on a single machine this allows for multiple instances but introduces problems of port name and network conflicts however the larger problem it introduces is that at some point the single machine will run out of available resources as more and more satellites are spun up to solve this problem of resource scarcity we could scale vertically by upgrading a single server to have more resources or scale horizontally to include more servers which pull resources together the problem with vertical scaling is that there is a limit to how many resources one single server can have and the cost in upgrading the server rises exponentially we chose horizontal scaling because it is more cost efficient and can scale indefinitely in this architecture several machines pull resources together and the number of machine scales according to demand however there is still a problem inefficient resource use in this diagram we can see that machine 2 is at its maximum capacity machine 1 however has plenty of room to spare it would be nice if one of the satellites from machine 2 could be placed into machine 1. even better would be if individual satellite components could be deployed onto whichever machine is least used at the time to maximize resource efficiency and that's our desired solution we want to distribute the individual components of a single satellite across machines to maximize resource efficiency this solution comes with a set of challenges how do we spread individual components of a satellite across multiple nodes we can't use a dotted transpose file anymore we would need to find a way to either randomly or even with spread containers every time a satellite is deployed this is because dr compost file is node stroked and cannot be used to distribute containers across multiple nodes further we would have to write application code to keep track of available nodes and the resource utilization another problem is how do satellite components communicate since individual components of a satellite can live on separate machines they need a way to communicate with one another over the network for that they need to have a way to somehow dynamically discover one another's ip addresses and ports also how do we know which node to route traffic to in other words which node handle traffic for a given instance of the back end and finally what happens when a node or container dies ideally we would want the failed container to be restarted automatically especially since it gets harder to monitor all containers manually when there are potentially dozens of nodes in case of a node failure we would also want the containers to be restarted on a different node lately there is a solution that can solve these problems and that solution is a container registrator a container registrator is a tool that can be used to solve these problems container orchestrators are tools that are used to manage maintain and scale containerized applications for satellite we use kubernetes as our container orchestrator because it's the industry standard and is supported by all major cloud providers in kubernetes containerized applications live within a cluster which is a group of connected machines either physical or virtual the container orchestration tool solves our specific problems with a single api for managing nodes and the containers running on nodes we can easily write commands to spin up new containerized apps or tear them down we can define the exact way that satellite instances should be spun up through declarative app definitions and even define how node or container failure should be handled kubernetes also provides simple networking between containers running on the same or separate nodes and networking for requests coming from the internet managing satellite creation and deletion is simple with kubernetes we define a satellite instance in a manifest file which describes its ports names specification details and more we supply this manifest file and some environmental variables like name as arguments to the kubernetes cli which in turn makes a request to the kubernetes api which creates the given satellite instance tearing down is just as easy since we just make another command to the kubernetes cli and supply the name of the satellite instance to delete and the api takes care of the rest the next challenge is implementing internal networking we said before that containers make the single instance uh we said before that containers from a single instance will potentially be spread across multiple nodes how can they find each other to communicate for instance how can our nginx container forward request to the express api in kubernetes each container is given an ap address and is reachable by that ip address as seen here we can make a request to the specific ip address and get the request where it needs to go however this would require hard coding the ip address of the destination container this becomes a problem when you consider the fact that containers can fail or be updated when the container fails or is updated it is respond up as a new container with a brand new ip address though the previous hard coded ip address will no longer work how can we route requests internally to the create ip address given that containers may change ip addresses the solution is to use kubernetes services services provide the fixed gateway to containers there are many types of services but the one we care about in particular is traster ip cluster ip service exposes a container to internal traffic the service is defined as routes into a specific set of containers like the express api for example the service is given a name so that other containers who want to send requests to the container defined within the service can make requests to that service instead of destination container the name of the service is resolved by the internal dns to the ip address of the service the service then process the request to the correct ip address according to its specification in this example the express api has a service code app server app server is defined as routing request to the express container when nginx needs to make a draftkill request instead of needing to look up the ip or hard code the value it can send requests to the clusterwide available cluster ip service called app server app server then forwards the request to the correct container express api according to its configuration next task is to route recruit in external requests to the credit satellite how can we how can requests be routed to the credit satellite instance now that satellites are spread across several machines for this problem we use traffic traffic is an http reverse processor that can be used to route requests based on user-defined routing rules in satellite's case the sub-domain is the name of the satellite we can use the sub-domain as a routing row to send it to the third satellite running in the satellite system then a request enters when a request enters the system traffic is forwarded the request then traffic communicates with the cluster ip service of the engineer's container that it needs to send a request to then it forwards the request to that satellite instances nginx container we can see that flow here more generally a request enters the cluster and is routed to traffic traffic checks out the sub domain and path of the request and then routes the request to the cluster ap service with the name matching the sub domain the cluster ip service then browse the request to the engineer's container for that satellite instance and finally we want to make to make manage managing administrative tasks easy using an admin panel as it is now a front-end developer would need to issue commands directly to kubernetes to manage satellites this is far from ideal since developers may not know how to use kubernetes in addition he or she would need to have direct access to the kubernetes cluster which comes with its own set of challenges and security concerns is there some kind of interface we can provide to abstract away the process of managing satellites we use a gui as our instant interface of choice for managing individual satellites namely an admin panel the admin panel is a react application that communicates with an express api and is available at admin.yourdomain.com where your domain is a domain of your choice through that react app front-end developers can create and destroy satellites configure the graphql schema of their application upload files for static hosting and manage satellites data now we have reached the final multi-instance architecture we have a kubernetes cluster which the containerized satellites run on traffic a reverse proxy running is a container within our cluster browse external request to the current satellite an admin panel is provided at admin.domain.com and is used by front-end developers to perform administrative actions on satellite instances they own this is all good but how about building an actual application let's build a to-do app with satellite right now we don't have any satellites running so let's create one we will call it a to-do app it takes a few moments for the button to spin up and once it's ready we can begin configuring our application we start by defining the graphql schema of the to-do list the schema is uploaded as a text file once the schema is uploaded admin panel will display the current schema of the satellite instance let's see the database with some data here we are performing a graphql mutation to add entries to the to-do list since we named our app to-do app the back-end will be available at the sub-domain to-do up of the them of your domain all we need to do is update the javascript files to make requests to the correct origin once the front-end files are updated and ready to go we upload them to be served by satellite instances web server nginx and as you can see we now have a to-do app built and ready for venture capital funding some of the features that we intend to implement in the future would like to provide an authentication mechanism so that front-end developers don't have to rely on third-party providers also we would like to add a way to keep track of api metrics and loads and finally we would want to facilitate the easy database backups and exports here are the people involved in bringing this project to life and who presented for you today thank you all for coming and we're going to open for questions now yes i think just if you have questions go ahead and type them in the the chat or there's the question and answer and zoom too we'll give you give you a few minutes to get your questions in so go ahead and let us know what you wonder what you're wondering there we go we have a question from edmund um hey guys amazing work there's so much happening here yes i had a question about where the back ends are hosted uh could you elaborate on this so i guess i can take this one um yeah with kubernetes so we kind of mentioned it really quick it is supported by you know pretty much every cloud provider so you can you essentially get a managed cluster as a service a managed kubernetes cluster as a service so you would end up hosting your back-ends actually on on the cloud provider now it's also possible to to run kubernetes like on on your own hardware your own kind of bare metal setup so that's that's kind of an option too so they're kind of hosted wherever wherever you want typically a cloud provider but if you had the infrastructure you could you could run them locally as well looks like another question um from daniel a couple questions actually uh where's the kubernetes cluster hosted does the user need to configure it for certain cloud architecture i i think i think i might just answer that so if you want more clarification daniel definitely you can ask a follow-up question and daniel's second question what were some of the challenges of using a graph database versus a like a sql database so i guess um just from my perspective the the graph database so it uses like a completely different kind of query language and and they're specific to different kind of graph databases so like d graph has a different query language than neo4j i think they generally there's there's kind of some standards that they follow so there's like and um kind of kind of the general standard is called like cipher or like open query and things like that so using a using a graph database if you're using it directly you've got like an entirely different query language basically um you know the data model and everything for the graph database is obviously a lot different but you know using graphql to interact with the database really abstracts all that away so you're just you're just really using you know the kind of graphql queries that uh that a front-end developer will be familiar with so that is challenging but you generally don't have to deal with it um directly got a couple more questions here a question from rodney can you talk more about the process of setting up a reverse proxy could you elaborate on that and any challenges you faced during that part or anything you learned in that process if anybody from the team might remember when we were setting up our kind of reverse proxy from scratch i guess i guess one of the things about a reverse proxy like if you're just using nginx um you know just kind of like you know configuring it manually right um you've got a lot of settings to manage and you know you kind of gotta make sure everything is exactly right and you know it's just it's just kind of weird dealing with that kind of low level configuration and i think that's it's actually very very challenging for an application like like satellite where we're talking about the multi-instance architecture where you have you have essentially back ends you've got you know these upstream destinations being created and destroyed dynamically you kind of think about that you'd have to go into your configuration and update it manually every time right so that would be kind of like not only it'd be challenging to say the least of the impossible really so that's that's where um the service traffic really came in it actually dynamically sort of manages all that configuration itself on the fly based on the kind of service discovery that it that it enables when it's when it's working with your kubernetes cluster so you know i think those are some of the challenges of reverse proxy and yeah things that we learned as part of that process is that there's some there's some pretty robust tools out there you know it's kind of a well-known problem question from emel um regarding your choice of kubernetes for container orchestration what made you choose it over docker swarm maybe if uh i think i can jump in yeah there you go alias yeah it's given that doctor's worm is is much easier to set up than kubernetes like the define the application and so on but there are two main reasons why we chose kubernetes over swarm first is actually for us as as framework developers it might be more complicated but since uh most managed providers like azure and aws digitalocean they all provide managed kubernetes clusters which are very quite easy to use once you have your application packaged um in contrast uh with docker swarm you have to provision every node separately you have to connect them together and as a system administrator you have to manage the cluster yourself so for the end user using kubernetes is simpler and the second reason is without going into too much detail persistent data in swarm is more difficult because when if you have a database running in the node in one of the nodes for example in a cluster and let's say that the container died and it was rescheduled on a different node now with worm there is no really no easy way to move the data together with the container to another node but with kubernetes all major providers provide external storage that can be easily configured from the same manifest file and so if your container it contains data like a draft for example goes to another node the data goes with it so these are two main reasons looks like a couple um a couple more questions so if you have any other questions make sure to get them in question from drew how did you decide that you wanted to work with graphql for your project um i can address this one um i think we all had our reasons separately but um one of my main reasons was that graphql solves the problem of over fetching for the client very well and also prevents round trips so i thought that it was a neat convergence of solving front-end problems and then also a back-end as a service kind of solves the problem of developing a back end for front-end developers so those two things combined made the front-end experience much simpler so i thought it was a neat kind of combination of benefits there to use graphql okay and the uh the last question that we have is from cody does oh we actually have another question okay so a couple more questions does this work with any kind of front end application and what did you use to develop the admin panel um i could answer that um yeah it'll work with any front-end application that you just have to tell it to make graphql queries to the back end so as long as it can do that it'll work then the admin panel is just a react app so i wouldn't use any special tools to build that i think we use the front right of we used we are for the front end of the admin panel but there is also an express app running in the back right hand of the admin panel to keep track of data and the postgres database so all right and a question from owen it sounds like you guys were able to save yourselves from reinventing the wheel several times yes with a number of problems you encountered along the way utilizing existing tools like traffic to keep track of each uh where each component is located how do you get from being confronted with a problem to discovering that a tool already exists to solve i think from my perspective it's kind of like i mean you're encountering this problem and you like bang your head against the wall um you know for hours maybe days um just trying to understand the problem um you know and you kind of work it out on your own and it's really only then that you can start to understand why these why these tools you know why they are the way that they are because if you're just trying to jump into say kubernetes or say you know traffic as an ingress controller just from like like nothing before you even fully understand the problem i mean they're not going to make any sense you're not going to have any idea like where to even start with them so i think i think that there's you know a lot of pain that goes into it a lot of a lot of kind of struggle and a lot of just self education but then you start to you start to understand the problem um you start to kind of know what kind of questions you even need to ask and then you start to like start asking those questions say to like google you know like how do i do this and i think that kind of guides you to to the actual existing tools for those kind of problems yeah and just to expand on that a little bit or add to it um in will's section where we're going from schema converting eventually all the way to graph database um that was a multi-week process of a ton of research and a lot of patience and like he said a lot of head banging didn't try and figure out what was the best option for us so it just takes a lot of time and patience and energy all right so it seems like that is all the questions that we have um yeah i think thanks for i think we have another question oh do we okay okay yeah all right question for each of you thank you rodney um what was the most meaningful part of working on this project for you or the most meaningful part of working on this project so i could go first uh i think for me it was just just uh coordinating a project that lasted this long because i'd never worked on a group project or team project that was this uh disinvolved so that was kind of a learning experience to be able to to do that and yeah that's about it um i can go next um reverse proxies were somewhat new to me like the whole kind of implementing them was new to me at the start of this and also um kubernetes of course was new to me so learning more of the networking side of things and how to actually set up a reverse proxy those really expanded my kind of server side understanding of um computers and all of that so i think that that was the most valuable part for me yeah i think a a very meaningful part for me from a technology side was working with the statically type system of graphql i haven't gone through like launch school's curriculum of course we're dealing with dynamically typed languages and so it was it was very interesting to work with a statically typed system like i mean graphql is not a whole programming language but it does use that strongly typed um schema so just just kind of like doing that and it's it feels kind of weird it's like why why do you why do you do this it seems like a lot of but then seeing the kind of you know applications that you can get as a result of that the kind of like schema introspection that that enables that was really really interesting from a technical side for me yeah i'm going to detail everyone so joking um i think the most maybe like what i got most from this project is um learning how to deal with the uncertainty especially about the project like uh initially when we were starting out like wow there was no way we could like see how it all how it would all end and like where we would get and it's like now that we see it coming together it's very different and i think that that's pretty much it like um like it's it's learning how to be okay with not knowing what the next step is going to be and just diving in at the deep end is probably was very meaningful to me okay i think i think that's it i made sure to scroll down all the way on all the boxes so yeah again thanks for thanks for coming to our presentation everyone and hope you enjoy the the rest of your start of this new year thank you everyone thanks for coming you 