Today, we will discuss Bento and our experience designing a blazing fast serverless video pipeline. We will start by explaining what a video file is and defining video transcoding and serverless architecture, which are the key components of Bento. We will also explore why serverless architecture is well-suited for a video transcoding pipeline.

A video file is a type of content that is abundant on the web, making up around 79 percent of all internet traffic. Video files tend to be large, presenting challenges with storage, memory, and bandwidth. These challenges are further amplified by the increasing size of video files due to higher resolution and frame rates.

Delivering video files over the internet is more complex than other file types due to two major challenges: the compatibility problem and the bandwidth problem. The compatibility problem arises from the numerous codecs, containers, and video players available, each with its own strengths and weaknesses. Using the wrong codec or container can result in some users being unable to play the videos.

To tackle the compatibility problem, businesses must choose a codec and container for their videos based on the characteristics of the codec and the devices their users have. They also need to consider how much to compress their videos to balance file size and visual fidelity. Multiple versions of the same video are often created to cater to users with different bandwidth capacities.

The second major challenge, the bandwidth problem, arises from the variation in download speeds among users. Transcoding large video files takes a significant amount of time and puts a strain on memory and CPU resources. For individuals or businesses with regular video demands, this can become a bottleneck. They typically solve this challenge by either building an in-house transcoding pipeline or using a third-party transcoding service.

Building an in-house solution involves writing custom software and deploying it to servers or cloud services. While this option provides control over the transcoding process, it requires technical expertise and can still be slow and error-prone. Third-party transcoding services, on the other hand, offer comprehensive solutions for businesses that need support for multiple formats, codecs, and devices. These services specialize in video transcoding and are optimized for speed and handling error cases. However, they can be expensive and may provide more options than necessary for smaller businesses.

Given the limitations and trade-offs of existing solutions, there seems to be an opportunity to create a fast, low-cost transcoding pipeline for businesses that do not have video expertise and do not require an extensive range of video options. This is where Bento comes in.

Bento is a serverless video pipeline built using function as a service (FaaS) technology. Function as a service refers to deploying application code on third-party servers, where the developers are only responsible for the business logic. The core benefits of using FaaS include delegating infrastructure management to a third party and paying only for the compute time actually used. Additionally, FaaS enables instant scaling of function instances and concurrent execution of functions, which are crucial for the bursty nature of video transcoding workflows.

The bursty nature of video transcoding, which demands high CPU and memory resources, aligns perfectly with the instant scaling and concurrent execution capabilities of FaaS. With FaaS, the computing resources automatically scale up or down in response to the workload, ensuring optimal resource utilization and minimizing wasted capacity during periods of low demand.

Furthermore, video transcoding is traditionally a serial process that works on the video from beginning to end. However, Bento breaks down videos into smaller segments and transcodes them concurrently. By processing multiple segments in parallel, Bento significantly reduces the total transcoding time. Instead of taking two hours to transcode a video in a linear fashion, Bento can transcode the same video in just 30 minutes or less by dividing it into multiple smaller parts.

In Bento, videos are broken down into six-second segments, each taking only a few seconds to transcode. These segments are processed in parallel within the system, leading to a dramatic reduction in transcoding time. Bento can handle dozens or even hundreds of small segments concurrently, further optimizing the transcoding process.

Bento falls between an in-house transcoding farm and a fully featured transcoding service on the scale of control over inputs and outputs. While in-house solutions offer the highest level of control, they require technical expertise and can be slow and error-prone. Fully featured transcoding services, on the other hand, outsource the video engineering and provide speed and control at a higher cost. Bento presents a fast, low-cost alternative for businesses that want control over their transcoding pipeline but do not have extensive video expertise or require a wide range of options.

In conclusion, Bento is a serverless video pipeline that leverages function as a service technology to provide a fast, low-cost transcoding solution for businesses. By utilizing the instant scaling and concurrent execution capabilities of FaaS, Bento optimizes resource utilization and significantly reduces transcoding times. It offers businesses control over their transcoding pipeline without the need for extensive video expertise or the high cost of fully featured transcoding services. Bento is a promising solution for businesses looking to efficiently deliver video content over the internet. The provisioning of the right level of computing power for a server dedicated to video transcoding is challenging due to the extreme variation in the size of video files. This challenge is even more pronounced for businesses with intermittent transcoding needs, as there may be periods of server idleness followed by periods of peak capacity. Function as a Service (FaaS) architectures, with their ability to scale instantaneously, can address these bursty workflows effectively. FaaS architectures can automatically scale up to meet high compute demands and scale down to accommodate minimal or no computing demands, eliminating wasted resources. The flexibility of FaaS architectures makes them highly suitable for video transcoding. This flexibility is the first reason why we believe FaaS and video transcoding are well-suited for each other.

The second reason why FaaS and video transcoding pair so well together is the serial nature of video transcoding. When transcoding a video, the process works from start to finish on the entire video file. Given the large size of video files and the slow transcoding process, this results in a significant amount of time required to transcode a single video. However, if we were able to transcode multiple segments of the video in parallel, the overall transcoding time could be dramatically reduced. For example, if we break the video file into four segments and transcode them concurrently, the time required to transcode the entire video could be reduced by 75%. With our system, Bento, we break videos down into six-second segments, resulting in even further reduction in transcoding time. By processing all of these segments in parallel, the time to transcode videos is significantly reduced. This parallel computing capability is the bread and butter of Bento.

Let's now talk about the development of Bento, a serverless video transcoder. Our primary goal was to make Bento fast and easy to use. Bento is deployed to your Amazon Web Services (AWS) account, ensuring that your files remain on your own servers. While existing solutions for video transcoding cater to large businesses with constant high video demands, Bento is designed for small businesses with bursty video transcoding needs, such as processing new videos several times a day or week with intervals of inactivity. Bento is also suitable for businesses that prefer not to host their videos on platforms like YouTube or Facebook. For our use case, we prioritized speed and simplicity of use, trading off some control over transcoding settings and input/output options.

Bento currently supports up to one and a half hours of 1080p video and up to 15 minutes of 4K video. The supported input formats include videos that use the h264 codec, such as MP4, MOV, MKV, 3GP, and TS (popular streaming format). The transcoded videos are in MP4 format, the most commonly used format today.

Our plan for building Bento was to create a pipeline of functions that would process a video file from start to finish. The pipeline works as follows: we divide the video into segments and use instances of the transcode function to transcode each segment to the desired output format. Finally, the transcoded segments are merged together into a complete video file.

To implement this approach, we chose a variety of resources from the AWS ecosystem. The main provider for Bento is AWS Lambda, the most widely used function as a service platform. We also utilize AWS S3 for storing video files, Amazon DynamoDB for tracking pipeline state and storing information about user videos, and Amazon EC2 to host Bento's admin dashboard. In the transcoding process, we use FFmpeg, a free and open-source software, for all our multimedia file operations.

Looking at the architecture of Bento, we have four main stages: execution, transcoding, intermediate, and merge. In the execution stage, the video is divided into segments, and each segment is passed to an instance of the transcode function for processing. The transcode functions run in parallel, transcoding their assigned segments to the output format. Once all segments have been transcoded, the merge function is invoked to combine the transcoded segments into a complete video file.

One of the main challenges we faced was coordinating the stages of the pipeline to ensure that the merge function was invoked only when all segments had been transcoded. The parallel nature of the transcode functions made it difficult to determine when all functions had completed their tasks. To address this, we introduced a database to track the state of the pipeline. Each transcode function updates the status of its assigned segment in the database, marking it as complete. The database events are then used to trigger the merge function only when all segments have been transcoded.

Another challenge we encountered was managing storage limitations when working with large video files. Since each function is allocated temporary storage, the storage capacity can quickly become overwhelmed. To mitigate this, we leveraged the use of S3 storage buckets to store the transcoded segments and the completed video file.

In conclusion, Bento is a serverless video transcoding solution designed for small businesses with bursty video transcoding needs. It leverages the flexibility of FaaS architectures to scale computing resources dynamically and offers a fast and simple user experience. The pipeline architecture ensures efficient parallel transcoding of video segments, reducing overall transcoding time. By utilizing AWS resources and FFmpeg, Bento offers a powerful and scalable solution for video transcoding. In this coding Capstone project video, we will discuss the different stages of our pipeline and the problems that arise from concurrency. When multiple processes are running simultaneously, it becomes challenging to track the status of specific processes and ensure the coordination of concurrent processes interacting with the same database, as it can lead to race conditions. Our solution involves capturing changes on a database to address these issues.

Without a centralized workflow orchestrator, our applications react to internal and external events. Serverless functions are a common feature in this architecture as they can respond to events and create events that trigger other functions in our pipeline. One function, in particular, stands out from the rest - the merge invoke function. This function plays a crucial role in coordinating our pipeline's workflow by invoking the merge function at the appropriate time. It serves as a bridge between the many transcoding processes running on the left side of the pipeline and the merge phase on the right.

To ensure the success of a transcoding job, the stages in our pipeline need to be coordinated properly. Timing is particularly critical in the merge stage, where transcoded chunks are assembled into a final video. The merge stage is the most challenging to coordinate because hundreds of transcoders can be running simultaneously on its left side. It is difficult to determine which transcoder will finish last or when they will all be completed. To trigger this stage reliably, we needed a dependable event.

Initially, we considered whether a specific transcoder instance could produce the event to trigger the merge stage. However, this approach led to a problem related to concurrency. It became tricky to monitor the status of these transcoder functions and predict which one would finish last. This uncertainty could result in the premature invocation of the merge function before all job segments were available. To overcome this challenge, we introduced the use of a database in our pipeline to capture state information.

By adding a database, we encountered another problem related to concurrency. Concurrent processes interacting with a database can lead to race conditions. To track the state of our pipeline, we created a segments table and a jobs table to store metadata. The transcoders now update the segment status from pending to complete in the segments table and update the number of transcoded segments for a job in the jobs table. This database allows us to reliably store and track the state of our pipeline. However, the database alone cannot orchestrate the transition from the transcoding stage to the merging stage.

We tested a model where any transcoder could orchestrate the merge phase. These transcoders would read the jobs table to check if all segments were transcoded. If so, they would trigger the merge phase. However, this approach introduced a race condition. If multiple functions completed at the same time, they could both read the jobs table and erroneously trigger the merge function. This resulted in multiple invocations of the merge function, which is not desired.

To solve this problem, we implemented an event-driven architecture that captures changes to the database as events. Change data capture involves recording a time-ordered sequence of updates to a table. We created an event stream attached to the jobs table to provide serialization of updates. Whenever the completed segments counter in the jobs table increases, a record is created in the event stream that includes a snapshot of the counter value. We then attached the merge invoke function to this stream so that it is invoked whenever new records are detected.

Each record in the event stream provides the merge invoke function with the counter value of the jobs table. If all segments are ready to merge, the merge phase is triggered. This approach ensures that a transcoder instance can read the counter value before another completed transcoder has a chance to update it. By capturing changes to the database as events, we have solved the challenge of coordinating the merge stage in our pipeline.

Moving on to the next problem domain, we encountered challenges related to storage capacity. Videos are typically large, and if our pipeline can only handle small files, it severely limits our use case. Initially, our pipeline was restricted to video files of no more than approximately 250MB. The main issue was the merge stage, where the merge function would download all segments to temporary storage. This limitation meant that Bento could only handle videos around 250MB.

To overcome this constraint, we decided to avoid storing the segments in temporary storage and instead process them in memory. Ffmpeg, the video transcoding software, does not require locally stored videos. It accepts a list of URLs pointing to segment locations in S3 storage. This means that segments can be downloaded and concatenated in memory, resulting in only the output video occupying temporary storage. By making this change, our pipeline's file size capacity doubled to 500MB.

However, in the world of video, 500MB is still not a significant amount. Our input segments could eventually total more than 500MB, but the merge function has 3GB of memory to hold and process the segments. This storage capacity limitation led us to the next challenge: output storage. In the original design, ffmpeg gradually built up the output video in temporary storage. Once the concatenation process was complete, the entire video was transferred to S3 permanent storage. This approach limited our pipeline to files around 500MB.

To overcome this bottleneck, we optimized the merge function's output by streaming it directly to S3 using multi-part uploads. Instead of holding the final output locally, we sent it in pieces as a byte stream. S3 supports multi-part uploads, allowing clients to transfer files in chunks that can be sent in any order. With this improvement, the merge video is gradually constructed in permanent storage, eliminating the limitation of temporary storage. Our pipeline can now handle videos of up to 2GB in size, thanks to the 3GB memory allocated to the merge function.

Now, let's shift our focus to Bento's performance. Our goal was to build a fast and user-friendly transcoder, and we benchmarked Bento against two alternatives commonly used for video transcoding. The first alternative was a free-tier EC2 instance with 1GB of RAM running ffmpeg. While this option provides a basic benchmark for non-optimized video transcoding on a single machine, it represents the baseline for comparing Bento's performance. The second alternative was Amazon Elemental MediaConvert, a professional-grade transcoding service used by broadcasters and media companies.

In our benchmarking test, we measured the time it took Bento and the two alternatives to output a video file in MP4 format at a resolution of 1280x720. We used 19 test videos ranging in size from 4MB to 2GB and with durations ranging from 7 seconds to 90 minutes. The results were remarkable. Bento consistently outperformed the EC2 instance by over 90% and Amazon MediaConvert by 50% across various file sizes, durations, and formats. These results demonstrate that Bento's serverless massively parallel approach significantly improves transcoding speed.

However, it's essential to acknowledge the limitations of our current approach. Function-as-a-Service providers impose execution time limits, such as AWS Lambda's maximum duration of 15 minutes. This means that each transcoding function must complete its work within this time frame to avoid failure. While high-quality videos generally finish transcoding well under this limit, large or high-quality video segments could potentially cause issues in our pipeline.

Another limitation is that Bento prioritizes speed and ease of use over video quality and file size optimizations. While there are transcoding optimizations that can improve the final file size, implementing them would come at the expense of speed. However, Bento's pipeline is well-suited for adding additional video transformations such as subtitles and intro/outro bumpers in the future.

Lastly, it's worth mentioning that as businesses move beyond the free tier, the compute time cost of Lambda functions can be more expensive than EC2. However, this is offset by the significantly reduced transcoding time. Businesses transcoding videos 24/7 may find that transcoding on Lambda or any function-as-a-service platform becomes more expensive. Therefore, Bento is primarily targeted at businesses with frequent but intermittent video transcoding demands, as they can benefit from the speed and ease of use offered by the pipeline.

In conclusion, Bento provides solutions to the challenges of coordinating concurrent processes in a pipeline and expands storage capacity for video transcoding. By capturing changes to a database as events, Bento ensures reliable coordination of stages within the pipeline. Additionally, Bento's optimizations significantly improve transcoding speed compared to traditional alternatives. While there are certain limitations, future enhancements can be made to support additional output formats and video transformations. Bento is a powerful tool for businesses with intermittent video transcoding needs who value speed and ease of use. During this video, we discussed the coding Capstone project called Bento. Bento is a video transcoding tool that aims to simplify and streamline the process of converting video files into different formats. We explored the features and functionality of Bento, as well as its potential for future enhancements.

One important aspect to note is that Bento may not provide cost advantages for those who already have dedicated resources for transcoding full time. However, for businesses or individuals who are looking for an efficient and user-friendly solution, Bento can be a valuable tool.

Moving forward, we discussed exciting opportunities for enhancing Bento. First, we plan to add support for popular streaming formats, such as HLS and DASH, in addition to the already supported MP4 format. HLS and DASH are widely used for streaming videos, and their inclusion in Bento will make it even more versatile.

Furthermore, we aspire to expand the types of video transformations available in Bento. For example, adding features like adding subtitles, intros, and outros to videos can be seamlessly integrated into Bento's transcoding pipeline. These additions will facilitate a wider range of video customization options.

Before concluding the video, we expressed our gratitude for the viewers' attention and invited any questions they may have. We proceeded to address a few questions posed by the audience.

One question inquired about the reason behind using six-second segments in Bento. We explained that the decision was based on keyframe data analysis, aiming for optimal video and audio quality. By aligning video segments with keyframes approximating two to six seconds, we achieved superior output quality.

Regarding the technical equivalence of transcoded files, another question emerged. We clarified that while the metadata of the original file may differ from the transcoded segments, the output size and quality were consistent. Bento successfully maintained video quality and ensured compatibility with major media players.

We were asked if Bento had been presented to any potential customers. Our response conveyed that the focus of the project was open-source development. Job applications would be an opportunity to showcase the project, while we also remained interested in feedback from the community. Detailed deployment steps and a user-friendly dashboard were available on GitHub.

Another question inquired about exploring Microsoft or Google serverless options. We admitted that we hadn't looked into these alternatives, expressing curiosity about their features facilitating state management. Exploring other serverless providers' capabilities to handle state would be an interesting avenue to explore.

A few additional questions surfaced in the chat session. One asked if Bento could handle compressed files and play them. We clarified that Bento is not a video player but rather a tool converting videos into playable formats compatible with major media players. Hence, Bento can indeed process and convert compressed files effectively.

Another query concerned the inclusion of audio transcoding options in Bento. While Bento currently focuses on video transcoding, incorporating audio transcoding would be a straightforward extension. Leveraging the capabilities of the FFMPEG library, Bento can easily incorporate audio transcoding functionality.

A question related to output bit rates arose. We shared that throughout our tests, Bento aimed to maintain the bit rate of the input file. Amazon Media Convert offered various options, such as constant bit rate and variable bit rates, which we did not extensively explore in our benchmarks.

The handling of video metadata, such as titles, descriptions, and authors, was another query. We clarified that Bento did not explicitly deal with video metadata, except in the final step when writing to Amazon S3. Due to the streaming nature of file creation and metadata appending, we encountered challenges when appending metadata, but adopted a workaround to ensure compatibility with all media players.

When asked about the language choice for Bento's functions, we replied that we used JavaScript in the Node.js runtime. Although other languages like Ruby could have been utilized, Node.js provided useful libraries, particularly for filesystem management within the functions.

The query about choosing DynamoDB over a relational database prompted us to explain the benefits of DynamoDB's NoSQL nature. With no need for complex data relationships or joining, DynamoDB offered a lightweight solution for storing and tracking information. Its schema-less structure allowed us to rapidly prototype and make changes without rebuilding the database.

Regarding our motivation for tackling the video transcoding problem, we acknowledged the fascination with video as a file format and its widespread use. However, none of us had specific plans to enter the video industry.

A mention of Bento's potential contributions from the community sparked interest. We emphasized the extensibility of Bento and highlighted the countless ways it could be further developed. With basic transformations already in place, the community could effectively contribute by expanding the supported formats. HLS and DASH were among the top priorities, considering their prevalence and relevance in streaming.

In conclusion, we expressed our appreciation for the positive reception of the project and the engaging questions from the viewers. We found building Bento to be a rewarding experience, and we believe there is substantial potential for a product like Bento in the marketplace. While Bento is not designed to be a commercial product, there is still room for growth and improvement to cater to the diverse needs of individuals and small businesses. There is great potential for a product like Bento to succeed in the marketplace due to its ability to provide both convenience and lower cost to a large number of people. The future holds ample room for such a product. With that, we will conclude this video. Once again, thank you for watching. We found the process of building this project to be extremely satisfying, and we are delighted to see that it has been well-received. We appreciate all the questions and interactions throughout this journey. Thank you all for your support.