okay so we're happy today to present my straw which is a framework that offers rapid iteration for serverless orchestration now some things that we're going to go ahead and cover today are serverless what that is and some patterns around working with serverless and we're going to get a little bit deeper into orchestration orchestration patterns of working in that area and we're going to talk through that with an example so it's more easily understood get into aws step functions which is a solution in this area and some existing solutions utilizing that and then we'll go ahead and present maestro and what we're hoping to accomplish and what we've accomplished with it so serverless when one hears that term is actually a bit of an ambiguous term really in the general sense it has to do with offloading application code to the cloud so the benefit of that is that a development team doesn't have to manage local servers no maintaining no provisioning so that can be pretty time effective but it's also cost effective now there's actually a subset of serverless that is often completed with the serverless itself known as fast for function as a server now when we speak about serverless in this presentation we're going to be focusing on that subset of fast and it actually matches well with how many developers understand serverless uh we've seen the graphic here one poll represents that some uh 60 percent of developers when they heard the term serverless equated it with that now faz really has to do with again small apple with application code uploaded to the cloud but here we're talking about really small applications ideally these applications have a single responsibility now the particular thing about fast is that these applications are on individual containers which can be spun up in response to events those containers also spin down once the execution of that function or that application terminates now so for this reason fast really shines when it comes to scaling the cloud provider can automatically spin up containers in response to events spin them down and only charge for the time that those functions were executing now the most popular cloud provider at the moment is aws and their fast offering is aws lambda now some facts about lambda and since we're talking about small applications they have an execution time limit now the limit is up to 15 minutes it really defaults to three minutes so ideally it's a very small application the deployment size up to 250 megabytes ram 3000 you can develop in some seven languages now there are some challenges when working with lambda one of which is state management since we're talking about containers that spin up and down once an execution has ended any state that existed during that function's execution disappears so managing state for a larger application that utilizes various lambda can be a challenge also there's an issue of cold start and what that's referring to is this spinning up phase of a container if a container hadn't already previously previously executed it can take up to 500 seconds for that container to be permit provisioned now aws has offered something recently to be able to offer sub 100 millisecond provisionings however there's an additional cost to that and it really looks like a model that doesn't doesn't tend to match a team using that model for all of their functions now amongst others what are you going to do if you have an execution limit if you have a long running process that could be a challenge to reconcile further what if something happens during execution and you need to peer into the system to see what happens since you're dealing with aws not a local system you can only peer through uh the window that they give you to audit execution so when we talk about lambda this is actually a very new field serverless in and of itself is new and there's not really many best practices in how to develop or configure an application in this environment so another challenge is configuration now since there aren't really many best practices practices what have been developed over time are some patterns for developing applications in serverless now there's patterns that correspond to general categories for example availability we've already discussed just a little bit about cold start about execution limits add to that failure and you can see where there's many reasons that a function may not be available when it needs to do its part in an application there's patterns to deal with that then since we're talking about functions responding to events there are some patterns for event management managing the monitoring or scheduling or responding to a schedule of an event also many services including multiple lambdas need to be able to communicate with each other to form a larger application there's patterns for communication and just like many applications serverless or not uh often a user needs to have some type of authentication or authorization and so there's some patterns for dealing with user authorization now maestro focuses on one set of patterns and that is the orchestration now orchestration in a nutshell is the act of managing the workflow between multiple lambdas and as required other services it's kind of vague though to talk about orchestration without actually thinking through a more concrete example so imagine there's a sole developer in a startup who's given the task of building an application that allows employees to request the provisioning of a resource that provisioning would have to be approved by a manager now if the manager denies then immediately the employee's notified if the manager accepts then of course the resource can be provisioned access granted later the employee is notified now if the developer is rather savvy they can perhaps think through this process and extract out some components and those components would actually be represented by various lambda in a workflow now what are some challenges along the way if one were to try and actually develop this workflow into a real application well what about chaining execution of these various components what if a particular component needs a given input or how do you process outputs we've already discussed a bit state management uh how do you resolve any issues regarding state management in this application execution type well it may be that one component executes and then synchronously the next one after the previous stop but it also may be that the previous continues to execute will the workflow continues that would introduce some asynchronicity well how do you manage that in an application where the components are disparate and then of course just something simple branching logic but where do you put it how is that handled now there's some challenges that come along with these various aspects of decisions to be made in orchestration communication challenges well how do these services communicate where do you put orchestration logic reliability well what if one of these components fails how do we implement retry how do we prevent failure also as we mentioned you can only peer into this system through the window aws gives you and aws doesn't give you a unified log for monitoring execution of these services so let's talk about some orchestration patterns that can be applied as we step through different uh portions of our workflow now first off it may be that the request that comes in is malform and that malformed request could lead to the manager failing once he receives it that's less than ideal so there's actually a validation that can be performed in what's called the proxy lambda pattern now a proxy lambda well it sits in front of another component and invokes it conditionally so in this case the condition would be well no error is present so in the case that the manager then receives a valid request only what happens now that the manager executes makes its decision well how do we determine where next to go in our workflow this branching we could actually handle in another pattern the orchestration lambda now an orchestrator lambda is able to communicate with other services just like the proxy lambda one thing to note is that lambda is capable of invoking another lambda now in this case let's consider that there is that 15 minute execution limit well maybe the savvy developer has determined that uh there's only going to be a request in when a manager is available or there's some other restrictions there and supposes okay this 15 minute limit is not going to be much of a problem to reconcile that assumption made well what if we actually made the manager lambda the orchestrator lambda and by putting business logic and orchestration logic side by side together we've overloaded it or fattened it up so we're effectively calling this the fat manager next in our process our branching has been uh resolved and the manager accepts well let's provision yet provisioning may be a risky task to perform that provisioning may fail now ideally the employee who initiated the request wouldn't have to wait some arbitrary amount of time and realize they never got no notification of denial or acceptance i ideally if this provisioning were to fail something would be able to retry at least some determinate amount of times to see if we can provision again well where could that logic go we're already using utilizing here the fat manager why don't we just fatten it out we already got business logic and orchestration logic together so why not just put it all in the fat manager so we've got our fatter manager here handling that however we're reminded that we do have a 15 minute execution limit now here what if the provisioning were to succeed but only after 15 minutes the fat manager that was monitoring maybe would have spun down by that time or what if the provisioning takes a long time and then failed see we do see that there is potentially more risk there now the developer knows the system relatively well you can say perhaps well we can tolerate that risk what are some other drawbacks well we've really got a poor separation of concerns here because we've got this orchestration logic and the business logic together and the consequence of that is every time we want to iterate on our workflow we have to modify or at least consider the orchestration logic along with the business logic so you know a developer may look at the fatter manager and say perhaps we can refactor out the orchestration logic just like we have the validator proxy lambda as an orchestration measure separate from the rest of the workflow well that's our intuition why stop there we can actually extract out an entire orchestration layer that being the case would be the benefits well we could return to this thin business logic as we see on the left and then we have a pure orchestration logic if we do that this allows us to more quickly iterate because we can try different workflows without actually having to change the orchestration logic along with the business just change the business logic that's really a lot easier and it could be that we could find a service that could provide us some of the primitives that we would require in orchestration right out of the box retry branching timeout now before we get into a potential service that could give us some of that out of the box let's consider a pattern that fits well for orchestration the state machine now a state machine or state when specifically talking about a workflow represents a state at a given step in a workflow now that state is dependent on inputs and conditionally would provide an output based on the execution but really what the state machine as a whole is concerned with are the transitions between each step as uh rowan udell who's an aws premier consulting partner stated when talking about state machines he said with them you can describe your application as a mixture of your inputs the states that your application can be in and the transitions between those states so the aws offering for state machines is the eight is our aws step function and to explain a little bit more about that we're gonna allow zach to continue so let's uh let's talk about step functions as terrell explained aws step functions is essentially amazon's implementation of a state machine and it acts as the orchestration layer over your serverless resources such as lambdas now in order to define a state machine with step functions amazon has created a language called amazon states language or simply asl asl is a declarative language which is written in json so we have here a simple example of what a state machine would look like written in asl and there's also a nice visual that the aws console creates for you and on line three there is a required field called start at and this specifies which state in the state machine will begin execution you have to start some somewhere then on line 4 is where we have our list of states now often these states will represent a lambda or some other service but it doesn't have to there are other types of states that exist to help orchestrate the workflow for instance there's a choice state which enables branching logic there is a weight state that will simply pause execution for some specified amount of time there are others but it's important to point out that step functions provides these different types of states to help facilitate the workflow you are wanting to accomplish now in this simple example we only have one state called hello world and it does reference a lambda which might just return a string of hello world and once the lambda returns the state machine must define what comes next so on line eight we see the end true and that is signifying that there actually is nothing next in this case we've arrived at the end of the state machine so that's a simple example but let's let's look at something a little more complex we'll bring back the hypothetical example that terrell discussed earlier of the manager deciding whether to approve a request for provisioning a resource so here's that same workflow but now implemented with step functions uh this this state machine is orchestrating several states uh four of which are lambdas and let's look at a couple of these states a little more closely there's the manager choice state and it's of type choice and it's actually not referencing any lambdas the previous state manager does reference a lambda and it's the output of that function that is then passed on as input to manager choice we see here that if the manager's decision is accept then execution continues to the provisioner if deny then a notification will be sent out now if we look at the provisioner state we see how one might implement retry logic for states that reference lambdas such as this one asl has a field called retry built in that allows you to specify which types of errors to retry and how many seconds to wait in between as well as a back off rate and maximum number of attempts pretty handy to be able to put this orchestration concern here instead of writing some custom retry logic alongside business logic so after a state machine has executed using the aws console you're able to access an interactive execution event history where you can audit the inputs and outputs of the transitions between states all in one unified place and also the visual workflow will be color coded to help you quickly determine what the outcome was of each transition of each state transition within that execution so quick recap of some benefits the the core purpose of step functions is to provide orchestration to your infrastructure rather than maybe having to choreograph everything in some way but it also has some really helpful built-in features we discussed choice states for conditional branching and retry logic and unified logs and visual workflows that help with auditing executions and there are others as well that we didn't touch on but in addition to the benefits there are also some challenges in working with step functions one of the common complaints when working with step functions is that asl is not very intuitive it's a json based language that's really optimized for machines rather than humans and some state machines can get quite complex with with dozens or or maybe hundreds of states now there are some tools out there that try to help provide a higher level of abstraction that compiles down to asl but these are not widely adopted as of yet and there's still much unsettled debate regarding what the characteristics of these tools should be so it seems that for now the most effective way to alleviate the pain of working with asl is to use templates to help you model the workflow you're trying to create this at least provides a useful starting point for beginners and it's a nice convenience for those who are already more familiar with the language another challenging area and this isn't unique to step functions is just working with the aws console in order to deploy your infrastructure now typically since step functions is an orchestration layer there are many services integrated with your state machine that need to be deployed right alongside it and each of these including the state machine needs to have the correct region and account number associated with it and the right permissions configured and each service has its own interface so you're not doing this all in one place and doing this all manually especially in the aws console is tedious and error-prone process so it's certainly an area that benefits from some some automation and indeed there are several frameworks that aim to help the developer with these tasks pertaining to deployment i want to discuss some of these frameworks but before i get into specific ones i first want to point out a couple of tools aws offers that these frameworks can leverage to help to help in automating deployment the first is a service called aws cloud formation and this is aws's offering that allows you to basically create a configuration file that will contain all of the resources in your serverless infrastructure that you are wanting to deploy it's known as infrastructure as code so here what a framework can do is to guide the developer through a process of creating framework-specific files that are then compiled down to cloud formation and then the whole stack is deployed at once the other tool is the suite of aws software development kits or sdks which are apis that allow the developer to work directly with individual resources from their language choice so basically any framework in this space is going to be using one of these two tools however it it seems the design philosophy of the framework will often inform which of these tools that the framework will employ for instance frameworks that aim to be a more general purpose tool will typically take the cloud formation approach whereas frameworks that have specific use cases in mind or maybe geared toward a particular language will often opt for the sdk approach so then let's discuss some of these frameworks uh keeping in mind that we're really only interested in those that allow for the deployment of step functions there are many frameworks out there that work great for their use case but don't include step functions so they're outside of the scope of this discussion so the first one we'll look at is aptly called serverless framework and it's the dominant player in this space serverless framework is a more general purpose tool so it takes the cloud formation approach and it does provide a plug-in that allows you to include step functions as part of your deployment so some of the good things about serverless framework is that it supports multiple runtimes it automatically creates the permissions that are needed for the resources in your infrastructure and it does provide some simple asl templates uh what's not so great is that these templates that are provided require the user to manually configure the resources which the state machine will be orchestrating also the state machine definition must be written in yaml in order to accommodate serverless frameworks conventions which isn't great because if you recall asl is written in json so you now have to convert that to yaml and finally the general purpose functionality that serverless framework provides you does come at a cost having 535 node modules as dependencies which can really be bulky and unnecessary depending on your use case the next framework we'll look at was created by aws and is called the serverless application model or sam and sam started providing support for step functions uh just a few months ago it's it's similar to serverless framework in that it also is a more general purpose tool that takes the the cloud formation approach and it also supports multiple runtimes and automatically generates the required permissions for your resources but unlike serverless framework you are actually able to deploy a working state machine from a template without having to make any manual configurations it can all be done straight from the command line however there's only one template that is offered and it has a relatively lengthy deployment time taking a couple minutes and there are several prompts that the user must respond to in the process and once deployed there doesn't seem to be a command that just as easily tears down so that has to be done manually so serverless framework and sam are both more general purpose tools and neither of them were designed with step functions in mind they both later added support for step functions in the event that your app uh just happens to use them so what about some more purpose-built frameworks well there doesn't seem to be many that are designed with step functions in mind and that actually support step functions but there is a framework built by coinbase called step and step actually allows the user to construct a state machine definition with a higher level language namely go however coinbase seems to be one of the only users of their framework in fact they they list the development status of the framework as beta an additional drawback is that step is not able to actually create a new state machine but can only modify an existing one which can be a hindrance to the developer who's wanting to quickly iterate on their workflow but has to manually create a mock state machine first okay so that's just a quick look at some of these frameworks and and how they might be used to address some of the pain in working with step functions but this this pain really needs to be experienced firsthand without any of these frameworks in order to appreciate the the problems that our framework maestro was specifically designed to solve so i'll let john walk you through some of the steps involved with deploying step functions with the aws console so you can experience some of that pain uh and then experience the ease of orchestrating your serverless workflows with maestro so i'll hand it to john so i'm gonna take you guys through a walkthrough of what it looks like to work with the aws console to create this example workflow so if you take a look at this diagram that just appeared on the left you'll notice that there are the four lambdas of the example workflow the requester the manager the provisioner and the access granter and in addition to that there's also this whole orchestration layer which encompasses all those lambdas an aws step functions state machine so let's go through all the steps required to set up a working application using only the aws console here's a diagram that we will step through that represents uh the steps uh required to create the state machine at the end here where it says save definition is when we're able to save and therefore execute the state machine so first a developer would have to navigate to the step functions web console so they probably open up a new browser tab and go to console.aws.amazon.com next they need to select the state machine and service specifically once they do that they can navigate through the state machine specific page on until they come across the select create state machine button once they go through here they can start providing their asl or amazon states language definition providing the asl can take several minutes for a developer that is familiar with the language and knows exactly what they want to create so for a developer who's not familiar with asl this step would take hours which is something that all three of us experienced firsthand so the developer finished giving that asl definition and now we can move on to the next step which is just a few final tweaks of this definition maybe changing the retry back off rate after that we click the save definition button and all is well or so we think it turns out that in the aws console you actually cannot create the state machine definition without first providing valid arn's or resource names for each lambda in the state machine so we're going to take a look here at step number six a little bit closer and create all these lambdas first so then we can go back over to the browser tab that is just hanging open with the state machine definition unsaved and provides those ar ends so these are the steps required to create a single lambda in the aws console this diagram represents all five of them at the end is the copy slash paste arn box which represents the act of cocking the resource name of the lambda and then providing it to the state machine definition that's in the other tab so first to create a lambda one must navigate to the lambda console similar to the state machine they must then configure the lambda giving the name configuring the wrong time and working out the permissions to give the land up after that the developer provides the lambda's definition which is a non-trivial task after the lab has been defined uh it can then be saved and then once the slander is saved we can retrieve that arn copy it and then paste it and supply it to the state machine definition it's important to realize here though that these are just the steps for creating one lambda we still have three more lambdas that we still need to create and go through all these steps for which is starting to become tedious and if say you had 10 or even 20 lambdas things will quickly start to get out of hand so once we finish creating all the lambdas in our workflow we can go back over to the state machine tab and finish providing uh that definition and finish it up so here the next step once we paste those ar ends over is to just do some last little configuration with the state machine with names tags logs and permissions once those are provided we can then save the definition and now finally the state machine is ready to be executed so that's what it looks like to create all these resources but what does it look like to tear things down well similar to creating these resources we would first need to navigate to the specific service in the aws console do a little bit of clicking around and then finally this is where it starts to get a little bit different we select a specific resource so an individual lambda or an individual state machine we click on a drop down menu which will provide us the option to delete the lambda or state machine and then a confirmation modal will pop up which we can then confirm the deletion of and we can start to delete these resources one at a time it is important to note here that it's not necessarily really hard to do this but it's very tedious because we have to do it for each individual lambda as well as a state machine and just the tedium of clicking around in the console could uh cause the developer to kind of so now and maybe make a wrong selection and delete the wrong lambda which is an irrecoverable mistake so uh as i kind of highlighted before there are a few problems with this approach of creating the resources in the console first of all it's very tedious there's a lot of just pointing and clicking pointing and clicking through the web interface it's also rather unintuitive in the sense that the lambdas have to be created first before the orchestration layer around them this requires us to our working the console requires us to work with multiple interfaces we have a tab open for the state machine another one open for the lambdas if we want to manually configure the permissions and roles another tab open for that and because of all of this it is very slow to create and to delete these resources just for creation there are 28 manual steps required to go through the console of for example pointing and clicking and for deletion there's 30 of them those two combined makes it very difficult to rapidly iterate upon our workflow so this is actually where my stroke comes in you've heard us all mention it and i think it's time to take a good look at maestro so maestro what is it well maestro is a framework for building deploying and iterating with step functions on a local development machine maestro is open source it runs on node.js and it's actually available as a published npm package it's quite easy to use it only has a few simple commands in this toolbox each of them having some inline help and we've got good documentation for each of those commands meister allows for fast deploys of whole workflows in about three seconds and it can tear down those same workflows in about two seconds allowing the developer to focus more on the business logic and rapidly iterate upon their application so let's take a look at what it's like to deploy this same example workflow we've been talking about but instead of using the console this time using maestro so first uh you create a new maestro project just with that single command there after that you can optionally modify the project template that is given to you which i will discuss a little bit more later and then once that's you've made your final tweaks you can just deploy up to aws with the maestro deploy command and at that point it has been successfully deployed by maestro and is able to be executed contrast this to the great time and tedium required to deploy manually using the aws console this is quite a stark difference so let's just take one more look at maestro actually being used now to really help drive home this point so first we have a terminal here and we can create a new maestro project just with this command it prompts us for a template to base our project off of which we can do so and if you see here that uh the format of a basic meister project um looks like this with the lambdas and the state machine definition once we tweak the definition we can deploy it with a single command and three seconds later all of these resources are up here in the aws console we can take a look at it a little bit closer you can see that's the same definition and it's actually able to be executed as well to tear down it's also as simple as just a single command two seconds later it's torn down and as you saw all of those resources are no longer shown in the console so let's take a look a little look at maestro kind of under the hood looking at the core of it and different commands that you can use so maestro uses templates to help you as a developer bootstrap your new projects really quickly this is my show's solution to the tedious overhead of manually writing the asl you can create your own templates actually to reuse if you have a common workflow that you use a lot and you can actually share it with other people as well and it's worth mentioning the meister provides eight official templates out of the box and if you see on the right that's just an example of one of the template state machine definitions that maestro provides the maestro new command is used to create a new maestro project based off of a template it allows the developer to really work locally just through their one interface in the terminal so you no longer have to point and click through the aws console and because this allows you to create a new project based off of template it reduces the overhead of manually creating your own asl the deploy command deploys a whole master project really quickly uh again just locally on your machine and just through the terminal so just this one interface instead of the multiple web interfaces of the console and it's really quick sort of about three seconds to deploy um contrast this to aws sam which is a framework that zach discussed earlier which it takes about three minutes to deploy so this is maestro is 60 times faster this really allows for the rapid iteration on your workflows and last here for the core part of maestro is the maestro teardown command that deletes a project really quickly it's like deployed but in reverse order and again since it takes about two seconds to turn down the project it allows for the rapid iteration because you can just tear down and deploy with a new change and just focus on working on your business logic so we recognize that maestro also has a few limitations we don't pretend that maestro is a one-size-fits-all solution right now my show only supports a single language runtime and your deployed lambdas which is no to js 12.x currently in the maestro deployer and tear down only supports lambdas and step functions there's no native support for the other aws services so you will have to manage the deployment and tear down on those yourself and maestro isn't super configurable on a per project basis so i'm just going to walk you through a few challenges that we the maestro team encountered while building maestro the first category here is dealing with aws iam for identity and access management which is the aws service for managing roles permissions and policies so to be able to use a role for a lambda and this role to be able to use a newly created role rather for lambda you have to wait for it to fully propagate to all of aws data centers which was an issue that we encountered another issue or challenge rather was determining what roles permissions and policies to give the state machine and get rich lambda and more generally we ran into some challenges regarding reconciling asynchronicity and concurrency in order to have a rapidly or just a really fast deployer that's also very stable and uh last note here maestro is working in a niche ecosystem there's not very many frameworks in this space to deal with step functions specifically and because of this we often had to blaze our own trail so we're in continual development here at maestro and there's some items of future work for us to do uh one that i'd like to point out is right now we would like to support officially other aws services like dynamo db sqs ec2 ecs and more so that the deployer and also the undeployer of maestro will be able to handle those natively and just so you are all aware this is the maestro team and thank you guys very much for coming if you have any questions we can start taking those now so it looks like we've got a question regarding uh how we dealt with the resource dependencies uh during deployment with aws and uh you know it's kind of a broad answer i think you know again just to note that in order to uh deploy our our example works flow for example really there's three services involved it's the step functions the lambda and iam so in order to deal with uh deploying to you know the step functions and lambda services both of those are dependent on iem so in order to deploy to aws we had to make sure that we had a good understanding of which roles would avail us of being able to actually create those step functions and lambda first and that was the first challenge there that john mentioned a little bit something that we didn't recognize and this kind of goes back to the idea of not having a unified log is that even though the sdk gives you a facility of being able to tell when your iem role is created which has to be created first to then create the other services when you send the re request to verify the existence of that iem role that does not mean that you can go ahead and create these other services because as john was saying previously there's no problem there's really no way appearing into whether or not that iem role has propagated the other services so that's where we actually had to build some retry for our business logic which was able to basically retry with a specific back off rate that we kind of figured out through a little bit of trial and error to determine when the roles had propagated to the different services so as far as dependencies really those were the only three concerns we knew we had to reconcile the first two there wasn't much clarity in working with iam so it was just a matter of trial and error to understand you know which dependencies were required and so then we basically took a composite of the policies and permissions uh that are applied on the roles we use and use that for the other other workflows that we provided as templates i'm not sure if that was exactly the type of answer for that question you were looking for you can provide more uh specific questions uh to to that question of a subsequent one if that didn't answer i really appreciate those thoughtful questions though definitely appreciate the everyone who's come out today and don't don't be shy if there is anything regarding the presentation or uh the subject serverless in general that one's curious about again it's a somewhat of a new environment to be programming in so there are many working developers who have many years of experience for whom some of the subjects are a bit unfamiliar as well but don't be shy yeah and this is zach i i just wanted to point out that cornell had a comment saying so lambdas and step functions work together it's not that step functions replace lambdas and and that's right really kind of the goal of step functions is to help abstract out logic orchestration logic that would otherwise you would have to choreograph into your your lambdas which is really just a single function that you're wanting to you know keep separated from other concerns and that's where you want your business logic to live i have another question here regarding you know the terminology versus orchestration versus choreography and really that is it's a good question because again in a new field um there's a lot of completion of terms as we mentioned from the beginning even fast and serverless are conflated and that's kind of at the very top we did rely on some resources where we saw the term orchestration really referring to the the coordination of services in a workflow one kind of paramount uh that that comes to mind is uh in our write-up which will be made available shortly but uh really it mapped out the um uh common patterns of orcas some common patterns of orchestration which really have heavily rely on lambda but beyond that there's actually some research papers uh there's two or three academic papers in this area and our write-up specifies that a little bit more as well that actually dive into the fact that there's not really many best practices and so the term that it uses is orchestration and then it goes goes on to really clarify about 20 different patterns under those five different uh areas that we consider at the beginning availability communication uh event management so forth and so we were actually relying uh not on not on i guess a broadly established you know best practices in the area but some of the academic learnings that speak about the orchestration using that term orchestration and not choreography yeah i'll just add real quick another helpful resource um for serverless in general um is a podcast called serverlesschats uh by jeremy daly and he's an aws serverless hero and yeah there was a lot of helpful helpful information on there in one particular episode he talked about orchestration versus choreography and kind of what's what's going on there um it looks like we've got another um question here in the q and a the question is did you consider any cloud providers other than aws why or why not so actually we did consider some uh other providers but we actually ended up using aws because the field that we were working in orchestrating um like serverless functions or functions as a service aws was by far the leader in that field with the aws lambda so we decided to stick with aws mainly for that reason and there are you know other cloud providers have similar offerings as step functions for instance microsoft's azure has a service called durable functions which is similar to step functions um and so like like john said aws is the prominent provider and so we chose to go aws so we don't support any other cloud providers and actually on top of that another company made an internal tool netflix made one called conductor that also is kind of a mirror of step function so even though we only consider step functions here some of the same patterns are found in these other services so if uh you know this uh discussion and what meister does makes sense one can delve into some of these other services and find some some other similar patterns if not a similar framework which likely does not exist well it seems that that's all the questions uh i just really appreciate everybody um listening to our talk about maestro um it's been a really fun uh past few months going through capstone and um we really appreciate it yeah thanks again for your support everybody take care 