# Canopy: An Open-Source Monitoring Framework for Content Delivery Networks

## ELI5 (Explain it Like I'm 5)
Canopy is a system created by a group of coders to help understand what's happening inside servers that deliver website content (like videos or pictures) to people around the world. It's like a teacher in a playground watching lots of kids play to make sure everything runs smoothly. It collects and analyses different types of data to alert if something is going wrong, ensuring that people can view website content quickly and without problems. 

## Specific Tools:

- **Cloud Services**: Amazon Web Services (AWS), AWS Kinesis Data Streams, AWS Kinesis Firehose, AWS Lambda, AWS Simple Queue Service (SQS), Amazon Elastic Container Service (ECS), Amazon EC2 (Elastic Compute Cloud), Amazon S3 (Simple Storage Service)
- **Databases**: ClickHouse, SQLite
- **Networking**: CloudFront Content Delivery Network (CDN)
- **Other Technologies**:  Docker (for local deployment), Vector (for data piping), Grafana (for data visualization), React (UI for the dashboard), Express (backend server)

## Detailed Project Explanation

Canopy is an open-source real-time monitoring framework designed for Content Delivery Networks (CDNs). It provides a data pipeline that simplifies the process of observing the health of a CDN.

### Background

Content Delivery Networks (CDNs) are a network of servers primarily responsible for reducing latency (time delay) and load on company servers. They serve the requested data from locations closer to the user. Monitoring these network servers is crucial in identifying system trends and overall health, which is done by collecting and analyzing two types of digitized data, logs, and metrics.

### Problem 

Due to the distributed nature of CDNs, monitoring them is often a challenge, particularly understanding large amounts of emitted log data. Log data gets complicated due to the bursty nature of internet traffic, the need for real-time analysis, and the need for the right storage solution.

### Existing Solutions & Importance of Canopy

Existing monitoring solutions for CDNs (like native CDN reports or SAS solutions) either lack integrations, do not meet data ownership requirements, or demand significant developmental effort. Canopy addresses these problems by providing a customizable open-source solution that offers real-time dashboards, automated deployment and seamless data flow, and complete control over data within the team's AWS account. 

### Architecture

Canopy's architecture consists of three stages: 

1. **Emitting**: The CDN emits logs which are prepared for shipment in the logging pipeline.
2. **Shipping**: Log data is collected, transformed, and stored. This involves stream storage and log transformers.
3. **Presentation**: Log data is queried, visualized, and analyzed through a user interface.

During the development process, several challenges were resolved, including efficient data storage and real-time data transfer. ClickHouse (a columnar database) was used for data storage, and AWS Kinesis Data Streams and Firehose were used for reliable data transfer.

### Advancements and Final Architecture

After successful prototype creation, enhancements were made including support for monitoring multiple CloudFront distributions in parallel and creation of an admin dashboard for efficient pipeline management. Also, AWS Lambda was introduced for better control over log buffering and errors.

Additionally, they built a contingency pipeline for handling failed log data. This pipeline, called the Dead Letter Queue, ensures failed logs are archival for debugging and compliance purposes.  

### Future Scope

Despite the success of the project, improvements in terms of custom transformations, enrichments for logged records, improved customization options for quick alerts, and additional configuration options for ClickHouse and EC2 instances can be incorporated in the future.

## Q&A Session

During the Q&A session, the most challenging aspect of building Canopy was identified as dealing with AWS SDK inconsistencies. The name 'Canopy' was chosen because it represents the monitoring pipeline's role as an interface between the cloud and the user's system. The project aimed to showcase diverse skills, including web development, AWS, and data handling. ClickHouse was chosen as a database for its speed and efficiency in handling aggregates. Potential external threats to Canopy are high load performance, service disruption, and competition from other solutions.

Constructive questions and feedback from attendees were handled with insight and gratitude, providing essential context on the journey of building Canopy, the challenges encountered, and the joy of successful teamwork.