In this video, we will discuss our experience building Canopy, an open-source real-time monitoring framework specifically designed for Content Delivery Networks (CDNs). We'll start by providing some background on CDNs and monitoring. Then, we'll talk about the existing solutions in the CDN monitoring space prior to Canopy. Next, we'll delve into the process of building our prototype, and finally, we'll wrap up by outlining the improvements made to the prototype and our final architecture. 

Before diving into the details of how Canopy works, let's review some basic concepts related to CDNs and monitoring. A CDN, or Content Delivery Network, is a network of servers distributed geographically that stores cached versions of web content, such as HTML pages, images, and videos, at locations closer to end users. CDNs offer two major benefits for web applications. The first is the reduction of latency. When users request data from a server, their response time can vary based on the distance between them and the server. CDNs address this issue by serving the user's request from the edge location closest to them, reducing the distance the data needs to travel and providing a faster experience. The second benefit is the reduced load on a company's web servers, also known as origin servers. With CDNs, requests can be fulfilled by the CDN itself, relieving the burden on the origin server. 

So, why is monitoring important for CDNs? Monitoring involves collecting, processing, aggregating, and displaying real-time quantitative data about a system. It allows developers and system administrators to identify trends and gain insights into the health of the system. In order to monitor a system, we need telemetry data. Telemetry data is the data emitted by production systems to provide feedback about what's happening inside the system. In the context of software engineering, the two main types of telemetry data are logs and metrics. Logs are timestamped records of events that occur within a software system, and they provide detailed information about individual events. Metrics, on the other hand, are numerical representations of data and offer a high-level view of the system's overall health. 

To effectively monitor a CDN, we need to collect and analyze both logs and metrics. Logs provide valuable insights into individual events, while metrics offer a broader understanding of the system's performance over time. Google has identified four key monitoring signals for CDNs: latency, errors, traffic, and saturation. These signals help monitoring teams gain a comprehensive understanding of what is happening in the production systems of CDNs. 

Due to the distributed nature of CDNs, they often remain a black box for many companies. The physical infrastructure of a CDN is operated by third parties and is largely outside of our control. Monitoring the logs generated from CDN traffic is one of the few ways to gain observability into the system. However, building a monitoring solution for CDNs presents several challenges. 

One of the primary challenges is the sheer volume of log data that CDNs emit. CDNs handle a massive amount of web traffic, which results in a substantial amount of log data. For example, even a medium-sized company like Love Holidays, an online travel agency, may handle over 30 gigabytes of CDN logs per day. This poses a significant challenge for engineering teams, as they need to handle and process this large volume of data effectively. 

In addition to the data volume, there are other technical challenges when building a logging pipeline for CDN data. One challenge is the bursty nature of internet traffic. CDNs experience bursts of traffic, similar to rush hours at a train station, and the logging pipeline must be able to handle these bursts without slowing down or becoming overwhelmed. Another challenge is efficiently querying and visualizing the log data. Analyzing large datasets and performing mathematical operations in real-time can be slow and expensive. 

Furthermore, choosing the right storage solution for CDN logs is critical. A suitable storage solution should be able to handle the entire log data set efficiently and support fast insertions for batch log data. Effective data compression is also essential to reduce storage requirements. Lastly, the chosen solution should align with the specific needs of the team, considering factors like data ownership, ease of use, and cost. 

When it comes to existing monitoring solutions for CDNs, teams have several options. The CDN's native solution, such as the reports and analytics page provided by CloudFront, is easy to use but lacks integration with other observability data sources and customizable dashboards. Alternatively, teams can opt for a SAS (Software as a Service) solution like Datadog or New Relic. SAS solutions provide ease of use, integration capabilities, and customizable dashboards. However, they may not meet strict data ownership requirements and can be expensive. Lastly, teams can choose to build their own DIY solution, which offers full control over data and potentially robust features. However, building a DIY solution requires significant development effort and is not as user-friendly. 

Canopy aims to bridge the gap between ease of use and data ownership by providing a customizable open-source solution. It offers real-time dashboards, automated deployment, and complete control over data within the team's own AWS account. Deploying Canopy is a straightforward process, requiring minimal configuration, and the Grafana dashboards provide comprehensive visualizations of the CDN data, aligned with the four golden signals. The admin dashboard also allows teams to efficiently manage the pipeline infrastructure configuration and monitor its status. Quick alerts can be configured with a single click to notify teams when certain thresholds related to the golden signals are met. 

The core architecture of Canopy consists of three stages: emitting, shipping, and presentation. The emitting stage involves accepting and preparing data from production systems for shipment in the logging pipeline. The shipping stage includes collecting, transforming, and storing the log data using components such as stream storage, log transformers, and log shippers. Finally, the presentation stage is where the log data is queried, visualized, and analyzed through a user interface. 

Building the prototype of Canopy presented various challenges, and one of the most prominent ones was data storage. Due to the unique requirements of CDN log data, efficient data aggregation and the ability to store every log line were crucial. After careful consideration, we chose ClickHouse, a columnar database, as our storage solution. ClickHouse's sparse indexing and column-oriented approach proved advantageous for aggregating metrics over time. 

Another challenge was moving the log data from the CDN to our storage solution in real-time. We leveraged AWS Kinesis Data Streams and AWS Kinesis Firehose as managed services for collecting, storing, and delivering the logs. These services ensured a reliable and efficient data transfer process. 

In conclusion, Canopy provides an open-source, customizable monitoring solution for CDNs. Its architecture addresses the challenges of data volume, query efficiency, and storage requirements. With Canopy, teams can gain observability into their CDN's performance, analyze the four golden signals, and make data-driven decisions for improving system health and user experience. We needed to create a logging pipeline with three stages: emitting, shipping, and presentation. We decided to build a system called Canopy. In the emitting stage, the CDN emits a continuous flow of logs as users make requests. The shipping stage involves collection, transformation, and storage. For collection, we needed a way to collect and store logs in real-time. For the transformation, we required a log transformer to convert the logs into a suitable format for storage. And for storage, we recognized the need for a log shipper to buffer and batch the transformed logs in a database.

In the presentation stage, the visualizer queries the data stored in the database and displays the results in real-time using charts, graphs, and tables. We mapped out the core components for each stage and proceeded to build a working prototype based on this architecture. During the prototyping process, we encountered several challenges.

The first major challenge was deciding on a database for storing the log data. We considered Elasticsearch, timescale, and clickhouse. Due to the unique requirements of our use case, particularly the need to efficiently handle data aggregates and avoid sampling, we ultimately chose clickhouse. Its sparse indexing and column-oriented approach were well-suited for aggregating multiple metrics over time.

The next challenge was how to move log data from the CDN to clickhouse in real-time. We needed stream storage, a log transformer, and a log shipper. We considered building an application to read data from Kinesis data streams, process it, and deliver it to the next destination. However, prioritizing development speed and reliability, we chose AWS Kinesis Firehose. It provided near real-time delivery of logs and any failed logs were sent to AWS S3 for storage.

For the log transformer and log shipper, instead of building these components from scratch, we decided to use Vector. It was compatible with both Kinesis Firehose and clickhouse, making it a convenient choice as a data pipe between the two. Vector could also handle log transformation, fulfilling both functions.

We then focused on the nitty-gritty of data transformation, specifically how to transform Cloudfront logs before loading them into the database. With Vector's log transformer, we used a custom regex pattern to convert plain text logs into structured JSON objects. This pattern mapped field names to their corresponding values in the logs and converted values to the appropriate data types.

After successfully addressing these challenges and developing a working prototype on our local computer, we wanted to make Canopy easily accessible for anyone to set up and use in the cloud. With AWS Kinesis Data Streams and Firehose, we could create these resources directly. For other components like Vector, clickhouse, and grafana, we needed to figure out their deployment.

To deploy Canopy locally, we chose Docker as our solution. We containerized the backend components and deployed them as containers on a host. Docker's built-in data persistence and service discovery allowed for automatic communication between containers and ensured that data in the database and dashboards in grafana would persist.

Once we successfully deployed the Canopy backend locally, we moved on to deploying it to the cloud. We had two options: Amazon EC2 and Amazon Elastic Container Service (ECS) with Fargate. EC2 involved running a virtual private server and deploying Docker containers within it, mimicking a local deployment. ECS and Fargate were fully managed services that removed the need for manual container management and scaling. For simplicity, we chose EC2 and continued deploying Docker containers on it.

With a working prototype and a deployed backend, we focused on improving the core pipeline. Two key goals were ease of use and real-time dashboard updates. Our initial prototype used AWS Kinesis Firehose for data delivery, but it had limitations that affected these goals. The complexity of configuring HTTPS connections and the 60-second buffering introduced unwanted latency.

To address these limitations, we built a custom log transformer and shipper using AWS Lambda. This simplified the architecture, eliminated the need for Vector and Firehose, and provided greater control over log buffering. Logs could be shipped over HTTP or HTTPS to an external endpoint, and errors were recorded for easier debugging.

However, this approach required us to handle failed logs ourselves. We used Kinesis Data Streams as a buffer for failed logs, allowing for retries until a key limit was reached before sending them to S3 for persistent storage. We also created a separate pipeline for handling failed log data, composed of a dead-letter queue managed by AWS Simple Queue Service and a Lambda function that pushed the failed logs to S3.

To further enhance the user experience, we introduced support for monitoring multiple Cloudfront distributions in parallel and created an admin dashboard for pipeline management. We consolidated log data from different distributions into a single pipeline, simplifying infrastructure and improving maintainability. The admin dashboard included metrics from Clickhouse and Grafana, as well as a list of configured Cloudfront distributions.

In conclusion, with the final architecture, Canopy provided a logging pipeline with seamless data flow, efficient storage, real-time visualization, and improved ease of use. The custom log transformer and shipper, along with the admin dashboard, offered better control, monitoring, and management capabilities. Canopy's core components functioned cohesively, enabling users to easily set up and utilize the platform for their logging needs. In order to address the issue of persistent storage after a certain number of free tries, we implemented a separate pipeline for handling failed log data. This pipeline consists of a dead letter queue (DLQ) managed by AWS Simple Queue Service and a Lambda function that pushes failed logs to Amazon S3 for persistent storage. When a batch of logs fails after multiple retries, Genesis Data Streams pushes the failed logs to the DLQ. The Lambda function then reads from the DLQ, stores the failed logs in S3, and clears them from the queue asynchronously. Although this approach introduced additional complexity, it ensured that the failed logs would be archived for debugging and compliance purposes, supporting our core use case. This improved architecture not only offered our users a more accurate real-time monitoring experience but also simplified deployment, while still accounting for network failures.

With the core pipeline elements in place, we turned our attention to quality-of-life improvements. One of these improvements was adding support for monitoring multiple CloudFront distributions in parallel. Developers often have multiple CloudFront distributions in a single AWS account, with different settings for different domains and web applications. To accommodate these users, we introduced native support for handling multiple parallel distributions within Canopy. Instead of duplicating pipeline components for each distribution, we consolidated log data from different CloudFront distributions into the same pipeline. This decision was made to reduce costs and complexity. Ingesting logs for multiple distributions into a single pipeline proved to be simpler and more maintainable.

Another improvement we made was building a custom admin dashboard for pipeline management. We adopted a three-tier architecture, consisting of a presentation layer, an application tier, and a data tier. The presentation layer is a React UI that communicates with an Express backend server, which in turn communicates with an app server and SQLite for storage. The admin dashboard collects and presents metrics from ClickHouse and Grafana instances, allowing users to monitor the health of their deployed pipeline infrastructure. It also displays a list of configured CloudFront distributions, with the data stored in an SQLite database. This capability provides users with a seamless way to track and manage their various distributions.

Now, let's discuss the final architecture. The diagram below outlines the flow of logs through Canopy's log pipeline. First, one or more CloudFront CDN instances emit log data, which is ingested into our pipeline via AWS Kinesis Data Streams. On the left side of the pipeline, the logs are parsed and transformed by AWS Lambda before being shipped to ClickHouse. Grafana visualizes the logs stored in ClickHouse and sends email alerts to users when metrics reach certain thresholds. On the right side of the pipeline, failed logs are processed by the Failed Logs Pipeline and stored in S3. 

In conclusion, building Canopy was a challenging endeavor. It involved complex research, careful planning, debugging, and testing. However, we successfully achieved our objective of building an easy-to-use, fully automated, real-time log pipeline for CDN data. While there is always room for improvement, we are proud of what we have accomplished. In future iterations of Canopy, we hope to incorporate features such as custom transformations and enrichments for logged records, improved customization options for quick alerts, and additional configuration options for ClickHouse and EC2 instances. We are excited to continue our work and make Canopy even better.

Now, let's move on to our Q&A session. Thank you all for attending. Please feel free to write your questions in the comments area, and we will do our best to answer them. While we wait for your questions, let's start the discussion by addressing one of our frequently asked questions: What was the most challenging aspect of building Canopy? Matt, our team member, will share his thoughts.

Regarding the most challenging aspect of building Canopy, Matt explained that dealing with AWS SDKs and their inconsistencies was a significant challenge. There were inconsistencies we encountered while trying to automate the deployment pipeline for Canopy. If there is interest, Matt can provide further details on this topic.

Now, let's move on to another question from Fred Durham: How did you come up with the name "Canopy"? Michael, another team member, will answer this question. 

Michael explained that the team spent a considerable amount of time brainstorming for the best name for the project. They wanted a name that conveyed the idea of Canopy being the interface between the cloud and the forest below, similar to the interface between a rainforest canopy and the forest floor. The name "Canopy" represents the monitoring pipeline's role as the interface between the cloud and the user's architecture, providing a high-level view of the system below. 

We have another question from Anthony Alexander: What made you choose this project over other project ideas in the context of showcasing your skills to potential employers? Jason or Alex, would you like to answer this question?

Jason answered that this project was chosen because it covered various interesting areas that showcased their skills as developers. It involved web development, creating an application with a React front-end and an Express backend. They also had to figure out how to integrate different tools into a coherent framework. Additionally, the deployment process provided an opportunity to learn about containerization and deployment options in AWS. Overall, the project demonstrated their ability to handle different aspects of development and problem-solving.

Moving on to the next question from an anonymous attendee: Can you provide more detail about your database decision? Alex, another team member, will answer this question.

Alex explained that choosing the right database was crucial for their data-focused project. They decided to use ClickHouse, a columnar database, for several reasons. One of the primary reasons is ClickHouse's ability to quickly run data aggregate queries. The columnar storage format allows for efficient data retrieval and analysis. Furthermore, ClickHouse is a popular choice among CDN monitoring companies, such as Cloudflare, which inspired their decision. The team believed that ClickHouse was the optimal choice to efficiently process and visualize the log data in their pipeline.

We have another question from Vincent: What are the biggest external threats to Canopy's core service? In other words, what could potentially render Canopy useless? Nabil, a participant in the webinar chat, asks for elaboration on the SWOT analysis perspective. Could you explain what you mean by SWOT, Nabil? We'll address your question once we have clarification.

While we wait, we have another question from Shosuke Ihara: What part of the project was the most enjoyable to work on? Alex, as the team member who hasn't had a chance to answer yet, would you like to share your thoughts on this?

Alex expressed that he enjoyed collaborating with his team members the most throughout the project. Working with the team, mentor, and Launch School staff was a terrific experience. He emphasized the importance of teamwork and how it allows one to achieve much more than working alone.

Okay, now let's discuss the external threats to Canopy's core service. In the context of a SWOT analysis, the team considered several potential threats to Canopy's success. One potential threat is the performance of the logging pipeline under high load. While they implemented stress testing with their "Request Monster" program, there is still room for further optimization to ensure all visualizations function as intended. This threat could impact the real-time monitoring experience and the overall usefulness of the pipeline.

Additionally, Canopy relies on AWS services, and any disruptions or issues with these services could potentially render Canopy temporarily unusable. However, the team chose AWS services, taking into account their high availability and reliability. They also included measures in their architecture, such as the DLQ and S3 storage, to mitigate the impact of temporary failures.

Another external threat is the emergence of competing solutions. While Canopy offers unique advantages, such as improved real-time dashboard updates and customization options, competitors in the CDN monitoring market may develop similar or better solutions.

In conclusion, the team recognizes these potential threats and is committed to continually improving and optimizing Canopy. By actively working on load testing, staying updated with AWS service changes, and striving for innovation, they aim to ensure Canopy remains a robust and valuable solution for their users.

Unfortunately, we haven't received any clarification regarding the SWOT analysis question from Nabil. If you have any additional questions or need further clarification, please feel free to ask in the comment section. We're here to address all inquiries.

Wow, time flies! We're really grateful for all the positive feedback and congratulations from the attendees. Great job to all the other Capstone grads and students as well. Keep up the hard work! It’s been a pleasure presenting our project to you all. Thank you for joining us today. During the presentation, Nabil discussed the importance of teamwork, explaining that together, we can achieve much more than we can alone. He then proceeded to elaborate on the strengths, weaknesses, opportunities, and threats of our project. As we delved deeper into the topic, we discussed how using Lambda had its advantages, specifically in terms of debugging. Lambda made it easier to identify and rectify issues such as incorrect log data insertion or incorrectly formatted requests. However, we acknowledged that there is room for improvement when it comes to load testing our pipeline. While we did test it to a certain extent by creating a testing program called "request monster" that sent numerous requests to hit the CDN, generating logs that entered our pipeline, we realized that we could optimize and test it further under heavier loads to ensure that our visualizations function as intended.

Moving on, one of the questions raised by Vincent in the webinar chat was regarding the new technologies or skills we had to acquire for this project. It was an excellent question, as this project exposed us to a wide range of interesting technologies and skills. None of us had previously worked with a colnar database, and while we had experience with SQL and writing queries with PostgreSQL, working with colnar data databases presented new challenges. Additionally, most of us had limited experience with AWS, so Jason and Med dedicated a significant amount of time to learning and familiarizing themselves with AWS to complete this project successfully.

Shifting gears, our project mentor, Rodney, inquired about our overall journey throughout the Capstone project. Looking back, we can confidently say that it was a long and challenging journey. However, the experience was undoubtedly worth it. It was fascinating to face such a significant challenge and witness how the project evolved and transformed over time, as mentioned by Jason and Matt. We made decisions along the way, such as relieving the user from maintaining their HTTPS certificate, which altered the course of the project. Being part of these discussions and witnessing the project's transformation was truly remarkable, making this journey a memorable one.

Nabil raised another intriguing question, asking if we were aware of any services or new technologies that could potentially replace our project, Canopy, in the short term. We designed our project specifically for the AWS CloudFront CDN, as existing monitoring solutions provided by the CDN provider itself were not as robust for real-time blog monitoring. While AWS lacks native real-time monitoring services for CloudFront, there are a few third-party SAS solutions available, such as Datadog and New Relic. However, there appears to be a gap in the market for open-source automated deployment solutions tailored to CloudFront specifically. As Nabil mentioned, our focus was primarily on tackling the engineering challenges, rather than commercializing the project.

In terms of what we would have done differently now that we have completed the project, everyone had different perspectives. For some, there was nothing they would change, as the Capstone staff did a fantastic job organizing the program, and the learning process was a valuable experience. Others, like Jason and Med, who invested significant time grappling with AWS documentation, might have preferred to avoid that particular challenge. However, overall, everyone agreed that the journey was rewarding, and we acquired a plethora of new skills and knowledge.

Finally, we expressed our gratitude to the attendees for their participation, outstanding questions, and insightful discussion. It was a surprise to see the abundance of questions, all of which were excellent. We thanked everyone for their time, wished them a fantastic weekend, and concluded the presentation.