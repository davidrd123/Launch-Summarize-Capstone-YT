Welcome everyone! Thank you for joining us for today's webinar. My colleagues and I are excited to introduce Signant, an open-source contract testing framework for microservices. I'm Zach, and joining me today are Michael, Fernando, and Eric. Over the past few months, we have collaborated remotely to create Signant. 

In this presentation, we will start by discussing the problem domain that led us to develop Signant. We'll provide context for what microservices are and explain why they present challenges for testing. Then, we will introduce contract testing and explore the existing solutions in this space. Finally, we'll dive into Signant's approach to these challenges, discussing the tradeoffs and design decisions we made during its development. We'll also reserve some time at the end for Q&A. 

Let's begin by exploring the difference between monolithic and microservice architectures. In a monolith, all server-side logic is deployed together as a single unit. Each business domain, such as shopping cart, users, and payments, is represented by a programming construct, typically a Ruby class. The objects instantiated from these classes run in a single process and interact with each other through in-memory method calls.

On the other hand, in a microservice architecture, each business domain is represented by a standalone service that can be deployed independently. Services interact with each other by passing messages over the network. For example, the shopping cart service can access the functionality of the user service by making an API call over HTTP. While microservices allow multiple engineers to work on different parts of the application simultaneously, they also require a more complex infrastructure compared to monoliths.

In order for businesses to choose microservices over monoliths, there are two key characteristics they aim to maximize. The first is limited ownership, which means that each team of engineers only needs to understand how their own services are implemented. They don't need to know the internal details of other services. This limited scope allows teams to build new features quickly. The second characteristic is independent deployability, which means that each service can be updated and redeployed independently of others. This flexibility allows for rapid development and deployment cycles.

However, while microservices offer these benefits in terms of development and deployment, they also pose challenges when it comes to testing. Traditional automated software testing can be classified using a pyramid structure. At the base of the pyramid, there are lightweight unit tests that verify individual components in isolation. Above that, there are integration tests that verify multiple components working together. Finally, at the top of the pyramid, there are end-to-end tests that simulate the entire application.

While tests at the top of the pyramid provide the highest level of confidence in the app's quality, they are more time-consuming and resource-intensive. Therefore, many companies sequence their tests in a specific order, with unit tests running first, followed by integration tests, and finally end-to-end tests. This sequencing allows for quicker feedback and greater confidence in the software quality as it progresses through the testing pipeline.

For monolithic architectures, it is common to run integration and end-to-end tests before every new deployment. However, microservices present unique challenges for running these tests with every service deployment. Integration tests, for example, require the conser team to know specific details about the provider service, such as how to set up its stateful data, configure and deploy it, and handle external dependencies. This goes against the idea of limited ownership.

One solution to this problem is using a service test, where a test double is used instead of the real service. The test double provides a canned response when requested, saving the conser team from having to run the actual provider service. However, maintaining the test double to accurately mimic the behavior of the real service can be challenging. This is where contract testing comes in.

Contract testing focuses on the compatibility of interfaces between services, rather than testing their integration as a whole. It uses a contract, which formally describes the interactions between services, to generate and verify the expected HTTP requests and responses. In a basic form of contract testing, the contract is read by a tool, which replays the requests against a live service and compares the actual responses to the expected ones. If they match, the test passes; otherwise, it fails, indicating that the services will not integrate correctly.

Contract tests offer several advantages. They are faster and less resource-intensive than traditional integration tests, allowing developers to identify bugs earlier in the process and accelerating the feedback loop. Contract tests also run in isolation, reducing the need to deploy multiple services together for testing. They provide specific information about any missing or malformed messages, aiding in debugging. However, it's important to note that contract tests should supplement, not replace, end-to-end tests, as they focus on interface compatibility rather than overall system behavior.

When considering a contract testing solution, there are several factors to weigh. First and foremost, it's crucial to evaluate which testing approaches the solution supports: conser-driven, provider-driven, or spec-driven. For independent deployability, we prioritized a spec-driven approach. After researching various options, we narrowed our search down to Pactflow and Specmatic, the two prominent options that offered a spec-driven approach.

Another important consideration is the ease of adoption of the testing solution. Some solutions may require writing many new tests to achieve sufficient interface coverage, which may slow down development. With these factors in mind, we developed Signant, which we will now discuss in more detail. I'll now hand it over to Michael to delve deeper into the concept of contract testing. In service classification, it is common to designate one service as the "conser" and the other as the "provider". A conser service relies on functionality or data from a provider service. It's important to note that these labels only apply within the context of a specific integration. A service can be a conser in one pairing and a provider in another. Now that we understand these terms, let's examine different approaches.

The conser-driven model represents the current implementation of the conser. The contract describes the specific parts of the API being used by the conser. However, this approach does not offer independent deployability. The conser team must wait for the provider team to pull down the contract, set up their service, and verify compatibility.

The provider-driven model is the reverse of the conser-driven model. The contract represents the implementation of the provider service. This approach allows the provider team to have control over the integration. It is particularly useful when there are a large number of consers, as negotiating individual APIs would be impractical.

The spec-driven approach involves defining the API spec separately from the implementation of both services. This allows each service to be developed and tested in parallel, without depending on completed implementations of the other service. It aligns well with spec-first API design practices. This approach enables independent development and testing.

When choosing a contract testing solution, several factors should be considered. Firstly, which testing approach does the solution support? Options include conser-driven, provider-driven, and spec-driven. Independent deployability was a priority for us, so we focused on solutions that offered a spec-driven approach, such as Pack Flow and Spec Matic.

Ease of adoption is another consideration. It's important to minimize the startup cost and leverage existing service tests whenever possible. Spec Matic stands out in this regard, as it automatically generates contracts by recording interactions between the conser and provider services. On the other hand, Pack Flow requires writing new tests using language-specific client libraries, which can be cumbersome.

The availability of a contract broker is another important factor. A contract broker acts as a central repository to store and organize contracts, and can be integrated into a CI/CD pipeline. Brokers offer advanced features like deployment awareness, which is crucial for identifying the relevant contracts during deployment. Pack Flow provides a fully-featured broker interface, while Spec Matic relies on external solutions like version control systems for contract management.

The licensing models of contract testing solutions vary widely. Some are subscription-based managed services, while others are fully open source and self-hosted. Our search for a suitable solution led us to Pack Flow and Spec Matic. Pack Flow was appealing due to its feature-rich broker, although it is a closed-source managed service. Spec Matic, on the other hand, is open source but lacks a dedicated broker.

However, neither solution met all our criteria, so we decided to build our own. I'll now hand it over to Hernando to introduce Signet, our open-source, self-hosted framework for spec-driven and contract testing of microservices.

Signet removes the barriers to entry by minimizing upfront costs and leveraging existing service tests. It addresses the need for smooth deployment by ensuring compatibility between service versions. Signet's unique features set it apart from other solutions in the market.

Signet adopts a spec-driven approach, where the API spec is established independently from service implementations. This allows independent integration testing and faster development. Signet is easy to adopt, thanks to its support for using existing service tests for automatic contract generation.

Signet also includes a dedicated contract broker, which acts as a central repository for contracts. It offers a fully-featured interface for managing the contract testing workflow and integrating it into CI/CD pipelines. Spec Matic, on the other hand, lacks a built-in broker, necessitating the use of external solutions.

The contract testing landscape varies in terms of licensing models. Signet is open source, which we appreciate, but it also provides the features we were looking for. We wanted the ease of adoption, the presence of a contract broker, and the ability to perform deployment awareness.

Now, let's dive deeper into the features of Signet. One of its core functionalities is streamlined adoption. It allows the use of existing service tests for automatic contract generation, eliminating the need to write new unit tests. This greatly simplifies the adoption process and improves the overall development workflow.

Signet caters to both the conser and provider sides of the integration. On the conser side, Signet allows existing service tests to automatically generate conser contracts. This reduces the need for manual contract creation and speeds up the testing process. On the provider side, Signet generates tests from the API spec, ensuring accurate implementation.

Signet makes it easy to deploy the contract broker within existing AWS Cloud environments. The Signet CLI seamlessly sets up the necessary infrastructure, such as an ECS Fargate cluster, with minimal effort. This flexibility allows for scalability to meet changing requirements.

Signet's dedicated contract broker sets it apart from other solutions. It offers functionalities specific to contract testing, such as automated comparisons between contracts and specifications for immediate feedback on compatibility. Additionally, Signet's Deploy Guard feature oversees service version deployment, evaluating the safety of introducing new services and ensuring compatibility with dependent consers. This feature is also accessible via the CLI, allowing CI/CD pipelines to gate deployments based on the current deployed services.

Signet provides a comprehensive solution for automating the contract testing workflow. It offers seamless integration with CI/CD pipelines through the use of CLI and webhooks. Teams can subscribe to specific events, such as new contract publications or fresh contract test results, using the Signet web interface.

These features were carefully designed to streamline contract testing integration for companies working with growing microservice environments. Signet's focus on ease of adoption, spec-driven approach, and dedicated contract broker make it a powerful tool in the contract testing landscape.

Now, let's shift our focus to the engineering decisions that influenced Signet's design. The fundamental idea behind Signet's spec-driven contract testing is that instead of directly checking compatibility between the conser and provider, we can check compatibility between the contract and spec. This eliminates the need for direct conser-provider compatibility testing.

In Signet, there are two types of documents: conser contracts and provider specifications. A conser contract represents the API interface expected by a conser from a specific provider. If a conser relies on multiple providers, separate conser contracts are required. Conversely, a provider specification encapsulates the complete API interface for a specific provider, even if it serves multiple consers.

Conser contracts are not necessarily required for spec-driven contract testing, as compatibility can be directly tested between the conser and provider spec. However, conser contracts offer advantages in terms of faster backwards compatibility testing. By comparing the old and new specs against the conser contract, we can quickly determine if the new spec is backwards compatible.

Conser contracts can be generated in two ways. They can be manually written using a text editor, following a specific schema. However, this approach can be tedious and error-prone. Alternatively, conser contracts can be automatically generated by recording service tests using a proxy. This eliminates the need for manual contract creation and speeds up the adoption process.

Signet's engineering decisions also consider the provider side. It introduces provider verification, where tests are generated from the API spec to ensure accurate implementation. This functionality is integrated into Signet, removing the need for companies to develop their own tools.

Another important engineering decision was the inclusion of a dedicated contract broker. Unlike storing contracts in version control systems, Signet's broker acts as a central repository, enabling automatic comparisons between contracts and specifications. Additionally, Signet's Deploy Guard feature oversees service version deployment, ensuring compatibility and preventing disruptions for dependent consers.

Signet's engineering decisions were made with the goal of streamlining contract testing for companies with growing microservice environments. By adopting a spec-driven approach, offering ease of adoption, and providing a dedicated contract broker, Signet offers a comprehensive solution that improves development workflows and ensures smooth deployments. In this coding Capstone project, we have two important services: the order service and the shopping cart service. Additionally, we have two providers: the payment service and the inventory service. The order service depends solely on the payment service, while the shopping cart service relies on both the payment service and the inventory service. It is worth noting that a service can act as both a consumer and a provider.

Now, let's discuss the purpose of a consumer contract. Initially, a consumer contract is not necessary for performing spec-driven contract testing. In the diagram provided, we can see that the consumer contract acts as a mediator to test the compatibility between the consumer and the provider specifications. However, it is possible to bypass the consumer contract and directly test the consumer with the provider specification. One approach is to use the provider specification to generate a provider test double, then verify whether the consumer is compatible with this generated test double. By adopting this approach, we eliminate the need for a consumer contract.

Despite this, there are advantages to using a consumer contract, such as facilitating faster backwards compatibility checking. Backwards compatibility checking entails testing a new specification against the same consumers that the old specification was compatible with. In our case, we want to ensure that the new specification is compatible with the existing order service. By examining a simple scenario, where the old specification offers functionality A and B, while the new specification adds functionality C, it is evident that the new specification is compatible with the order service. A comparison between the two specifications reveals that the new specification only introduces functionality C. However, a more complex case arises when the old specification removes functionality that the new specification still offers. Here, functionality B is removed. This, however, does not imply that the new specification is not backwards compatible, as the order service may not rely on functionality B. Without a consumer contract, we would need to retest the order service against the new specification, which would involve spinning up an instance of the service in a testing environment. However, with a consumer contract, we can test the new specification against the contract itself, without the need to spin up an actual instance of the consumer service. This test can be efficiently managed by the broker and does not require the additional step of spinning up a consumer instance. Thus, employing a consumer contract allows for faster backwards compatibility testing, offering timely feedback.

Now, let's shift our focus to the generation of a consumer contract. One possible approach is to manually write the contract using a text editor. Consumer contracts are serialized data files that adhere to a specific schema, so it is feasible to handwrite them. However, this method can be tedious and prone to errors. An alternative approach is to record service tests using a proxy. In this scenario, assuming the teams have already configured a test double for the provider, the interactions between the consumer and the test double during service tests already contain the expected HTTP requests and responses. To generate the consumer contract, we can set up a proxy to record these interactions and then write them into the contract. This approach provides an automatic and language-agnostic way to generate consumer contracts. The main drawback of using a proxy is that we must wait for the service tests to complete before generating the contracts. Consequently, the contract tests are performed after the service tests. Ideally, we would prefer to conduct contract tests earlier, as they are quicker than service tests.

Now, shifting our focus to the provider side, let's discuss how we can ensure that the provider adheres to the specification. One approach is to let the developer handle the testing between the provider and the spec. They can utilize their own testing tools to evaluate the provider's compliance. After testing, the developer can publish the test results to the broker. While this approach provides greater freedom, it increases the setup costs for contract testing. Developers must ensure that their tests align with the latest specification, thus avoiding any deviation or drift. To counter this issue, we decided to include a way to test the provider within our Signant solution. Signant offers a hands-on, language-agnostic approach to testing the provider. The first step involves pulling the latest specification from the broker to eliminate any potential specification drift. Then, we send a request to the provider for each request listed in the specification. The test is successful if all the provider's responses match the expectations outlined in the specification. Finally, we publish the verification results to the broker, ensuring transparency and accountability.

Lastly, let's explore how Signant integrates into the CI/CD pipeline. Signant is both platform and language independent, enabling its integration into existing CI/CD environments through the command line. Initially, let's outline the workflow for the provider. We first run provider verification to confirm adherence to the specification. If the verification passes, we proceed to deploy guard to ensure compatibility between the provider and all currently deployed consumers. Once these steps pass, from a contract testing perspective, we are ready to deploy. After deployment, we update the provider's deployment status. 

For the consumer workflow, the first step is generating the consumer contract. Once generated, we publish it to the broker to test its compatibility. We then run deploy guard to confirm that all dependencies are met and that there is at least one deployed provider for each dependency. Once these checks pass, we are ready to deploy the consumer, after which we update the deployment status.

All of these steps can be automated within the CI/CD pipeline through the Signant command line interface. Furthermore, CI/CD pipelines can be configured to trigger contract testing workflows in response to web hooks emitted by the Signant broker.

In conclusion, this presentation provided an overview of Signant and its functionalities. Signant offers a comprehensive solution for performing contract testing and ensuring compatibility between services and specifications. By utilizing consumer contracts, we can expedite backwards compatibility testing and achieve faster feedback. Additionally, Signant provides various methods for generating consumer contracts, such as manual creation or recording service tests using a proxy. On the provider side, Signant enables developers to test adherence to the specification and publish results to the broker. The integration of Signant into the CI/CD pipeline streamlines the testing process. Ultimately, Signant aims to enhance the efficiency and effectiveness of contract testing within software development projects. We hope you found this presentation informative. Thank you for your attention, and we are now open for questions during the Q&A session.

[Eric]
Thank you for that insightful presentation. While we wait for any questions to come in, let me ask you, what was the most challenging aspect of building Signant?

[Presenter]
Ah, I wasn't prepared for that question, but I would say the most challenging part was building the deploy guard functionality. In the presentation, we simplified the scenario by assuming only one version of the provider and one version of the consumer. However, in reality, multiple versions of the same provider and consumer can be deployed simultaneously. Thus, when deploying a consumer, we need to ensure that all its dependencies are met and that it is compatible with all deployed providers. This involves complex logic and fetching data to check compatibility in a multi-version environment.

[Eric]
Thank you for sharing that. It's clear that ensuring compatibility in a multi-version environment adds a layer of complexity. Well, since we haven't received any questions, let's wrap up. We hope you enjoyed learning about Signant and its capabilities. Have a fantastic weekend, and thank you for joining us today.

[Presenter]
Thank you, everyone, for attending. If you have any questions about Signant, please feel free to post them in the comments. We appreciate your time and wish you a great weekend. Thank you!