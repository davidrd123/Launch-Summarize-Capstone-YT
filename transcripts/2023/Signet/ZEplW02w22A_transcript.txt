welcome everyone thank you for joining us for today's webinar my colleagues and I are excited to introduce signant an open-source contract testing framework for microservices my name is Zach and I'm joined today by Michael Fernando and Eric the four of us collaborated remotely over the last several months in order to create signant here's the road map for today's presentation we'll Begin by breaking down the problem domain that eventually led us to build Sigma first we'll provide context for what microservices are then we will talk about why they are challenging to test after that we will introduce contract testing and walk through the existing Solutions in the space finally we'll discuss signet's approach to these problems and talk about the tradeoffs and design decisions that we considered while building it we'll also leave a few minutes at the end for Q&A let's start by talking about the difference between monolith and microservice architectures in a monolith all of the serers side logic is deployed together as a single unit in this example there are three business domains shopping cart users and payments in a monolith each of these domains is modeled by a programming construct in this case a ruby class the objects which are instantiated from these classes run in a single process and they interact with each other through inmemory method calls oops somehow I skipped all the way to the end for back in one moment all right so we've discussed monoliths we've discussed that each business domain runs as a programming construct in a single process in a microservice architecture each business domain is modeled by a standalone service that can be deployed independently Services interact with each other by passing messages over the network here the shopping cart service consumes the functionality of the user service by making an API call over hdtp microservices make it easier for many Engineers to work on the same application however they also require a more complex infrastructure than a monolith if a business is going to choose micro Services instead of a monolith there are two characteristics they will want to maximize the first one is limited ownership limited ownership means that each team of Engineers only needs to know how their own services are implemented if the shopping cart service needs to access the functionality of the payment service the shopping cart team only needs to know how to use the payment Service as API everything else about the payment service is abstracted away limiting the scope of the shopping cart team makes it easier for them to build new features quickly the second thing that micro Services should maximize is independent deployability this is where services are Loosely coupled in such a way that any of them can be updated and redeployed at any time let's say that the user service team wants to add a new feature when the feature is finished they can deploy the new version of user service without coordinating with any other teams as long as the user service API remains backwards compatible the other services don't even need to know that the user service was updated for many businesses limited ownership and independent deployability are worth the extra complexity that comes with microservices however even if the design of the application supports these benefits their effect can be diminished during the process of testing in order to understand why this is the case let's take take a brief detour and talk about automated software testing in general automated software tests can be classified using a pyramid the foundation of the pyramid is a large number of lightweight unit tests a unit test verifies that an individual component of the system works in isolation above unit tests are integ ation tests where multiple components of the system are tested together at the top of the pyramid are end to end tests where all of the components are put together and the app is tested as if it was released in production here's the main takeaway from this diagram the tests at the top of the pyramid give the most confidence in the quality of the app but they are also more expensive and time consuming than tests that are lower on the pyramid this realization leads many companies to sequence their tests in a particular order here's an example of how tests are often sequenced in a cicd pipeline cicd refers to continuous integration continuous delivery at a high level it is the series of steps that new software must go through before being released to production unit tests typically come first because they provide the quickest feedback when a bug is introduced as software progresses through the pipeline the scope of each test increases along with our confidence in the quality of the software in addition to the sequence of the tests the overall length of cicd matters as well a long cicd pipeline delays the release of new updates and also takes longer to notify developers if their changes broke something for monoliths it is common for integration and endtoend tests to be run before every new deployment however the story is different for microservices there are a number of difficulties with running integration and endtoend tests every time a new version of a service is being deployed let's examine integration tests first suppose that the shopping cart team updates their service and they want to test that the new version still integrates with the payment service in order to test the two Services together the shopping cart team needs to know a few things about the payment service how to set up any stateful data that the payment service needs how to configure and deploy the payment service how to set up any external dependencies that the payment service requires and finally they need to know which version of the payment service is currently released do you see the problem here limited ownership means that the shopping cart team should not need to know any of these details about the payment service one way to get around this problem is to use a service test with a service test the shopping cart team uses a test double instead of the real payment service the test double simply returns a canned response when a request is made to it using a service test instead of an integration test saves the shopping cart team from having to run the actual payment service however they still need to keep the payments test double up to date with the real payment service the way at least the way it behaves a contract test can help with this but before we get there we need to examine a few more problems with testing microservices this time related end to-end testing the first challenge with endtoend tests is that they are difficult to build and expensive to run endtoend tests try to simulate production conditions as closely as possible in many cases this requires duplicating the entire application in a dedicated staging environment not only is this expensive but it can also be very challenging to accomplish for applications with a large number of services another challenge with endtoend tests is that they are slow they are often used to exercise consecutive user interactions as they would occur in production for example a test might validate that a user can sign up for an account then log into that account and finally try to buy something these tests are especially slow for microservices because each test may result in several API calls between Services the third difficulty with endtoend tests is that they tend to be flaky a flaky test is one that occasionally fails even when there is nothing wrong with the code being tested a classic indicator of this is when running the same test over and over yields different results flakiness can occur because of network faults third party Services being unavailable and application State not being set up or torn down correctly between tests to recap integration and end-to-end tests are challenging for microservices especially when they are used in every Services cicd pipeline these tests don't always conform to The Limited ownership of teams they're expensive they're relatively slow and they have a tendency to be FL ke however we still need these tests because they provide a lot of confidence in the overall quality of the app how do microservices address this dilemma well a common solution is to reduce the number of integration and endtoend tests that are needed and if possible move the rest of them outside of cicd in their place other forms of testing can be used along with Progressive delivery techniques these make cicd faster while still providing a sufficient level of confidence in the quality of the software ideally any integration and endtoend tests that remain can be run on a schedule that does not obstruct the Rapid Release cycles of services at this point we have discussed why microservices require a unique approach to testing we have also briefly touched on service tests something that will come up later as we discuss the design of signment for now I'll hand it over to Michael to take a closer look at Contract testing in particular all right thank you Zach hi everyone uh let's Jump Right In so what is a contract test uh to recap a traditional integration test spins up both services and verifies that they properly work together service tests try to narrow the test scope by replacing the external service with a test double a contract test is different it interrogates each service in isolation to see if the two interfaces are compatible with each other it has a much narrower narrower scope and only tests the interface between the two services so contract tests get their name from a document known as a contract that formally describes the interactions between the services the contract does this by enumerating the H HTTP requests and responses that each service expects to send and receive in a basic form of contract testing a tool reads the contract and replay the request against a live service the actual responses are then compared to the expectations described in the contract and the test passes or fails depending on whether they match a failure here indicates that the services will not integrate together now I'm sure this is all very stimulating but why would we want this right the first reason is speed contact tests are much faster and less resource intensive than traditional integration tests this lets developers identify bugs much earlier in the process saving time time and accelerating the feedback loop yes just speaking for my own sanity I would much rather fail a test after 30 seconds of local testing then 30 minutes of a deployed endtoend test before having to start over um next contract tests run in isolation with the services with the service being tested saving the burden of having to deploy multiple Services together for testing this helps us with the independent deployability that Zach described um last specificity because each request and response is described in the contract a failing test can report exactly which messages are missing or malformed so clearly you're now hooked but contract tests do have their limitations the first is that they should supplement not replace endtoend tests this is because they have a more narrow Focus to test the compatibility of the interfaces and catch breaking changes quickly another trade-off to consider is that implementing contract testing may require writing many new tests until there's sufficient coverage of the interface you can't be confident that you're going to catch those breaking changes so great now that we've got the fine print uh we're ready to look at some common approaches to contract testing um but first let's define a couple terms so when we're talking about an integration of two Services we often find it useful to classify one of them as a consumer and the other as a provider so a consumer service depends on functionality or data from another service which is of course the provider and it's worth noting that these labels only make sense in the context of a particular integration right a service can be the consumer in one pairing and then it could turn around and be the provider and another so now that we're armed with our new vocab let's take a look at those approaches all right first up is the consumer-driven model where the contractor represents how the consumer is currently implemented the nice thing about this one is that the contract describes exactly which parts of the API are being used by the consumer the main drawback is that it doesn't deliver independent deployability the consumer team still has to wait for the provider team to pull down the contract spin up their service and verify compatibility up next we have the provider driven model which is nearly the reverse of the consumer driven not too surprising uh here the contractor represents the current implementation of the provider service often in the form of an API spec and you'll often hear it you know called that when we're talking about it you know from the provider perspective so the main benefit here is that it gives the provider team control over what the integration is going to look like and this might be a better fit if the provider has a large number of consumers which would make it really impractical you know to negotiate the API individually with them okay last but not least spec driven our favorite here the API spec is defined separately from either service's implementation ideally by having the teams agree to it in advance this makes it a natural fit for spec first API design which is a development practice where the team decides on a spec before writing the code instead of documenting it after the fact um the value here is that allows each service to be developed in parallel and tested against the spec along the way without having to wait for completed implementation of the other service aesome okay we're going to wrap up this section with some thoughts on what to consider when choosing a contract testing solution and how these considerations let us to create signant so the first thing to think about is which of the testing approaches you know does the solution support you know whether consumer-driven provider driven spec driven and this is a really important First Step because it defines the fundamental developer workflow going forward for us independent deploy deployability was a priority so we eventually narrowed our search to Pack Flow and spec Matic since these were the only prominent options that offered a spec driven approach uh the next big one is the ease of adoption and what we're talking about here is the startup cost you know the big one being whether we could use existing service tests to generate the contracts instead of having to write a ton of new tests just to you know get up and running so this is where spec Matic really shines because it offers a way to generate the contracts by automatically recording the interactions between the consumer and Provider Services it's very convenient uh in comparison Pack Flow requires you to write new tests using a language specific client Cent Library you know they provide a number of those and that's about as fun as it sounds U next up is whether the you know frameworker solution provides a contract broker which is a central repository to store and organize contracts and it can be integrated into a into your cicd pipeline um Brokers are great because they can also you know enable some more advanced features like deployment awareness um which is something that we wanted because it can quickly identify the contracts that matter when you want to deploy to a particular environment and we'll hear more about that in a moment um the broker so in terms of the these two solutions the broker is really Pack Flow strength um it provides a great you know fully featured interface that you can manage the whole you know testing workflow view contracts integrate it into cicd all that um spec Matic on the other hand does not provide a broker at all and so it relies on you to bring your own solution in terms of you know storing organizing your contracts Distributing them um here a lot of people might use a version control system like git or GitHub to do that um but not having that you know dedicated broker for the task um really limits you from you know precludes you from having those Advanced features that we wanted um lastly contract testing landscape is very diverse in terms of the licensing models and existing Solutions range from subscription managed services to ones that are fully open source and you know self-hosted as relevant um as far as the two we've been looking at uh packed flows uh broker sorry me we like pack Clos broker but felt limited by it being a closed source managed you know software as a service um spec Matic on the other hand is open source which we liked um and we also liked it's approach to generating the contracts but we really missed you know many of the features that a broker could provide so ultimately where we landed was that neither of these Services provided the combination of trade-offs that we were looking for so we decided to build our own so now it's my pleasure to hand it off to Hernando to tell you about it great thanks Mike today I'm excited to introduce Signet Signet is an open source self-hosted framework for spectr and contract testing of microservices it's designed to assist companies facing challenges with integration and end-to-end testing getting started with Signet is easy and comes with minimal upfront costs since it removes the necessity of creating new unit test one of its core functionalities addresses a fundamental question that many development teams face which is Will deploying this new service version cause any issues signate helps ensure deployment go smoothly let's now get into the features of what set signant apart as Mike already mentioned only a handful of tools adopt a spec driven approach in Spec driven contract testing the API spec is established independently from the implementation of either service this often involves a preliminary agreement between the consumer and provider teams on the apis spec before either service begins its implementation using spect driven contract testing allows each team to conduct integration testing independently without the need for support from others thereby achieving greater deployability aligning each service with specified requirements speeds up the development process allowing companies to rapidly deliver new service and updates new features and updates here we compare Signet with two well-known spec driven Solutions currently available in the market that we've already discussed Pack Flow and spec Matic while Pack Flow features a dedicated broker for contract management it isn't straightforward to adopt or open source on the other hand spec Matic is easy to adopt and open source but it lacks a contract broker Signet offers a unique blend of features it's spec driven open source easy to adopt and comes equipped with a dedicated broker let's delve deeper into the remaining features and explore the significance within the contract testing workflow let's begin with ease of adoption on the consumer side signant provides the capability to utilize existing Service Test service tests for the automatic generation of consumer contracts automatic contract generation offers the advantage of sparing developers from the time consuming and error Pro processes of writing new unit tests to get started with contract testing this efficient process makes it easier to adopt contract testing and improves the overall development workflow now let's turn our attention to the provider side where signit introduces provider verification in contrast to Alternative spec driven solutions that require companies to develop their own tools Signet incorporates this functionality right out of the box Signet generates tests from the apis spec to ensure the provider accurately implements the specification finally teams can also effortlessly deploy the signant broker within their current AWS Cloud environment through a single command the signate CLI efficiently coordinates the setup of an ECS fargate cluster encompassing all necessary foundational infrastructure this approach not only streamlines signate setup but also provides the flexibility to scale its capacity in response to changing requirements at the core of the application and the next feature we'll discuss is signat dedicated broker which includes functionalities that are purpose built for contract testing rather than storing contracts and Version Control Systems signant employs a dedicated broker as a central contract repository the signant broker instantly conducts automatic comparisons between contracts and specifications upon publication offering immediate feedback on compatibility this automation is great however it's not enough to Simply ensure that a service complies with a contract what truly matters to developers is whether any disruptions will occur when deploying a new service version into an environment this would require the additional step of identifying the current relevant set of contracts which can be a potentially cumbersome task often left to developers and other Solutions this is why signat deploy guard feature was built deploy guard oversees the deployment of service versions offering a convenient way to evaluate the safety of introducing a new service it validates the existence and compatibility of all Provider Services within the environment ensuring that the service won't cause any disruptions for dependent consumers what's great is that deploy guard is also available through the CLI so cicd can gate deployments based on what's currently deployed deploy guard is is not the only feature that's available to be used by cicd pipelines the entire contract testing workflow can be automated by cicd through the use of Signet CLI and web hooks teams can also utilize the Signet web interface to subscribe their cicd pipeline for web hooks pertaining to specific events which can include new contract Publications provider verifications against API specs and availability of fresh contract test results signet's features were thoughtfully crafted to accomplish the goal of streamlining contract testing integration for companies with growing microservice environments since we're now familiar with what Signet is and its core functionality I'll now pass it over to Eric to explore the engineering decisions that have influence signet's design thanks Hernando first let's talk about how Signet performs spec driven contract testing so Signa requires two types of documents per integration a consumer contract and a provider specification we can think of the contract as a representation of the consumer and the spec as a representation of the provider then instead of directly checking compatibility between the consumer and provider we can instead check for compatibility between the contract and spec so that's the high LEL overview now let's talk more concretely about contracts and specs a consumer contract represents the API interface that a consumer expects from a specific provider if a consumer relies on multiple providers then we require a new consumer contract for each provider in this example shopping cart service requires functionality a B and C A and B is provided by payment service while C is provided by inventory Service as shoing cart service depends on two different providers we require two consumer contracts one for each provider on the other hand a provider specification encapsulates the complete API interface for a specific provider if a provider serves multiple consumers they would all be associated with the same specification in this example payment service is providing functionalities a b and d payment service is serving two consumers shopping cart service and Order service with both Services being associated under the same specification now we comb both of our previous examples together in total we have two consumers order service and shopping cart service as well as two providers payment service and inventory service order service depends on only payment service while shopping cart service depends on both payment service and inventory service keep in mind that it's possible for a service to be both a consumer and a provider why have a consumer contract first off we don't need a consumer contract to perform spec driven contract testing from this diagram we see that the consumer contract is used as a middleman to test the consumer's compatibility with the provider spec however it's possible to cut the middleman and directly test the consumer with the spec for instance we can use the provider spec to generate a provider test double we can then test if the consumer is compatible with the generated test double if we took this approach then we do not need a consumer contract however one advantage of using a consumer contract is that it allows for faster backwards compatibility checking backwards compatibility checking is when we test if a new spec is compatible with the same consumers that the old spec is compatible with in this case we want to know that the in this case we know that the old spec is compatible with consumer service we want to determine if the new spec is compatible first let's examine the trivial case in this example theack provides functionality A and B while the newp adds on C it's obvious that the newc is compatible with consumer service all we need to do is to compare the two specs and recognize that the new spec only adds on functionality a less trivial case is when the old spec removes functionality from the new spec in this case functionality B is removed this does not mean that the new spec is not backwards compatible as it's possible that consumer service does not depend on B in this scenario without a consumer contract we would have to retest consumer service against the new spec this would entail spinning up an instance of the consumer service in a testing environment with a consumer contract we can test the new spec against the contract instead of the actual consumer this test can be handled by the broker and does not require spinning up an instance of the consumer as a result using a consumer contract will allow us to speed up backwards compatibility testing giving us faster feedback now that we covered what the consumer contract is we'll now talk about how to generate a consumer contract one approach is to write it by hand consumer contracts are serialized data files that follow a specific schema so it's possible to manually write them using a text editor the downside is that this can be tedious and prone to error another approach is to record service tests using a proxy in this case we assume that teams have already configured a test double for the provider which means that during the service test the interactions between consumer and the test double should contain the expected HTTP request and responses therefore we can set up a proxy to record those interactions and then write them into the consumer contract this approach provides a language agnostic and automatic way to generate consumer contracts the main drawback of using a proxy is that we must wait for the service test to finish executing before we can generate the contracts as a consequence the contract test will be performed after the service test ideally we want to perform contract tests earlier since contract tests are faster than service tests next we'll switch over to the provider side and talk about how to verify that the provider aderes to the spec one approach is to let the developer handle the testing between the provider and the spec they can use their own testing tools to test the provider after the test they can then publish the test results to the broker although this approach offers more freedom it increases the setup cost to contract testing developers would have to worry about making sure that their test doesn't Drift from the latest specification as such we decided to bundle in away to test the provider signate offers a Hands-On language agnostic approach to test the provider first we pull the latest back from the broker which prevents specification drift then we send a request to the provider for each request in the specification the test is is successful if all the provider responses matches with this p and finally we publish the verification results to the broker the last thing we'll talk about is how signant inter integrates into the cicd pipeline Signet is platform and language independent and can be run in cicd environments through the command line we'll start with the workflow for the provider first we run provider verification to check if the provider aderes to the spec if that passes we run deploy guard to see if the provider is compatible with all the consumers currently deployed once that passes from a contract testing perspective we are ready to deploy after deployment we update the provider's deployment status now we'll go over the consumer's workflow first we generate the contract then we publish the contract to the broker to test if the contract is compatible we run deploy guard once that passes we are ready to deploy and finally we update the consumer's deployment status all of these steps can be automated in cicd through the signate c c CC cicd pipelines can also kick off contact testing workflows in response to web hooks emitted by the signate broker that concludes today's presentation and now I want to take a few minutes for Q&A if you have any questions about signant feel free to post them in the comments while we're waiting for those to come in um Eric can I pitch a question to you um what do you think was the most challenging part of building signant I was not ready for this question by the way I know I know uh I honestly think building the ploy card was the most challenging part um one of the things that we didn't go over in the present presentation because it was a bit too much details was that we allow consumer and providers to have different versions so in the presentation we kind of assume that there's only like one version of the provider and one version of the consumer but in reality the consumer can have multiple versions that the iterate and so is the provider and so multiple versions of the same provider can be deployed on the same environment and same thing with the consumer and there are a bunch of dependencies so with deploy guard we need to check you know when I deploy a consumer um first of all are all of my dependencies met is does there exist at least one provider for each of the providers that I'm depending on that are deployed and I also need to check you know for all of the providers that that are deployed that I'm using am I compatible with all of them and that type of checking just takes like I don't know a bit of logic to work through to fetch out the data for well not seeing any questions come in I'm sort of stalling a little longer but other than that I think we might wrap up then um okay uh thanks everyone for coming out we hope you enjoyed learning about Signet have a great weekend thanks everyone thank you thank you 