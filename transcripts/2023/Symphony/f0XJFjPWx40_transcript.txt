foreign let's get started today we're going to talk about Symphony and collaboration on the web symphony is an open source framework designed to make it easy for developers to build collaborative web applications Symphony handles the complexities of implementing collaboration including real-time infrastructure and conflict resolution freeing developers to focus on creating unique and engaging features for their applications Symphony was built by a team of four software Engineers working together remotely two of us based in the US and two in the UK my name is Derek and my teammates are Yusuf mikolis and Diego we'll start off by talking about what it means to collaborate in real time next we'll take a look at collaboration on the web and how it has evolved over time after that we'll introduce Symphony in more detail and explain how it solves the problem of adding real-time collaboration functionality to an existing web application once we've explained what symphony is we'll perform a brief demo that shows how Symphony can be dropped into an existing web application transforming a single player experience into a collaborative one next we'll talk about how we designed and built the symphony prototype the single server prototype of symphony has its limits however so we'll then walk you through how we tested and scaled it after presenting the final architecture we'll talk about future plans for Symphony and then take some time to answer any questions from viewers first let's talk about what we mean by real-time collaboration real-time collaboration happens when multiple users work together to modify the same content at the same time in recent years apps like Google Docs Trello Miro and figma have offered this functionality using these apps groups of users can modify documents whiteboards or other content simultaneously let's now go over a few basic concepts that are key to real-time collaboration the first concept is a room collaboration is something that happens when two or more users work together to modify content a room is what we call this group of collaborating users the second concept is a document a document is the shared state that users are collaborating on keep in mind that this is not limited to text documents a document can be any type of content including not just text but also drawings on a whiteboard or a list of to-do's for example that brings us to the third concept which is presence presence represents the action specific users are taking in a room at any given moment this might be represented by Mouse cursors for example seeing what other users are doing in real time makes for a smoother and more meaningful collaborative experience so that's real-time collaboration in a nutshell but not all online collaboration works this way how would online collaboration work if it wasn't real time if we're not making changes to content at the same time that means taking turns the first user Bob is working on a document the second user Alice is waiting and trying to stay patient finally Bob finishes making his changes and sends the document to Alice now it's Alice's turn to work and Bob's turn to wait this kind of non-real-time collaboration works and it may even be preferred in certain situations like when team members are in very different time zones but for many use cases it's sub-optimal there's a lot of waiting involved which means that everything takes more time and productivity is reduced so in many cases real-time collaboration seems like the way to go but there are two main problems that need to be dealt with before an application can offer it the first is actually getting our data to where it needs to go in real time and the second is resolving conflicts when users make different changes to the same content at the same time let's talk about the real-time problem first if we're talking about a real-time experience on the web we probably think of something like a chat application or a sports site that gives you live updates so what do these kinds of user experiences have in common first the user receives data without any noticeable delay as soon as someone sends you a message in a chat app it appears on your screen or as soon as a player scores a goal the sports app sends you a live update the second thing is that the user doesn't need to take an action in order to receive new data you don't need to keep refreshing the page to see if anyone has sent you a new chat message for example but there's a problem we'll face when we want to create a real-time experience on the web the underlying architecture of web communication is based on the HTTP protocol and HTTP is built on a client server model where the client sends a request to the server and the service sends a response back to the client each HTTP request response cycle is independent of others making HTTP a stateless protocol this means that if we're limited to the HTTP protocol there's no way to send data from the server to the client without first receiving a request from the client now we could try to get around this by having the client send repeated requests that set intervals to the server to check for updates this is called polling if the polling interval is short enough you could end up with something that looks like real time but this is a sub-optimal solution for use cases where we want to send high frequency updates we're sending a fresh request every time we want to check for new data and these repeated requests create extra load on both the server and the client fortunately there are web Technologies and protocols that enable data to be sent in real time over a stateful connection next we'll talk about two of the more commonly used Technologies webrtc and websocket first web real-time communication or webrtc is an open source project that allows web browsers and mobile applications to engage in peer-to-peer real-time communication via apis since webrtc is primarily used over UDP it offers lower latency at the cost of some data loss this makes it an especially attractive choice for video and audio streaming because these use cases prioritize faster data transfer and can tolerate a few missing packets the next technology we consider is websocket websocket is a protocol that provides a two-way persistent channel of real-time communication between a client and a server this allows the client to receive updates from the server without having to send repeated requests websocket channels are provided over a TCP connection and the reliability baked into TCP means that websocket provides Superior data Integrity compared to webrtc this does cause this does come at a cost of higher latency however websocket is ideal for real-time applications like stock trading platforms or online games where it is especially important that every message is delivered now I'll hand things over to Yousef who will talk about the next problem to be solved in real-time collaboration which is conflict so as Derek mentioned the complexity of building these collaborative applications radically increases because of the possibility of conflict and by conflict we mean when two or more users without knowledge of one another attempt to modify the same piece of State concurrently resulting in conflicting versions of that data now let's make this clearer with an example consider a collaborative text editor where Alice and Bob are working together on a document Bob and Alice both make changes to the same section of the document when they do this the state of the document diverges in other words each uses modifications can be seen as branching off from the previous state of the system creating parallel versions of the system state and it's these branches that represent different possibilities for the final state and reconciling them is essential for maintaining consistency of State across clients so how do we go about reconciling these conflicts and enforcing distributed consistency well the simplest way would be to just lock the state so that only one person can make edits at any given time you can see this and you can see this in action on applications like Basecamp and once this facilitates asynchronous collaboration as Derek mentioned earlier it provides a very limited workflow where users have to explicitly coordinate when they can edit the document or they have to work on separate documents and then merge the changes together but we want conflict resolution mechanisms that can support synchronous collaboration going back to the branching model we need a mechanism to automatically merge branches in a deterministic way until all branches have converged to a single eventually consistent State across the entire system over the years multiple mechanisms that support automatic conflict resolution have been proposed and we'll go through some of the most pertinent let's start with the most well-known operational transformation of OT for short it's an algorithm famously used by Google Docs the idea behind OT is to represent each user's edits as a sequence of operations that can be applied to the shared state when a user makes an edit the client application sends an operation to the server which broadcasts it to all other clients and in cases where multiple users attempt to modify the same piece of State concurrently the OT algorithm transforms one of the operations so that the operations can be applied in any order without conflict in this example two users attempt to add different words to the end of the string hello the server which implements the OT algorithm shifts the insertion index of one of the operations which ensures that both of the user's updates can be inserted without conflict on the whole we can say that OT is a performance and memory efficient algorithm but it's also very complicated to implement as Joseph gentle a formal Google wave engineer highlights and it's this complexity of OT that led researchers to try to find alternatives and of the most recent developments is conflict-free replicated data types or crdts for short a crdt is an abstract data type that is designed to be replicated on multiple clients with the following properties the first is that any of these replicas can be modified without coordinating with any of the other replicas and when two replicas receive the same set of updates in any order they are guaranteed through their mathematical properties to this to deterministically convert to the same state and the way crdts achieve this is by requiring these operations to be commutative meaning that if an operation can be applied in any order then you'll just no longer have any conflicts the advantages of crdts include their conflict-free nature and flexibility and because of these mathematical properties that they adhere to the replicas are guaranteed to converge but they also do come with some disadvantages the main one is that to make the operations commutative the crdt needs to store additional metadata and this means that they come often come with significantly more memory overhead than Alternatives like OT so we've seen a bunch of potential conflict resolution mechanisms and the key takeaway from the last section should be that when it comes to choosing one there isn't one size that fits all and each of the conflict resolution mechanisms have their own set of trade-offs and choosing a particular method requires a deep understanding of the usage pattern of the target application and so some of the questions that we may want to consider might be like what what are the cap properties so the consistency availability and partition tolerance properties of the system you know what's our system architecture is it client server peer-to-peer do we need to support offline capabilities do we have any CPU or memory constraints so now that we know that the key ingredients which go into building these collaborative applications it's clear that if someone wants to build this themselves it would be a lot of work you would need to host your own real-time infrastructure choose your own conflict resolution mechanism and implement it and that's not to mention all the auxiliary components you would need like persistence monitoring that are essential to modern day web applications and so to lower this barrier new Solutions have started to emerge that promise to abstract away a lot of this complexity and two of the most popular are live blocks and fluid framework they've made it radically easier for developers the majority of which do not have any expertise when it comes to real-time and conflict resolution to build collaborative web applications but even these Solutions have limits live blocks for example provides a great developer experience but it's not open source and it's very expensive when fluid is open source but it doesn't come with a predict production ready real time and persistence infrastructure unless you use their closed source as your managed service and it's with these limitations in mind that letters to want to build a tool a tool for a very specific use case we wanted to build an open source scalable tool for teams that want to add collaborative functionality to their applications without having to spend the time implementing and deploying their own conflict resolution and real-time infrastructure and it's clear that there was a need for this since most developers don't traditionally have expertise in this propeller Aero a company that wanted to make their 3D survey Maps collaborative is a great example of this here's Jai Lewis an engineering manager from propeller saying the following and it's with this motivation that we set out to build Symphony which we're now proud to demo symphony is built to support all manner of collaborative applications ranging from the simplest collaborative whiteboard to the most complex like collaborative 3D CAD design tools but before we get too deep into how we actually do this behind the scenes we'd love to give you a quick demo and we'll keep it simple just to show you that Symphony lets you build collaborative whiteboards that we can we can build a collaborative whiteboard with Symphony in just three steps first we install the symphony client and the symphony CLI tool then we write our application using the data structures and apis provided by the symphony client we provide a variety of data structures so that even the most complex data models can be represented then we simply deploy using our CLI command and just like that we have a collaborative web application if you'd like to go to the link shown you can see it in action so here on the demo we can see as Derek mentioned previously a presence you can see all the curses moving and you can also see users now drawing which constitutes the persistent state now you're probably intrigued how Symphony Works under the hood well I'll leave it to make less to explain when designing Symphony our goal was to provide the infrastructure needed for creating conflict-free collaborative experiences on the web in a way that is easy for developers to drop into their existing applications this infrastructure will need a means of resolving conflicts receiving and transmitting updates to collaborating users and persisting State furthermore we wanted to abstract away the complexity of managing and scaling this infrastructure for conflict resolution we settled on yjs and open source well-documented and performant crdt Library all of these properties made it an attractive choice for our use case for receiving and transmitting updates we chose a websocket server as we mentioned earlier since websocket uses their DCP protocol it provides for better data Integrity when transmitting messages compared to web RTC for example which uses the UDP protocol furthermore websocket uses the client server model applications that we use Symphony are likely already using the client server model as well which lies at the heart of modern web applications for these reasons websocket was a natural choice for us since we have chosen the ygs crdt implementation our starting point for the symphony backend was the reference websocket server provided by yjs it implements the necessary protocols for syncing document updates and broadcasting presence data we chose to deploy our initial prototype of the system on Amazon web services the biggest player in the cloud provider Market with 32 Mark percent market share as of Le 2023 we first deployed the server to elastic compute Cloud a standard virtual private server offered by AWS when a collaboration session ends users will likely want to come back later and continue where they left off when they reconnect they will need access to that room's state to accomplish this we needed to modify the server to persist document data to a data store so that users would be able to leave a room without losing their work for the storage location we considered object storage and a database because we needed to store potentially large amounts of unstructured data we chose object storage which is a cost effective option for our purposes we connected our server to simple storage service provided by AWS as for when to store document data we decided first of all to persist the data to S3 every 30 seconds which minimizes the amount of data that would be lost in the event of server failure and we also persist document data when the last user leaves the room the next time a user connects to collaborate in a given room and the server does not have the document for that room in memory it will query S3 for that data and retrieve it if it exists right now we have a way of establishing websocket connections between users and Away to persist room state to save users work between collaboration sessions however the developers don't have any good way of seeing how many rooms are active how many users are connected at any given time or the size of a given room we wanted to give the developers visibility into these metrics to persist metadata about Connections and rooms we chose a relational database which takes care of ensuring data integrity and enables flexible and efficient queries we connected our server to a postgresql database provisioned in relational database service provided by AWS to access the stream metadata we added get roots to the server the dashboard sends HTTP requests to these routes and the server responds with a requested data for the number of connections for a given room a continuous stream of data is sent from the server to the dashboard client via servers and events with the server deployed to ec2 the developer remains responsible for managing the server which includes applying security updates handling logs and so forth we wanted Symphony to abstract away this back-end management from their developer in line with our design philosophy of making an easy to use framework with that in mind we moved our architecture into AWS elastic container service a fully managed container orchestration service for deploying managing and scaling containerized applications PCS gives you the choice of deploying in ec2 or fargate mode the ec2 mode gives developers more granular control of a container instances at the cost of needing to manage instance configuration and updates since we wanted to abstract away this management from the developer we chose Target mode since we have a symphony client as well as a dashboard plan for developers accessing our backend we want a single point of entry for both an application load balancer that sits in front of our backend gives us the single point of entry and also Roots traffic to individual instances of our websocket server in the scaled form of our architecture which we will discuss in a later section while ECS is a scalable service our server isn't actually scalable just yet and on that note I will pass it on to Diego who will talk to you about load testing and scaling the symphony server as Michael has mentioned a framework was missing a key piece scalability one of symphony's core principles is to provide developers with infrastructure that is ready to scale the definition of ready to scale will drastically differ depending on who you ask larger applications might Define scalable as handling millions or tens of millions of concurrent users but such a high number is rarely seen in real-time collaborative applications most real-time collaborative applications don't need to handle millions of concurrent users instead their scalability requirements are usually in the range of thousands to tens of thousands of concurrent users we looked at similar Solutions in the space to confirm these numbers symphony is an open source version of live blocks with less features as a pain managed service live blocks offers different tiers their Pro tier supports between two thousand to twenty five thousand users using the higher end of this range as a reference we've set to support 20 000 concurrent users over five thousand rooms we load tested our solution to identify its capabilities in potential bottlenecks a series of low tests revealed our monolith server could only support 240 users over 60 rooms initial results put as far from our goal adding more websocket servers is an effective strategy that improves the system's ability to handle more connections and process more data however our current architecture could not support multiple websocket servers due to its message propagation strategy here's how our monolith originally broadcasted updates user 1 joins Room 1 by establishing a websocket connection to our websocket server the websocket server will retrieve the room state from persistent storage and hold it in memory each room state has additional metadata one important piece of metadata is a list of users in the room this live list updates when a user joins or leaves a room if another user joins the same room the server will add the user to the room's user list this list is used to propagate updates when the user changes the state of the room if user 1 updates room one state on their local machine the update is sent to the websocket server over to websocket connection server will use a room's list of users to send an update to other users the implementation assumes all clients will land on a single server it propagates updates to relevant clients using data in memory pertinent to the server let's introduce another websocket server and let it handle a new user user3 that joins the same room each server will have the room state in memory along with its own list of users but has no knowledge of users in the same room on another server if user degree updates to room State the websocket server has no way to send the update to users who join room one on the other server there needs to be another mechanism to propagate updates across multiple websocket servers the traditional way to scale websocket servers is through a publisher subscriber or Pub sub pattern the pub sub pattern has a few key Concepts topics Publishers and subscribers topics are at the core of understanding the pub sub messaging pattern a Topic's purpose is to handle a specific set of messages identified by the Topic's name topics are the central component used by Publishers and subscribers Publishers are to components responsible for sending messages to a topic when a publisher publishes a message to a topic the message is sent to All subscribers of that topic subscribers are components that receive and process messages sent by publishers a subscriber will subscribe to a topic and when subscribed the subscriber receives all messages published to the topic in order to implement a pub sub mechanism we evaluated different Technologies including redis Kafka and rabbitmq Kafka is a powerful data shooting platform it supports use cases that extend far beyond Pub sub messaging such as event sourcing log Recreation and many more Q is primarily a message broker that supports a wide range of messaging patterns it also supports cues Advanced routing and more advanced configuration redis is an in-memory key value store that supports Pub sub messaging pattern persistence storage caching Etc Kafka and routing Cube are catered For more complex use cases the value message retention and durability at a slight cost performance both are also significantly more complex to set up and manage redis has a lowest latency and is the easiest to integrate for these reasons we chose redis for a pub sub messaging system using reddit's requires server management configuration of routers nodes to simplify implementation we used Amazon's elastic cache as a managed service it simplifies the task associated with managing redis nodes handling data replication automatic failover and other server management tasks AWS took care of the underlying infrastructure and ensured high availability and reliability of our messaging system by leveraging elastic cache you can efficiently create an internal Pub sub messaging system that enables websocket servers to exchange room State updates integrating a managed redis messaging system permitted horizontal scaling or websocket server in our implementation a topic is uniquely identified by rooms ID each topic each room is represented in redis as a topic each websocket server is both a publisher and a subscriber acting on behalf of users when a user joins a room the server will subscribe to the topic matching the room's ID here we have user water user 2 joining the same room on different websocket servers they both subscribe to the room through Reddit when user One updates the state of the room the update is published to redis redis will push the update to subscribe to websocket servers a subscribed websocket server we use the rooms list of users held in memory and send the update to all users with the system in place we're no longer limited to a single websocket server but there is still an issue retrieving the state of an active room an inactive room is a room with no connected users when a user joins in an active room by definition the user is the first the state of an inactive room can be safely retrieved from the person store an active room is a room that has at least one connected user when a client connects to an active room if its state is not in service memory then it cannot be reliably retrieved from the persistent store when a client makes an update to State and the persistent store becomes outdated our checkpoint saved data at 30 second intervals but that's a 29 second window or the persistent store could return outdated state if a room is active the state must be in memory on one of the websocket servers our solution leveraged is simple fact by using a separate data store to hold the location of every server that has their own state when a user joins a room the server checks at the state is in memory if the state is not in memory server has no immediate way of knowing whether the room is active to determine if room is active to serve a core is a data store for a list of servers that have the room state the return list has a private IP address of each server the server cores one of the servers using an API endpoint to retrieve a room state this approach allows us to efficiently retrieve the most up-to-date state without overloading a separate storage mechanism or duplicating State data across all websocket servers to store the IP addresses of servers we looked for a performance key Value Store capable of handling high throughput for the latency redis can be configured to store more persistent data such as session data while also handling the pub sub messaging system another key value database is AWS dynamodb it is a managed nosql database service although my team tempting to use redis for both the pub sub messaging system and the session data store we decided against it by using dynamodu B we could separate the concerns of messaging and session data storage leading to a cleaner architecture preventing potential bottlenecks caused by overloading a single system with multiple responsibilities separation ensures that the performance of one component does not negatively impact the other our modified solution could scale horizontally and guarantees clients joining active rooms received the most up-to-date state the last step was to Define when are websocket servers should scale since we're using ECS hargate we could Define autoscope policies that would instantiate new websocket server instances based on the average metrics of all websocket servers our websocket API service is the aggregation of all websocket servers we configured our websocket API service to Auto scale on CPU utilization the auto scaled service should have been scalable but after running another set of load tests we got unexpected results the first websocket server was always failing first due to high CP utilization to issue as a misconfiguration with their load balancer routing algorithm by default aws's application load balancer uses a round robin algorithm to Route requests with this algorithm the load balancer is impartial to two servers with different CPU utilizations say fat five percent and eighty percent are just as likely to serve a new client we change a router algorithm to least outstanding connections the new algorithm routes new clients to the websocket server has the least number of users connected our final load testing reached our goal of handling 20K concurrent users over 5000 rooms this is not the actual limit of our system but we were unable to test more users due to AWS service quota limits preventing us from creating more websocket server instances I could have requested a service call to increase improve a higher limit but we were satisfied with the end results next we recognize some future areas of improvement the current architecture can have a single room State replicated across several servers different servers could all be holding the same room State and memory an insurer has to execute a crdt merge algorithm to apply every new update a potential optimization from our current architecture is to use one process per room this maximizes CPU and memory utilization by limiting a room state and the execution of the CO2 merge algorithm to one process okay thanks everyone for joining our presentation about symphony today and I will now open the floor to questions Okay so we've got the first question is what tool did you use to perform load tests yes I'll answer that um initially we tried to use artillery i o thought we realized that we didn't really like artillery was more students to test the number of websocket connections uh so we ended up coming up with uh just like our own um like a solution that basically just simulated created several virtual users in each virtual user would simulate a user session by running some some script that performed updates uh give it several like a set interval that we decided and we ran these on you see two instances on AWS we've also got a second question here what was your greatest challenge when implementing Symphony um yeah I'll try that one um I think that one of the biggest challenges um and maybe the biggest is is related to something that Diego just talks about which is load testing um one aspect was the actual load testing tool but then in addition to that um for our use case for testing Symphony there was a little more complexity than you would get with sort of the traditional websocket testing um in our case it wasn't just a matter of saying okay how many websocket connections can our server handle at once uh and that's because the load on the server is going to vary dramatically depending on your chosen testing parameters not not just on the number of connections uh so for example we needed to consider how many presence updates so reminder presence update would be like if a user is moving their Mouse and you want to show that to other users you need to send an update every say 100 milliseconds um or for example how many document updates each user is making per second another parameter is the number of users per room and that one ends up being very important because as that number increases the number of messages the server is sending for a given room is going to increase uh I think quadratically um and then another thing about testing was how we thought about CPU versus memory requirements because when we ran our test we would notice that at first CPU was the immediate bottleneck and that's basically what you would expect but then as time went on like for example if we ran the test for a couple of hours the memory utilization increases at a linear rate basically the entire time well CPU might be holding steady uh and that's because of how the crdt is implemented so every document updates had every document update uh it has to be held in memory so the document is constantly increasing in size as users make updates even if they're actually deleting something in the document the document is just getting bigger so we had to think about at some point memory is going to become the bottleneck but what point is that going to be it really depends on your specific use case what is the average size of the document for your use case what is the average number of accumulated updates per document so when you're trying to find that number how many concurrent users we could support we found that the answer would just vary really widely depending on how we Define those parameters and that then they're testing a real challenge okay I I think that's it then um thank you everybody for spending part of your Friday with us um hope you enjoyed it 