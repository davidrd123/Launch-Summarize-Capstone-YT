Today, we will discuss Symphony and collaboration on the web. Symphony is an open-source framework that simplifies the development of collaborative web applications. It handles the complexities of implementing collaboration, such as real-time infrastructure and conflict resolution. This allows developers to focus on creating unique and engaging features for their applications.

Symphony was created by a team of four software engineers, working remotely, with two based in the US and two in the UK. The team consists of Derek, Yusuf, Mikolis, and Diego. In this video, we will cover the concept of real-time collaboration, the evolution of collaboration on the web, an in-depth look at Symphony, and its ability to add real-time collaboration functionality to existing web applications.

Real-time collaboration occurs when multiple users work together to modify the same content simultaneously. Applications like Google Docs, Trello, Miro, and Figma have popularized this functionality, enabling groups of users to edit documents, whiteboards, and more simultaneously.

There are three key concepts in real-time collaboration. The first is a room, which refers to a group of users collaborating on content. The second is a docent, which represents the shared state being modified. Docents can include text, drawings on a whiteboard, or even to-do lists. The third concept is presence, which indicates the actions specific users are taking in a room in real-time. This can be represented by mouse cursors, for example, and enhances the collaborative experience.

However, not all online collaboration follows real-time principles. In cases where simultaneous content modification is not possible, users take turns, resulting in increased waiting time and reduced productivity. While this approach can be suitable for situations involving team members in different time zones, it is suboptimal for many use cases.

To enable real-time collaboration, two main problems need to be addressed. The first is sending data in real-time, and the second is resolving conflicts when multiple users modify the same content simultaneously.

Real-time experiences on the web typically involve applications like chat apps or sports websites that provide live updates. These experiences have two common characteristics. Firstly, data is received without noticeable delay, so users immediately see new messages or updates. Secondly, users do not need to take any action to receive new data. There is no need to refresh the page repeatedly, as new information is pushed to the user.

The underlying architecture of web communication is based on the HTTP protocol, which follows a client-server model. In this model, the client sends requests to the server, and the server responds. Each request-response cycle is independent, making HTTP a stateless protocol. This means that without additional technologies, data cannot be sent from the server to the client without first receiving a request from the client.

To overcome this limitation, there are web technologies and protocols that enable real-time data transfer. Two commonly used technologies are WebRTC and WebSocket. WebRTC allows real-time peer-to-peer communication between web browsers and mobile applications. It prioritizes low latency at the cost of potential data loss, making it suitable for video and audio streaming. WebSocket, on the other hand, provides a two-way persistent channel of real-time communication between clients and servers. It offers superior data integrity compared to WebRTC, making it ideal for applications where every message must be reliably delivered, such as stock trading platforms or online games.

Resolving conflicts is the second challenge in real-time collaboration. Conflict arises when multiple users modify the same content concurrently, resulting in different versions of the shared state. To maintain consistency, these versions need to be reconciled. There are several conflict resolution mechanisms available, including Operational Transformation (OT) and Conflict-Free Replicated Data Types (CRDT).

OT, used by Google Docs, represents user edits as sequences of operations that can be applied to the shared state. When conflicts occur, the OT algorithm transforms one of the operations to ensure they can be applied in any order. While OT is efficient, it is also complex to implement.

CRDT is an abstract data type designed to be replicated on multiple clients. Replicas can be modified independently and will always convergently reach the same state. CRDT achieves this through commutative operations, meaning they can be applied in any order without conflict. While CRDTs are conflict-free and flexible, they can have higher memory overhead compared to OT.

While solutions like Live Blocks and Fluid Framework have simplified collaboration for developers, they still have limitations. Live Blocks, while providing a great developer experience, is not open source and can be expensive. Fluid Framework, on the other hand, is open source but does not provide a production-ready real-time and persistence infrastructure unless its closed-source Azure managed service is used.

To address these limitations, we developed Symphony, an open-source and scalable tool for teams who want to add collaborative functionality to their applications without the need to implement and deploy their own conflict resolution and real-time infrastructure.

In a simple three-step process, Symphony allows developers to build collaborative web applications. The first step involves installing the Symphony client and the Symphony CLI tool. Then, developers can write their applications using the provided data structures and APIs. Symphony offers various data structures, accommodating even complex data models. Finally, the application can be deployed using the CLI command, resulting in a collaborative web application.

To demonstrate Symphony's capabilities, we provide a quick demo of building a collaborative whiteboard. In the demo, presence indicators, such as moving cursors, provide real-time feedback on user actions. By following the provided link, viewers can experience the collaborative whiteboard firsthand.

While Symphony fulfills a specific use case, it is important to note that there is no one-size-fits-all conflict resolution mechanism. The choice of mechanism depends on factors such as the system's CAP (Consistency, Availability, Partition Tolerance) properties, system architecture, offline capabilities, and resource constraints.

In summary, Symphony aims to simplify the development of collaborative web applications by abstracting away the complexities of real-time infrastructure and conflict resolution. By providing a scalable and open-source solution, Symphony empowers developers to create engaging and collaborative experiences. In the next section, we will discuss the design, development, testing, and scaling of Symphony, followed by future plans for the framework. We will also address any questions from viewers at the end of the presentation. Building collaborative applications requires a combination of key ingredients. However, the process is complex and time-consuming, involving tasks like hosting real-time infrastructure, choosing a conflict resolution mechanism, and implementing auxiliary components like persistence monitoring. To overcome this challenge, new solutions have emerged, such as Live Blocks and Fluid Framework, which promise to simplify the development process for collaborative web applications. However, they have their limitations, such as cost or lack of a production-ready infrastructure.

To address these limitations, our team developed Symphony, an open-source scalable tool for teams to add collaborative functionality to their applications without the need for implementing and deploying their own conflict resolution and real-time infrastructure. This tool aims to lower the barrier of entry for developers who don't have expertise in these areas.

The motivation behind Symphony was the recognition that most developers lack expertise in conflict resolution and real-time capabilities. For example, Propeller Aero, a company that wanted to make their 3D survey maps collaborative, faced this challenge. Symphony was developed to fulfill this specific need.

Symphony is designed to support a wide range of collaborative applications, from simple collaborative whiteboards to more complex tools like collaborative 3D CAD design. It simplifies the development process into just three steps. First, developers need to install the Symphony client and CLI tool. Then, they can write their application using the provided data structures and APIs. Symphony offers various data structures to represent even complex data models. Finally, developers can deploy their application using the CLI command, resulting in a fully functional collaborative web application.

To demonstrate the capabilities of Symphony, we created a collaborative whiteboard as a simple example. Users can see the presence of other users, represented by moving cursors, and they can draw on the whiteboard to create persistent state. A live demo is available for further exploration.

Behind the scenes, Symphony was designed to provide the necessary infrastructure for conflict-free collaborative experiences on the web. Key requirements include conflict resolution, update transmission between collaborating users, and persistence. For conflict resolution, we adopted the Yjs CRDT library, which is open source, well-documented, and performant. This library helps ensure conflict-free collaboration.

For transmitting updates between users, we chose WebSocket as it offers better data integrity compared to other options like WebRTC, which uses UDP. WebSocket's client-server model aligns with the client-server model commonly used in web applications. We built Symphony's backend using the WebSocket server provided by Yjs as a starting point.

The initial prototype of Symphony was deployed on Amazon Web Services (AWS), the leading player in the cloud provider market. We started with Elastic Compute Cloud (EC2) to deploy the server as a standard virtual private server. To enable users to reconnect and continue where they left off, we modified the server to persist document data to AWS Simple Storage Service (S3). This ensures that users can leave a room without losing their work.

To enable developers to monitor active rooms, the number of connections, and room size, we chose a relational database for metadata persistence. This database provides data integrity and efficient queries. We connected the server to PostgreSQL, provisioned using AWS's Relational Database Service.

To provide developers with visibility into these metrics, we added routes to the server that can be accessed by a dashboard. The server responds with requested data, such as the number of connections for a given room. The dashboard receives a continuous stream of data from the server via server-sent events.

With the server deployed on EC2, developers are responsible for managing the server, including security updates and logs. To simplify backend management, we moved Symphony's architecture into AWS Elastic Container Service (ECS), a fully managed container orchestration service. ECS offers both EC2 and Fargate deployment modes, but we chose Fargate to abstract away the need for developers to manage instance configuration and updates.

For load balancing and routing traffic, we implemented an application load balancer as a single point of entry. This load balancer directs traffic to individual instances of the WebSocket server, ensuring a scalable architecture.

While ECS offers scalability, our initial monolith server lacked scalability. To address this, we performed load testing to identify bottlenecks and determine its capabilities. Our goal was to support 20,000 concurrent users across 5,000 rooms. We found that multiple WebSocket servers improved the system's ability to handle more connections and process more data.

To achieve this scalability, we introduced a pub-sub messaging system using Redis. We evaluated different technologies like Kafka and RabbitMQ, but ultimately chose Redis due to its low latency and ease of integration. We used Amazon Elasticache, a managed Redis service, to simplify server management.

Each WebSocket server acts as a publisher and subscriber, handling updates on behalf of users. Redis facilitates the exchange of room state updates between WebSocket servers. Using this pub-sub mechanism, we achieved horizontal scaling of the WebSocket servers.

To address the challenge of retrieving the state of active rooms, we introduced the concept of inactive and active rooms. Inactive rooms are those without any connected users and can easily retrieve state from persistent storage. Active rooms have at least one connected user, making it harder to reliably retrieve state from persistent storage. We implemented a checkpoint strategy to persist data to S3 every 30 seconds, minimizing data loss in case of server failure.

To summarize, Symphony is an open-source scalable tool that simplifies the development of collaborative web applications. It provides infrastructure for conflict-free collaboration, leveraging Yjs for conflict resolution and WebSocket for update transmission. Symphony's backend is deployed on AWS using ECS for scalability. With a pub-sub messaging system using Redis, Symphony achieves horizontal scaling, enabling multiple WebSocket servers to handle a higher number of connections. In this video, we evaluated different technologies including Redis, Kafka, and RabbitMQ for a pub sub mechanism. Kafka is a powerful data streaming platform that supports various use cases beyond pub sub messaging, such as event sourcing and log recreation. RabbitMQ, on the other hand, is primarily a message broker that supports a wide range of messaging patterns, advanced routing, and more advanced configurations. Redis, on the other hand, is an in-memory key-value store that supports pub sub messaging, pattern persistence storage, caching, and more.

Although both Kafka and RabbitMQ cater to more complex use cases and offer benefits such as message retention and durability, they are also more complex to set up and manage. Redis, however, offers the lowest latency and easiest integration. For these reasons, we chose Redis for our pub sub messaging system.

To simplify implementation, we used Amazon's Elasticache as a managed service for Redis. This simplified tasks associated with managing Redis nodes, handling data replication, automatic failover, and other server management tasks. By leveraging Elasticache, we ensured high availability and reliability for our messaging system.

By integrating a managed Redis messaging system, we were able to create an internal pub sub messaging system that enables WebSocket servers to exchange state updates for different rooms. Each room is represented as a topic in Redis, and each WebSocket server acts as both a publisher and a subscriber on behalf of the users.

When a user joins a room, the server subscribes to the corresponding topic in Redis. In the example, User 1 and User 2 join the same room on different WebSocket servers, and both subscribe to the room through Redis. When User 1 updates the state of the room, the update is published to Redis, which then pushes the update to all subscribed WebSocket servers. The servers use the list of users for each room stored in memory to send the update to all connected users.

This system allows us to scale horizontally by adding more WebSocket servers and serving multiple active rooms. However, there is a challenge when retrieving the state of an active room. An active room is one that has at least one connected user, and its state must be in memory on one of the WebSocket servers. An inactive room, on the other hand, is a room with no connected users, and its state can be safely retrieved from the persistent store.

To determine if a room is active or inactive, we used a separate data store to hold the location of servers that have the room state in memory. When a user joins a room, the server checks if the state is in memory, and if not, it queries the list of servers from the data store using an API endpoint to retrieve the most up-to-date room state. This approach allows for efficient retrieval of the state without overloading a separate storage mechanism or duplicating state data across all WebSocket servers.

To store the IP addresses of servers, we looked for a performant key-value store capable of handling high throughput with low latency. Redis was a suitable option as it can be configured to store more persistent data, such as session data, while still handling the pub sub messaging system. Another option we considered was AWS DynamoDB, a managed NoSQL database service. We decided to use DynamoDB for session data storage to separate the concerns of messaging and session data storage, preventing potential bottlenecks and ensuring better performance.

Separating the responsibilities of messaging and session data storage in two separate systems improved the architecture's cleanliness and decoupling. It allowed us to optimize each component independently and ensured that the performance of one component did not negatively impact the other. This separation also enabled horizontal scaling and better handling of active rooms, where clients joining active rooms always received the most up-to-date state.

The final step was defining when WebSocket servers should scale. Using AWS ECS Fargate, we defined autoscaling policies that would instantiate new WebSocket server instances based on the average metrics of all servers. Our WebSocket API service aggregated all WebSocket servers, and we configured it to autoscale based on CPU utilization.

However, during further load testing, we encountered unexpected results. The first WebSocket server would consistently fail due to high CPU utilization. Upon investigation, we discovered a misconfiguration with the load balancer's routing algorithm. By default, AWS's Application Load Balancer used a round-robin algorithm to route requests, resulting in an equal chance for new clients to be routed to servers with different CPU utilizations.

To address this issue, we changed the load balancer's routing algorithm to "least outstanding connections." This new algorithm routes new clients to the WebSocket server with the least number of connected users, ensuring a more balanced distribution of load.

After further load testing, we successfully handled 20,000 concurrent users across 5,000 rooms. This was a significant achievement, although we were unable to test with more users due to AWS service quota limits. While it was possible to request a service call to increase the limit, we were satisfied with the results achieved within the given limitations.

Moving forward, we identified some areas for future improvement. One area of concern is the potential replication of a single room state across multiple servers. Different servers could all be holding the same room state in memory, causing unnecessary redundancy. To address this, we could implement a CRDT merge algorithm, which would apply every new update and eliminate the need for duplicate state.

A potential optimization is to assign one process per room, maximizing CPU and memory utilization by limiting the room state and CRDT merge algorithm execution to a single process.

In conclusion, our symphony implementation leveraged Redis as a pub sub messaging system, using AWS Elasticache for server management and reliability. We separated messaging and session data storage using DynamoDB to prevent bottlenecks. We successfully handled an impressive number of concurrent users and identified areas for future improvements, such as eliminating duplicate room states and optimizing CPU and memory utilization. Thank you for joining our presentation on symphony today. If you have any questions, please feel free to ask.