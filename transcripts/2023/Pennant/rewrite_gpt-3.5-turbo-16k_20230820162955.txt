In this video presentation, we will be introducing Pennant, a cloud-based collaborative computational notebook. Pennant runs in a browser and allows users to create cells for text and code. These code cells can be executed on our cloud-based execution engine. Additionally, users can write documentation in formatted markdown cells, all while collaborating with multiple peers on the same notebook in real time. The primary focus of our discussion will be on two problem areas: real-time collaboration and remote code execution. We will address the trade-offs of available technologies to tackle these challenges. Furthermore, we will highlight the inherent constraints of our use case and provide insights into the build process leading up to the alpha release.

Computational notebooks are powerful tools that enable users to write code and documentation side by side, also known as literate programming. These notebooks find key applications in big data analysis, machine learning, and data visualization. An example of a mature notebook interface is Jupyter notebooks, which are widely used in the field. Jupyter notebooks allow users to process large audio datasets for training machine learning models. The interface includes directories for data input and code cells that may take a long time to execute. The tutorial text is included in text cells below the code cells. Notebooks also enable users to modify specific cells and rerun them without executing the entire notebook from the start. This feature is made possible by the persistence of execution results in a stateful execution context.

Our goal with Pennant is to leverage the power of the notebook interface for educational purposes. We aim to transform code snippets from experimental spikes into fully documented and easily teachable code. In addition, we want to support professional notebook users and developers who are looking for a JavaScript peer programming tool. While there are other browser-based computational notebooks available, none of them align perfectly with our use case. Only a few notebooks support multi-user collaboration, and even well-established platforms like Jupyter notebooks have struggled to implement collaboration effectively. Building a performant collaborative application poses technical challenges, such as requiring additional compute power and memory on client browsers. Moreover, notebooks that support JavaScript often use non-standard versions of the language, making it difficult for users who are accustomed to standard JavaScript.

One significant aspect of computational notebooks is the ability to break code into cells and execute them independently in any order. This flexibility allows cells to have a stateful execution context that is preserved between cell runs. In contrast, traditional scripts execute from top to bottom without maintaining any context between runs. For example, in a notebook, a variable can be initialized in one cell, reassigned in a different cell, and its value can be used in a subsequent cell. This order-dependent execution demonstrates the statefulness of execution contexts in notebook applications.

Our top-level goals for Pennant were to create a real-time collaborative experience, a performant user application, and to use standard JavaScript to minimize the need for users to learn a specialized JavaScript version. To achieve these goals, we needed to address several technical requirements: low-latency architecture, safe execution of user-submitted code, and consistent sharing of state across users. While these goals align with the needs of collaborative services, they impose constraints on the code execution engine. In the next section of the video, we will dive deeper into the challenges of code execution engines for collaborative applications.

When it comes to real-time collaboration, one of the major challenges is maintaining a shared state across all users. It is crucial that all users see the same content simultaneously. Another challenge is ensuring minimal latency in sending and receiving updates, allowing users to view updates almost simultaneously. Resolving conflicting user actions, such as when one user deletes a paragraph while another user is editing it, is another important aspect of collaboration. Finally, displaying the presence of other users on the document helps users stay aware of concurrent editing.

On the other hand, designing a code execution engine presents different challenges. Code execution engines take user code as input and produce the expected output. The primary concern is ensuring the safety of the execution engine since users can submit potentially malicious or poorly written code. Performance optimization and flexibility are also critical considerations when designing an execution engine. Additionally, allowing multiple users to access, work on, and execute the same code from different machines in real time is an emerging challenge in this space. Collaborative code execution, in particular, requires all changes to be made on one central location rather than distributed among users.

As we delve deeper into the challenges of code execution engines for collaborative applications, it is important to note that computational notebooks differ from generic code engines. In most code collaboration tools, code can be executed in a stateless fashion, where each code submission can be executed independently on any server. This approach does not require any shared data between different code submissions. However, in computational notebooks, code execution is stateful, and each code submission needs access to the context from previous submissions. This necessitates submitting all code from a notebook to the same engine instance running on the same server. Sending execution context from user to user is extremely difficult, if not impossible. Collaborative code execution, therefore, relies on centralizing execution on a server to maintain one shared history and context for all users.

While this approach may diverge from the model adopted by tools like Jupyter notebooks, it presented an opportunity for us to design and build our solution from scratch. We aimed to create an execution engine that operates collaboratively and is not tied to outdated models. In the following section, we will discuss the implementation details, starting with the collaboration service.

Implementing real-time collaboration in our application was a fascinating journey. One of the first challenges we had to tackle was designing a unified structure that all users could interact with. This structure needed to handle concurrent updates from multiple users seamlessly. To achieve this, we designed a system that allowed users to send updates to a central collaboration service, which would then relay those updates to all connected users. By following this model, we were able to gain insights into usage patterns and application performance, enabling us to implement safeguards for user-submitted code.

State convergence was another critical aspect of our implementation. We developed algorithms to ensure that the state of the notebook would converge across all users despite simultaneous updates. This required solving conflicts when multiple users made changes to the same section of the notebook. Our algorithms facilitated seamless merging of updates, maintaining the integrity of the shared state.

Synchronizing the shared data model across all users was also a significant challenge. We needed to ensure that every user had the most up-to-date version of the notebook. To achieve this, we implemented synchronization techniques that allowed for efficient data transfer and minimized latency. This ensured that users could see changes made by their collaborators in real time.

In addition to synchronization, we also addressed multiple synchronization scopes within the same application. This involved allowing different notebooks to exist within Pennant and ensuring that updates to one notebook did not interfere with the state of other notebooks. By managing multiple synchronization scopes effectively, we provided users with a seamless experience while collaborating on different notebooks.

Lastly, we incorporated real-time presence and awareness functionality into Pennant. This feature allowed users to see who was currently active on a notebook, providing visibility and promoting effective collaboration. By displaying presence information, users could avoid conflicts and coordinate their efforts more efficiently.

In terms of infrastructure, we separated the collaboration service, code execution engine, and web server into distinct components. This separation allowed us to scale each component independently based on its specific needs. The code execution engine required isolation to ensure the safe execution of user code. Placing it on separate hardware and interacting with it via API added an additional layer of security. On the other hand, the collaboration service had higher bandwidth requirements and constant connectivity needs to synchronize state and user presence data. By separating these components, we reduced the complexity of scaling out our infrastructure in the future.

Overall, implementing real-time collaboration in a computational notebook presented both challenges and opportunities. By carefully designing our infrastructure, developing algorithms for state convergence, and utilizing synchronization techniques, we were able to create a performant and collaborative user experience. Additionally, by separating the collaboration service, code execution engine, and web server, we laid a solid foundation for scaling and future development. In the final stages of our build process, we focused on ensuring a seamless user experience and maximizing the educational potential of Pennant. With these efforts, we are proud to introduce Pennant as a cloud-based collaborative computational notebook that supports real-time collaboration and remote code execution. In order to enhance the security measures against malicious code, it is possible to safely run user code by placing the execution engine on separate hardware and interact with it through an API. This additional layer of security adds an extra level of protection. 

The collaboration service has the highest bandwidth needs and requires a constant connection to all users, as docent state and user presence data are sent across the network. Given the bandwidth and connection requirements of the collaboration service, it is likely that it will need to scale before the execution engine. 

To reduce the complexity of scaling from a monolithic structure later, we have separated out the services in our initial build. Now, let's discuss the implementation of the collaboration service. 

The choice of whether the collaboration service should happen on premise infrastructure is not predetermined. One possible model is a peer-to-peer model, where updates from every user are broadcast to every other user currently on a notebook. In this model, it would be the responsibility of the client applications to merge updates and maintain docent state. While the technology underlying pennant can support a peer-to-peer model, it is not suitable for our needs. 

The peer-to-peer model does not meet our requirements for security, as there is no way to control and sanitize user inputs. Additionally, it is less performant for users, as their browsers need to maintain multiple connections. Therefore, we have opted for the more conventional client-server model. In this model, every update is sent from a user to our collaboration service and then relayed to all connected notebook users. This model provides us with greater insights into usage patterns and application performance and allows us to implement more safeguards for users to submit code. 

Although this adds an additional node and introduces more latency into the system, the performance is still fast enough to provide an elegant collaborative experience. This approach requires more complexity on the back-end in the collaboration service, but reduces complexity inside the client application. 

Now, let's discuss the implementation details of the collaboration service. We started by designing a unified structure that allows all users to interact with it. This structure had to be able to handle concurrent updates while ensuring state convergence. 

To achieve this, we implemented conflict-free replicated data types (CRDTs). CRDTs are data structures that enable multiple computers to update a shared data structure independently and concurrently. They guarantee eventual consistency by automatically resolving conflicts, even if replicas temporarily differ. 

One key property of CRDTs is uniqueness, where every character is assigned a unique identifier known as a timestamp. The timestamp consists of two components: the user identifier and an incrementing clock indicating the sequence of operations. 

Concurrency in CRDTs is handled using an algorithm that prioritizes lower user IDs when conflicts occur. This ensures that all replicas can resolve conflicts in the same way and converge to the same state. CRDT operations are also associative, commutative, and item potent, further ensuring consistency in distributed systems. 

After researching various CRDTs, we chose Yjs, which is known for its memory efficiency. Yjs provides robust conflict resolution, undo/redo management, and the ability to handle network partitions and delays. It allows local changes to be accepted even when a connection is lost and merges them with the global state when the connection is restored. 

With the unified data structure and CRDT algorithms in place, our next step was to synchronize the shared data model across all users. We achieved this by implementing a pub-sub model facilitated by connection providers. 

Client-side providers handle all user interactions and ensure that every modification made by a user is communicated to the backend. They are responsible for displaying updates in real time. On the other hand, backend providers coordinate real-time data exchange on the network. They receive messages from client-side providers, process them, and then send them to all other active clients. This ensures that everyone remains in sync. 

In our application, each cell contains a code editor or markdown editor bound to a Yjs data tech. Traditionally, collaborative editing has a one-to-one relationship between an editor and a websocket provider. However, this can be inefficient when dealing with multiple editors or docents. 

To address this issue, we took a more holistic approach with Yjs. By using nested Yjs data types, we established a one-to-one ratio between an entire notebook and a websocket provider. This reduced connection overhead and resulted in a more efficient and cohesive system. 

In order to handle multiple collaboration spaces, such as different notebooks, we implemented the concept of rooms. Rooms are metaphorical shared spaces where users can collaborate on a notebook. Each room is identified by a unique name, and the backend provider manages updates between individual rooms without interference from others. 

Now that we have laid the foundation of the collaboration service with a unified data structure, implemented CRDTs, and handled multiple collaboration spaces with rooms, let's focus on injecting life into the system by implementing real-time presence and awareness. 

Real-time collaboration requires knowing who is active and what they are doing. This awareness is essential for reducing conflicts and ensuring smooth workflow. To facilitate this, we implemented an awareness protocol within our CRDT framework. 

Awareness is facilitated by an object controlled by a specific protocol. The client sends an awareness message, which is then broadcasted by the server to all clients. Each client receives awareness messages from all other connected clients. This allows team members to identify potential conflicts and reduce the chances of overriding or conflicting with others' work. 

All awareness data for a client is ephemeral but uses the same websocket connection for communication. This ensures that all pieces come together seamlessly. 

In summary, we have designed a system that allows users to safely run code by placing the execution engine on separate hardware and interacting with it through an API. Separating the collaboration service from the execution engine reduces complexity and enhances security. 

The collaboration service follows a client-server model, which relays updates from users to all connected notebook users. This provides an efficient and secure collaborative experience while allowing for future development. 

The implementation of the collaboration service involved designing a unified data structure, implementing CRDTs for state convergence, synchronizing the shared data model across users, and handling multiple collaboration spaces through rooms. 

The real-time presence and awareness feature provides visual cues for team members, allowing them to identify potential conflicts and work more efficiently. 

Moving forward, the next challenge is the implementation of the code execution engine. We have two options for where to execute code: client-side or server-side. After considering factors such as flexibility, collaboration, and security, we have chosen server-side execution as the best option. 

Server-side execution requires addressing challenges such as reducing code cell execution wait time, improving system reliability, and implementing security measures. To reduce execution wait time, we have decoupled the API logic from code execution, allowing the API server to quickly respond to requests. 

We also minimize the number of cells executed per request, running them individually against a long-lived process that persists the execution context. This approach enables collaboration and reduces overhead. 

To ensure system reliability, we use multiple background workers dedicated to each notebook for executing code asynchronously. This allows for scalable code execution needs and prevents system crashes. 

Finally, to implement security measures, we have measures in place to mitigate the risks of executing untrusted code. This includes using a sandbox environment, limiting system resources, and implementing code review processes. 

By carefully considering these factors and implementing the necessary measures, we aim to provide a robust and secure code execution engine that meets the requirements of our collaborative coding platform. The discussion begins with the decision of where to execute code, with two options: client-side or server-side execution. Client-side execution offers faster processing and features like rendering front-end code. However, executing code on multiple users' browsers is not feasible as it leads to inconsistent executions and outputs. The client-hosted model allows one user to run code for their group, but system configurations and network reliability become major concerns. Therefore, server-side execution is the best option, despite being slower and more expensive to host. It ensures a reliable collaborative experience for users.

There were challenges faced with server-side execution, including reducing code cell execution wait time, improving system reliability, and implementing security measures. To reduce code execution wait time, the unpredictability of user code needed to be addressed. waiting for the code to be evaluated can cause head of line blocking and dropped connections. In some cases, an infinite loop can crash the system, rendering it inaccessible. To overcome this, the restful API logic was decoupled from code execution. When a user runs a cell, the API server immediately sends execution requests to a notebook queue and responds to the client with a token. Background workers execute the code asynchronously, ensuring quick request handling, preventing head of line blocking, and allowing for scalability.

Another way to reduce execution time is by minimizing the number of cells executed per request. Instead of running the entire notebook's code as one script, individual cells are executed. Penance workers, long-lived processes, persist execution context objects in memory, allowing for more responsive and faster execution. By avoiding cold starts, users can create new variables, functions, and objects in one cell and reference them in subsequent cell executions.

System reliability was improved by containerizing the workers. Each worker runs concurrently and in isolation from others, preventing long-running cells from blocking other notebooks. In case of worker failure, other workers can continue functioning normally. Resource Management was also important to ensure the health of the host machine. Docker control groups limited each container to 100 megabytes of RAM and enforced compute limits. Script timeouts were implemented to prevent excessive resource usage. System metrics were monitored to regulate the deployment of additional workers during high load. Containerization minimized system downtime.

Security measures were crucial due to the execution of untrusted code. Execution context objects were used to make code execution stable and confine it to an isolated environment. Vm2, a sandboxing library, guarded against JavaScript escapes. Multiple layers of security were implemented by combining vm2 with container-level sandboxing. Container escapes, which could grant unauthorized control of the host system, were warded off. Gvisor, a runtime providing virtual kernels, was initially considered but was found to have limitations and increased resource requirements. Instead, privileges were stripped away from workers to minimize the chances of container escapes, resulting in a secure system.

The overall architecture of the Pennant system consisted of three services: web server, collaboration service, and execution engine. The web server handled user login and provided access to their notebooks. It used a DynamoDB database to retrieve notebook names and IDs. The collaboration service facilitated real-time collaboration between users, with a load balancer routing them to a websocket server. Notebooks were stored in an AWS S3 data store, fetched when needed, and saved back to the database. The code execution service, asynchronous in nature, received code submissions and routed them to the appropriate Docker container. Results were then shared among users through the collaboration service.

The team was asked about their experience working together. They emphasized the importance of teamwork in tackling the project's complexity and the scope of the challenges they faced. Collaboration allowed them to research various aspects, from security to the number of connections. It was a fun and rewarding process, enabling them to explore different technological areas and build a cohesive system.

When asked about the most difficult part to implement, the team mentioned synchronizing real-time collaboration across various browsers and devices. They faced issues with compatibility, but through collaboration and multiple approaches, they found a solution that ensured synchronization across all browsers and modes.

The team was also asked about the motivation behind choosing this project and if they would change anything if they were to start over. They saw an opportunity to make an impact in the collaborative workspace, contributing to the changing landscape of remote work. The project provided them with a platform to showcase their problem-solving skills and practical thinking, which they believed future employers would value. If they were to start over, they mentioned they would have dedicated more time to address system limitations and compatibility issues.

In conclusion, the team successfully implemented a robust and secure system for executing untrusted code. They overcame challenges related to code execution wait time, system reliability, and security. The Pennant system allows for server-side execution, minimizing code cell execution wait time and providing a reliable collaborative experience. The use of containerization and sandboxing techniques ensures system reliability and security. The team worked collaboratively to build a system that offers real-time collaboration, efficient code execution, and robust security measures. I started my journey as a data analyst, and I found the ability to experiment with code cells and take descriptive notes in one place to be extremely valuable. I thought it would be great to bring this concept to JavaScript and web development, as it would allow users to keep their notes in one place and collaborate seamlessly with peers. That's why we were drawn to Pennant in the first place. And I must say, it delivered with its complex problem-solving capabilities and interesting challenges.

Initially, I was particularly interested in exploring the peer-to-peer models and how the underlying technologies could support both peer-to-peer and client-server approaches. It was surprising to see how elegantly the technologies could be configured to convert the project into a distributed peer-to-peer application. This technological excitement was a major motivating factor for me. The scope of the project was extensive, exploring areas such as containerization, persistence, and making infrastructure choices, all of which presented significant challenges that we were eager to tackle.

The reason we chose this project was that we recognized an opportunity to make an impact in the collaborative workspace. With remote work becoming more prevalent, we saw a gap in tools that catered to both code and markdown editing. Our goal was not just to create another tool, but to contribute to the changing landscape and build something that could genuinely improve the way people work together. We believe that this project demonstrates the kind of thinking and practical problem-solving skills that future employers will value. Additionally, I was interested in working on something similar to a Python notebook, as it is relatable and familiar to many people, including potential employers.

If we were to start over with the same project, we might change the distribution of involvement among team members. Given the project's size, each person became an expert in one vertical, and while everyone had some involvement in different areas, we would have liked to explore more and try different things. However, I must add that the learning curve was steep, especially when it came to implementing state management with React. A significant amount of time was spent adapting tools and understanding the results and challenges we faced. Custom implementations of our tooling were necessary, and while it was a fantastic learning experience, it was also time-intensive.

We often found ourselves underestimating the time required to solve challenges. What seemed like a simple task would lead us down multiple rabbit holes, resulting in iterations and numerous unforeseen difficulties. Looking back, I realize that I could have benefited from spending more time exploring the problem before jumping into coding or trying to simplify it. This would have helped us address certain issues, especially when scaling the project towards the end.

The most proud and surprising moment for us was when we figured out the client-side application's synchronization needs in the client-server model. After some prolonged roadblocks, we finally cracked it and were amazed at how robust and bug-free the state synchronization turned out to be. It took hundreds of hours of work from all of us to establish and document the synchronization pattern. Experiencing its exceptional performance afterward was truly a point of pride.

Seeing the UI develop to a point where we could conduct usability tests and try it out ourselves was particularly rewarding. Working on data structures and algorithm problems using the notebook and realizing its real-time functionality was a significant highlight. It made us feel that we had created something functional and exciting as we could take notes, collaborate, and even paste pictures. Witnessing the different team members accomplish various technical feats was also gratifying. Personally, I struggled with getting the notebook to function correctly with JavaScript, but thanks to Michael's expertise, the challenge was overcome, showcasing the power of teamwork. Additionally, there was a moment when we were dealing with bugs, but in the process of optimizing code execution, we unintentionally solved some of them. It was a pleasant surprise and a good feeling.

In conclusion, we are grateful for everyone's support and contribution during the development process. Despite the obstacles and challenges, we are proud of what we have achieved with Pennant Notebook. If you want to learn more about Pennant Notebook, you can visit our website at www.tripendent.com and open your own notebook to experience its functionalities. Thank you all for attending our talk, and once again, thank you for your support.