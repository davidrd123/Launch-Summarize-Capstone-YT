foreign thank you for coming today well today we'll be presenting pennant which is a cloud-based collaborative computational notebook so pennant runs in browser and allows users to create cells for text and code users can execute code cells on our cloud-based execution engine documentation can be written in formatted markdown cells all this happened seamlessly while collaborating with multiple peers on the same notebook in real time we'll face the two primary problem spaces real-time collaboration and remote code execution presentation will discuss the trade-offs of the available Technologies to address these challenges we'll also discuss the inherent constraints of our use case and finally we'll discuss the build process as we iterate it up to the alpha release so computational notebooks are a tool that allows users to write code and documentation side by side and what's known as literate programming most common use cases for computational notebooks are for Big Data analysis machine learning and data visualization on the left here you can see a screen capture of Jupiter notebooks Jupiter notebooks are synonymous with computational notebooks so this is an example of a fully featured mature notebook interface it's a Jupiter notebook set up as a tutorial for processing large audio data sets to train a machine learning model you'll notice the directories of data input on the right there's a considerable quantity of data to be processed and the left we can see a large code cell which may take a long time to execute notice the tutorial text is included in the text cell below the first code cell further down in the tutorial there's a cell which visualizes a specific example from a large set processed in the previous slide notice how I'm able to change trivial details in this cell and run it over and over without running the time intensive first cell again the result of the execution of the first cell are persisted to a stateful execution context now I'm free to access that execution context in these subsequent code cells for this project we wanted to Leverage The Power of the notebook interface for educational purposes with pennant code Snippets can be transformed from experimental spikes into fully documented and easily teachable code we want to support professional notebook users and developers looking for a JavaScript peer programming tool there are other browser based computational notebooks none of them match our use case exactly only a few notebooks support multi-user collaboration Jupiter notebooks has been stumbling in their implementation of collaboration for almost 10 years building a performant collaborative application is also technically challenging collaborative applications can consume more compute power and memory than is necessary on their client browsers python is also the default language for most computational notebooks notebooks which support JavaScript tend not to support standard JavaScript here we can see the network tab for a different browser-based notebook the browser application is opening a streaming connection to the server for each code cell the browser becomes sluggish as the number of cells in the notebook grows many notebooks require that basic idiomatic parts of JavaScript such as variable declarations initializations and function definitions must be handled in a non-standard way for example observable which is a visualization oriented notebook disallows the use of the keywords let and const so we could say that the user needs to write an observable flavored JavaScript not standard JavaScript for Penance educational use case we need students to be able to use standard JavaScript the particularities of JavaScript like variable declaration or function hoisting present difficulties for a notebook interface with a notebook interface we have code being split into cells we can run every cell in the notebook in order just like a script the difficulty arises in that notebooks allow cells to be run independently in any order the cell is on the left and the cells on the right contain the same code in the same order it's an initialization of a variable a logging of that variable and a reassignment of that variable script on the left will only ever execute from top to bottom the results will never change the reassignment at the bottom will never be utilized The Notebook interface is not locked into this linear execution this contrived example we could first initialize our variable by running the first code cell we can immediately reassign that variable in the third code cell and then when we log the variable in cell 2 we'll see the string bar so we know that the variable state was impacted by our order of execution so we can say that execution context is stateful in Notebook applications the context is preserved between cell runs this will be explored in Greater depth when we discuss the execution engine our top level goals for pennant were real-time collaborative experience the performant user application which is fast and preserves user data and use real JavaScript so that users don't need to learn a pennant flavored JavaScript in order to begin using the product the recurrent technical requirements to meet the top level goals are low latency architecture safe execution of User submitted code and strongly consistent sharing of State across users the needs of the collaboration service differed quite a bit from the needs of the execution engine Judah will now take us deeper into the challenges of code execution engines for a collaborative application so our problem Space is really two completely separate problem species one's real-time collaboration and one's remote code execution however there's a really interesting crawl space at the intersection of these two which right now is not only being explored by us but also by large companies and large Open Source Products first here are a few General challenges in the collaboration space these problems are maintaining a shared State across all users so all users see the same thing having minimal latency in sending and receiving updates so users can see the same thing at nearly the same time resolving conflicting user actions think like one user deletes a paragraph while another user is writing in that paragraph there are many ways of resolving that situation and finally showing the presence of other users on the document okay now here are some challenges in designing code execution engines a code execution engine is just any program that takes a user code AS input and Returns the expected code output now the most important problem for all code execution engines is to be safe since we're giving client users the ability to submit code this opens the door to accepting malicious or error written code that can spill out to affect the rest of the program other issues we faced were in trying to optimize our code engine for Speed and flexibility a third issue a relatively new issue for this space but a growing issue for products like Jupiter vs code replit among others is to allow for multiple users to access work on and execute the same code from different machines in real time this collaborative code execution is where our two problem spaces overlap and this is where we were focused okay now you might be thinking okay well that's coderpad and it is but coderpad is not a computational notebook in computational Notebook engines are more complex and work differently than generic code engines the differences are what make it so difficult for Jupiter to make their notebooks collaborative despite trying to do this for many years encoderpad and most code collaboration code can be executed in a stateless fashion which means each time you hit play the code can be executed anywhere on any server regardless of where your teammate's code has been sent each code submission does not access any shared data from any previous submission so you can see here that the console log statement on the right has no access to the value of x from the first run in pennant and other notebooks code execution is stateful each code submission needs access to the context from previous submissions this means all code from a notebook needs to be submitted to the same engine instance that means the same instance on the same server why can't changes encode execution context just be shipped from user to user like document updates Nobody Does this because it's extremely difficult or even impossible to send execution context from user to user therefore code execution needs to be centralized on a server this runs against Jupiter notebook's model of code execution on a user's machine but it brought us to our solution which is cloud-based not user based collaborative code execution just to make this clear if two users were submitting code from the same notebook and each time they hit play the code was submitted to a different engine instance The Notebook would not work as expected here user 1 is submitting his code and it's going to one engine instance maybe on their machine maybe on a server user 2 is submitting her code and it's going to another engine instance maybe on her machine maybe on another server even though they are collaborating on the same document and even though the output can be synchronized once they get it the output is not correct so that means that unlike text editor collaborations where changes can be made on your own version and then shipped to all other versions code collaborations require all changes be sent to and made on one central location this Central bottleneck actually benefits code execution engines because it ensures that the users share one history one context in which they all run their code however this brings us back again to the collaboration space advances in document collaboration over the past 20 years have actually gone against storing one Central copy of a document users instead ship small updates to each other and they merge these updates into their own copies of the document as they receive them again this model would not work for code execution because collaborative code execution relies on a centralized execution context that everyone submits code to so our problem Space is really two problem spaces code execution and real-time collaboration the intersection of these problem spaces has been explored by other companies and open source projects and the needs of collaborative code execution set limits on our code execution architecture however we were in a better position than existing companies in that we were designing and building our solution from scratch we could build the engine the correct way to run code collaboratively and weren't tied to any outdated models I'll pass it off to Richard now for the implementation details now I'll break down the implementation for our two problem domains we established these guiding principles for most of our decisions and trade-offs we wanted a performant user application we wanted notebook state to seamlessly merge updates from other users without needing to use any sort of system of lockouts and we wanted to use the most standard versions of coding language as possible shouldn't be a special variance of JavaScript specific dependent because we want this tool to be useful in the education sphere we also wanted users to be able to store their notebooks in the cloud like a typical web application this is the broadest overview of the pennant infrastructure to keep in mind as we've discussed the implementation we have a service for our code execution engine we have a web server for our single page react application as well as for user management lastly we have the collaboration service which will be responsible for the bulk of the state synchronization between users all these tasks could be accomplished on the same piece of infrastructure say one virtual private server but consider the specific needs of the execution engine and the collaboration service the execution engine needs to be as isolated as possible to safely run user code putting the execution engine on separate hardware and interacting with it via API adds an additional layer of security against malicious code the collaboration service has the highest bandwidth needs to require a constant connection to all users as documents State and user presence data are sent across the network given the bandwidth and connection needs of the collaboration service it is likely to need to scale before the execution engine the execution engine is likely to need to scale before the web server beginning our with our beginning our build with these Services separated out reduced the complexity of scaling out from a monolithic structure later now we'll begin discussing the implementation of the collaboration service it's not a given that the collaboration service happens on pennant infrastructure so let's take a second to examine that choice one model which is available to us was a peer-to-peer model in which updates from every user will be broadcast to every other user currently on a notebook it would be the responsibility of the client applications to merge updates and maintain document state the Technology's underlying pennant can support a peer-to-peer model it's not strictly necessary that we have updates of state or presence and awareness touch a centralized piece of infrastructure this would be the lowest latency solution because there's no intermediary node between users so it also reduce the complexity of our back-end infrastructure however this the peer-to-peer model doesn't meet our needs for security as there's no way to control and sanitize user inputs it's also less performant for users as their browsers need to maintain multiple connections instead we opted for the more conventional client server model where every update is sent from a user to our collaboration service and then relayed to all connected notebook users this gives our team greater insights into usage patterns and application performance in order to facilitate future development it allows us to implement more safeguards for users to submitted code this does add an additional node and thus more latency into the system despite this the performance is fast enough for an elegant collaborative experience this requires more complexity on the back end in the collaboration service but less complexity inside the client application now Maron will discuss the implementation details of the collaboration service thank you Richard so implementing real-time collaboration in our application was a fascinating journey and I'm excited to take you through many of the steps it took to accomplish it so first I'll begin by discussing how we designed a unified structures that all users could interact with next I'll dive into algorithms and how they have allowed us to ensure State convergence from there I'll move on to how we synchronize the shared data model across all users then I'll discuss how we handle multiple synchronization Scopes like different notebooks within the same application finally I'll focus on the human aspect and how we implemented real-time presence and awareness so let's start with the shared data model so deciding on the right data model can significantly affect many parts of your application in our case the shape of our data could either simplify or complicate the task of managing State between multiple users so imagine a scenario where concurrent updates are happening to multiple replicas this can easily lead to inconsistencies so we found ourselves asking how can we allow multiple users to work on the same document seamlessly and how can we resolve those inconsistencies that are bound to arise so we obviously needed efficient algorithms for State convergence and conflict resolution so the answer wasn't immediately apparent but after some research we found a powerful solution in conflict-free replicated data types or crdts so crdts are data structures that enable multiple computers to update a shared data structure independently and concurrently they guarantee eventual consistency by automatically resolving conflicts even if replicas differ temporarily so crdts have many Key Properties one of them is uniqueness so every character is assigned a unique identifier which internally is known as a timestamp so first is the user identifier the user who performed the operation and second is an incrementing clock which indicates where in the sequence of operations the operation occurs so for example the left diagram here shows the same user user 1 executing two operations both of which are insertions so starting with f at clock 0 and then o at clock one and it's worth noting that this is a monotonic clock that increments with each operation or update and does not actually represent time so then on the right you see greenbox indicating that user 2 has executed an insertion of the character o at clock 2. so the result becomes Foo now let's look at concurrency so the crdt algorithm handles conflicts uniquely as seen in this diagram starting with w x y z so at clock zero two simultaneous insertions occur between W and X by user 0 and 1. the algorithm prioritizes lower user IDs executing user zeros insertion first and user ones second resulting in w a b x y z and you might be asking yourself why favor lower user IDs the answer is that it doesn't really matter we could prioritize higher user IDs instead but what's important is to have a consistent Rule and stick to it so that all replicas can resolve conflicts the same way and converge to the same state so crdt operations are also associative and commutative meaning operations can be grouped and applied in any order they're also item potent so duplicate or repeated operations don't change the outcome when all these properties help to maintain consistency in distributed systems they ensure that variations in the order of event delivery or repeated message delivery do not lead to inconsistencies so our search for the optimal crdt led us to ygs which stood out due to its optimizations currently ranking as the most memory efficient crdt so with my.js we had robust conflict resolution undo and redo management and the ability to handle Network partitions and delays so if a connection is lost ygs continues to accept local changes and will merge these with the global State when the connection is restored and this is demonstrated on this uh in this video so I have a notebook open in Firefox on the left and Chrome on the right the Wi-Fi is currently turned off so the browsers are disconnected from the network on the right edits are being made while offline and then when I reconnect to the Wi-Fi without any intervention Firefox on the left automatically syncs with the edits made in Chrome on the right so after designing our shared data model and implementing algorithms for State convergence it was now time to move on to synchronization so in this step we had to bind our editor content for the CID team and sync the shared data model across all users so let's explore how we made that connection so our app enabled the pub sub model that was facilitated by connection providers so client-side providers handle everything you see and interact with within the application the ensure every modification made by their user is communicated to the backend mainly they're responsible for displaying updates in real time then we have the backend providers so these coordinate real-time data exchange on the network they receive messages from each client-side provider process them and then send them back out to all other active clients essentially they ensure that everyone remains in sync so so in our app each cell contains either a code editor or markdown editor bound to a white Jazz data Tech and traditionally in collaborative editing there's a one-to-one relationship between an editor and a websocket provider this structure is simple and reliable but can lead to inefficiencies in scenarios involving multiple editors or documents so in this design each editor requires its own connection between consume more resources and complicate synchronization between different parts of the application but with pennant we took a more holistic approach so by using nested ygs data types we established a one-to-one ratio between an entire notebook and a websocket provider this not only reduced connection overhead but also resulted in a more efficient and cohesive system so building on our one-to-one notebook to provide a ratio let's focus on how real-time communication happened between users and our backend provider so while our system leverages the same client-side websocket provider to manage connections each active client initiates its own websocket connection to the back end so this setup efficiency handles real-time updates between users and the server and ensures that changes are both sent and received promptly and for added persistence we have an S3 bucket that takes periodic snapshots of The Notebook and in managing many contexts our providers encapsulated notebooks in separate rooms so you can imagine rooms as metaphorical shared spaces where users can collaborate on a notebook each room is identified by unique name and all users connected to that room can interact in real time and the backend provider takes charge of managing updates between those individual rooms without interference from others so just to recap so far we had laid the foundation of each notebook with the unified data structure for collaboration we ensured all users see the same data simultaneously by implementing crdts we used connection providers to create a unified view for all users no matter where they are and we handled multiple collaboration spaces like different notebooks by using rooms so now all that was left was injecting life into the system by relaying real-time presence and awareness so in real-time collaboration knowing who's active and what they're doing is essential this isn't just about singles online it's about understanding the workflow so having an awareness protocol in place helps in relaying those visual cues so this way team members can identify potential conflicts and reduce the chances of overriding or pushing work that might be conflicting with others and this awareness um is facilitated by an object that's controlled by specific protocol within our crdt framework this object communicates through broadcast messages so the client sends an awareness message which is broadcast by the server to all clients and then the client also receives awareness messages originated from all other connected clients and it's worth noting that all awareness data for any given client is ephemeral but still uses that same websocket connection mentioned earlier for communication so how do all of these pieces come together so here's how first a user interacts with the application for example by typing then those actions get translated into transactions on the shared data model then the connection provider broadcasts the updates to all peers then every peer integrates the change into its own version of the shared data model finally the user's view reflects this alteration and all versions of the app remain in sync so by carefully selecting Technologies we were able to design a system that achieves almost instant propagation of changes the main elements that made this possible were the use of websockets for communication integrating memory efficiency idts for having concurrent updates backend and client-side providers coordinating together and ensuring problem communication across clients and optimal optimized data structures within y.js which was our secret weapon in reducing potential latents so with a real-time collaboration framework in place we've set the stage for the next challenge which was the implementation of our code execution engine and to dive into the details of how we brought this to life I'll now hand over to my teammate Michael thanks Marwan let's begin by reviewing our requirements for code execution we need code to run with the flexibility of a computational notebook and execution environments need to be fully collaborative meaning that collaborators should be working with a shared State and have consistent outputs lastly we need robust security measures for executing untrusted code we'll start a discussion with where to execute code we have two broad options client or server-side execution client side is faster and provides features such as the rendering of front-end code the leftmost diagram illustrates the multi-engine setup all users execute code on their own browser we know this isn't viable since multiple environments means executions and outputs can't be made consistent the middle diagram is of a client hosted model here one user runs all the code for their group this is collaborative but variants user system configurations and network reliability become our chief concerns here this means server-side execution our best option although it's slower and more expensive to host we're able to create a more reliable collaborative experience for our users we had a few challenges with server-side execution reducing code cell execution wait time improving system reliability and implementing security measures we'll start with how we reduced code execution wait time the unpredictability of user code leads to some problematic scenarios in this example our server receives run cell requests from three different notebooks one of them is a recursive Fibonacci function call while the others are two logging statements foreign receives the Fibonacci code first well the request needs to be held open by the server until the code is evaluated so other users have to wait this leads to head of line blocking dropped connections and results in an overall unsatisfying user experience and here's a worst case scenario some notebook sends an infinite Loop and when it's executed it consumes all of the engine's memory and causes the whole system to crash now no one's able to run code and our API can't be reached either all our front end application gets are a series of request timeouts our solution was to decouple our restful API logic from code execution now when a user runs a cell there's no chance of our front-end code getting blocked our API server immediately sends execution requests to a respective notebook queue and then responds to the client with a token from there background workers dedicated to each notebook execute the code asynchronously this asynchronous design enables our API to handle requests quickly and prevents head of line blocking it also allows us to scale our code execution needs independently from our server whether that's vertically or through the deployment of additional nodes the other factor for reducing execution time is to minimize the number of cells that need to be executed per request in other words to run a notebook's code cell by cell rather than as an entire script unlike the short-lived processes used by conventional execution engines Penance workers are long-lived processes that persist in execution context objects in their memory cell contents are run as individual scripts against this context allowing users to create new variables functions and objects and any collaborator could reference those same entities in subsequent cell executions this makes for a more responsive and faster experience by enabling staple cell execution and by avoiding cold starts now we'll move on to system reliability Our Workers are containerized which allows them to run concurrently and in isolation from one another that means that long-running cells from one notebook won't block other notebooks from executing their own code and more importantly if any worker experiences a failure others could continue functioning functioning as normal but it's also important to consider Resource Management since all containers run on a shared host kernel how can we keep the host machine healthy we use Docker control groups to limit each container to only 100 megabytes of RAM and enforce compute limits script timeouts are also implemented by our code execution Library lastly we monitor system metrics so we can stop the deployment of additional workers under periods of high load altogether containerization allows our users to execute code with minimal system downtime let's turn our attention to our final challenge security is the most critical feature of our engine since we're executing untrusted code earlier we mentioned using execution context objects as a way to make our code execution staple but that was only one reason the more critical purpose of the context object was to obscure the actual environment of the worker process from our users in other words the context object is a sandboxing mechanism that confines user code to an isolated execution environment there are however a few JavaScript vulnerabilities that could be exploited rather than patch these manually we've leveraged vm2 a sandboxing library that guards against JavaScript escapes using custom environments with object proxies regardless it's still important to have multiple layers of security and therefore we have a second sandboxing layer at the container level there are various techniques that attackers can use to break out of a container and gain unauthorized control of your host system these are known as container escapes for instance one such attack could Mount the dev director of a host giving an attacker control of a host disk and network devices a common solution that guards against container escapes is g-visor its runtime provides each container with a virtual kernel however as you can see in the table below the runtime severely diminished the number of concurrent workers that we could support at a given time kernel virtualization is expensive and it more than doubles the ram requirements for our containers we needed a much lighter weight approach we significantly minimize the likelihood of container escapes by stripping away as many privileges as possible from our workers we go into more details in our case study but for now we'll say that we've guarded against exploits by hardening our Docker container configurations now if an attacker escapes a vm2 Sandbox it's statistically unlikely that they can also escape the container therefore our configuration secures our system against malicious code while keeping sandboxing mechanisms as lightweight as possible this allows our hosts to support up to 40 active notebooks and 200 active users now we'll turn it over to Judah for an overview of penance spinal system architecture all right thanks Mike Michael let's take a step back and look at the final architecture there are three services the user interacts with them separately so let's step through let's step through them one at a time the web server collaboration service and execution engine in rough chronological order our web server handles logging the user into their dashboard the dashboard contains links to all of their previously created notebooks as well as a link to create a new notebook this service relies on a dynamodb database which can retrieve notebook names and IDs when a user initially accesses a notebook they are using another service the collaboration service a load balancer will route them to a websocket server called the provider server now they are connected to other users of The Notebook or waiting for other users to connect to them if the notebook is in use the notebook is already in memory in the provider server if the notebook is not in use the provider server will fetch the notebook from the AWS S3 document data store when the last user of a notebook disconnects The Notebook is saved back to the database and is removed from memory on the server when a user submits code that code is sent to a third service the code execution service their code is routed through an API server to the correct Docker container dedicated to their notebook this service is asynchronous which in our case means the user pulls for their results these results first go to one client only then are shared out to other users through the collaboration service that concludes the presentation pennant was built by a small team including Richard Cole Marwan zareb Michael rikasa and myself We Now open up for a question and answer session okay so we have a first question here um what was it like working together as a team who who wants to take that question Richard speaking uh it was essential to to build this uh as a team it was just it's too large of a of a project for for one mind and it was really important that we research uh every aspect from the security to the the number of connections um if you if one was to try to do this by yourself uh your technology would be outdated by the time you got around to implementing all the individual features so it was a lot of fun uh to implement it in a team context yeah there was a ton of ground to cover and definitely no one could do it alone uh we definitely need to Leverage all of our efforts all the time for for research and for implementation uh but all together has been a really fun process and uh it's been great working with everyone on the team um we have two more questions that just came in um first question uh it's from Peter uh what was the most difficult part to implement I can I can answer this one maybe this wasn't the most difficult part but it definitely was one of the most significant challenges that we faced and that was synchronizing real-time collaboration across various browsers and devices so at first it would only sync in regular Chrome tabs but not in Incognito tabs then we faced issues where it would only work on Chrome but not when a tab was open in Firefox so we spent quite a bit of time working together on this we went through many different approaches and then we finally found a solution that ensured synchronization between all browsers and browser modes I think that was a great learning experience for all of us but it also gave us a much needed confidence boost to tackle the other uh obstacles in our path it was interesting that we also faced problems with dealing with some of the Technologies are implemented by incredibly small open source projects incredibly small communities which face a lot of challenges with the Elegance of the API and the the documentation sources and then on the opposite end of the spectrum trying to integrate with massive Technologies like AWS which came with sort of the exact opposite set of challenges in terms of how much documentation and the available configuration setups um I was I was led to quite a bit of of whiplash building a cohesive system yeah I'll I'll just add that in this I I also think that um uh a difficulty was when running up against like system limitations like there were some uh servers that we could only work on uh in the cloud uh in certain operating systems um and that made it more difficult um just was more time consuming like we would have to um open up multiple processes on the cloud in order to test them um but that was just because they weren't compatible with uh the computer or operating system that I was working with um so that was difficult and frustrating we we have uh two more questions um first question from show uh how did you come up with this project and I'm sorry I'm actually going to tag along the second question because it's a very related question um questions from Anthony why did you choose this project over other potential projects uh in the context of impressing uh impossible employers sure I could uh maybe take the the first one how we came up with a uh gee I think um we spent a lot of time in the ideation phase there were so many different things that we wanted to tackle um but I think we were all drawn to the idea of creating a collaborative application uh because it seemed to pose a lot of interesting challenges uh more so than anything else that we were interested in um a second part of it is that you know my first experience with learning how to code was with python and Jupiter notebooks so I was trained as a data analyst first and I thought that the ability to experiment with code cells and you know also take these descriptive notes in one place with such a cool thing to have and such a great advantage that I thought it could be neat as well to bring that over to JavaScript or web development the web development world uh just because it would be really neat to keep your notes in one place and also have an easy way to collaborate with with peers you know in a really seamless way so I think that's what Drew us to pennant in the first place and definitely it yeah it delivered like it definitely delivered with all these really complicated problems um a lot a lot of interesting stuff to solve for sure it was uh particularly interested in in using the uh initially been interested in exploring the peer-to-peer models um and the fact that the a lot of the underlying Technologies can support both peer-to-peer and client server uh so elegantly was was a bit of a shock um depending on how you configure this you could reconvert this back to a distributed uh peer-to-peer application really quite quickly um so uh just in terms of sheer technological excitement that was that was a motivating factor for myself and then the the surface area of the project is quite big and it touched uh quite quite a few interest areas containerization persistence choosing the the broad infrastructure choices all sorts of uh big media problems that we wanted to uh dig into um yeah I was gonna take uh Anthony's question so why did you choose this project or are there potential projects the context of oppressing future employers I think we chose this project because we recognized an opportunity to make an impact in the collaborative workspace so uh you know remote work becoming more prevalent I think we saw a gap in in tools that cater to both uh like code and markdown editing um so it was so choosing this project wasn't just about creating another tool it was more about contributing to this changing landscape and building something that could genuinely uh improve the way people work together and I think we believe that it's an embodiment of the kind of thinking and practical problem solving that future employers will probably value one last thing to Anthony's question also um I was also particularly interested in working on something that was similar to like a python notebook um because I thought it would be relatable to a lot of people and potential employees a lot of people have heard of python notebooks um so I thought it would be like more palpable to uh talk about and show um that was also a really big reason why I really wanted to work on this um we do have another question from elubia um if you could start over with the same project would you change anything I think um oh were you going to say something just to fill the space you should go okay um yeah this is an interesting question I think the one thing that I might have changed was maybe the amount of involvement each person had in various domains that is to say like each one of us because this project is so large each one of us became an expert like in one vertical whereas I think I would have appreciated more time uh looking into other areas and trying those out that's not to say that um I mean pretty much every part of this project um everyone's had some involvement in in some way but yeah I think if we were to do it over again I think we would maybe manage our time in such a way that we get to try a little bit more of everything the uh the State Management was quite difficult um to implement with react in terms of once uh once an update has been received and integrated so it starts a large Cascade of event handlers um and that took a a shocking amount of time to adapt from the the tools as their bit as they're written you know so for one text editor for one application for creating a blog post or something really to uh to understand some of the results and challenges we were having took um exploring source code uh line by line and then building Uh custom implementations of a lot of our tooling which was a fantastic experience but incredibly time intensive um so that was just sort of a broad uh learning curve um in terms of our developments as as engineers and how we manage time and expectations uh when building something that complex um the amount of times we thought oh yeah that'll be done in 48 hours and then it presented quite quite a few iterations worth of challenges that was significant definitely a lot of rabbit holes yeah I I think maybe something that uh I was struggling with throughout the project um was I I always like to try to at least plan to finish Things Early um even at like the expense of maybe simplifying it a little bit too much and here I I felt from the beginning like a kind of time pressure right because it's it's a fairly short window for implementing the project so I just think like the more comfortable I would be from maybe doing a second project um I would probably actually take more time to delve a little bit deeper into uh exploring the problem before coding it up or before trying to spike it I think that may have helped solve some things that some issues be brought to you especially when we started trying to scale it at the end we have another question what are you most proud of in your work or surprised of like the the sort of moment of peak Pride was once we figured out the the need of the client-side application um in terms of what it needed to synchronize states in the client server model um how robust it behaved once we finally cracked it because we we hit some fairly prolonged roadblocks in terms of being able to synchronize State remotely and then the the breakthroughs came hard and heavy after that and then I've sort of been shocked at the uh the lack of uh bugs in in that space in terms of State synchronization so once we it took hundreds of hours of work um between all of us to get that synchronization pattern established and documented um and then just how performant it was after that point was was a real point of pride yeah I think um something that stuck out to me was when the UI had come like far long enough that we could actually start carrying out usability tests and try it out on our own and you know uh props to you all those who helped us test uh pennant um and it was cool to test it ourselves like I remember Judah and I working on you know some data structures and algorithms problems using the notebook and you know we were thinking well gee this is actually this is actually working like we could work in real time we could take notes maybe we could paste pictures like this is really neat um and it was yeah that was just like really rewarding to see it all come together and um being able to use it for the first time that was that was really cool there there were some like really cool things that I just saw like every like different people on the team were able to accomplish different like really cool technical Feats like um I I I'll say mine after but at one point I was uh struggling a lot with uh um getting the notebook to uh function correctly with uh JavaScript because JavaScript has uh so many kind of very specific uh limitations with the language um and um I passed it off to Michael and he uh he was able to solve it uh that was like really um like awesome uh so that was cool that was like a great like teamwork example but also like create that Michael uh push it through over the Finish Line um for for me I remember there was a there's one time when uh we were dealing with some bugs um but I wasn't actually trying to solve the bugs I was trying to optimize the code execution uh to make it faster um by instead of writing the uh outputs to a file uh which was like the typical way that we had seen in other remote code execution engines where they would um stream their results into a file um and uh then they would so they'd have to open up a file and file system tear it down every time so uh I was thinking why don't we just use like an array that's in memory I'll probably be much faster and easier to deal with and so just delving in kind of to uh how to make that work um and just as a side effect we ended up solving a couple bugs uh that was a really good like feel good moment so many bugs I I remember that that day that was such a huge optimization that I think uh you cleared maybe like four or five cards off the off the bug board like with one go so yeah definitely a super cool yeah yeah definitely really be proud of that's that's awesome all right that was it for the questions um if you want to learn more about uh pennant notebook um you can go to www.tripendent.com um and uh you can open up your own notebook and try for yourself um thank you so much for attending uh our talk and um yeah thank you again bye-bye thank you everybody thank you thanks 