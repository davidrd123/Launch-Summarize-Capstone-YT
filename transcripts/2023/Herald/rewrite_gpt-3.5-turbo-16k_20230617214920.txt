Harold is an observability solution that simplifies the deployment of the elk stack. The elk stack is a popular set of tools used for monitoring the health and performance of software systems. Harold allows developers to collect and explore telemetry data, including logs, traces, and metrics, through a single user-friendly interface. In this presentation, we will discuss what observability is, its importance, and the challenges involved in implementing an observability solution. We will also look at existing solutions in the observability space and how Harold fits into this solution space. Additionally, we will provide an overview of Harold and its functionalities, as well as the design decisions and implementation challenges faced in building it.

Observability refers to the ability to understand how a system is functioning based on its outputs and behaviors. Three types of telemetry data, known as the three pillars of observability, are commonly used: logs, traces, and metrics. Logs are detailed records of events or messages generated by a software application or system. They provide information about specific events or actions, such as time stamps, message content, severity levels, and contextual information.

Traces involve analyzing a software system by collecting data about the different stages of a request as it moves through various components or services. A trace consists of one or more spans, where each span represents a specific piece of work performed by a service within the request path. Spans contain important information, such as start and end times, and metadata relevant to understanding the work. Traces help identify the services a request passes through and how they interact, allowing engineers to pinpoint performance bottlenecks and improve user experience.

Metrics are like vital signs for a software system. They provide a numeric representation of data measured over time intervals. Metrics help developers understand the health of a system by studying performance goals and baselines. They allow developers to track whether a system is meeting its targets and catch problems before they become critical.

Logs, traces, and metrics work together to provide observability. A developer can use these three types of data to diagnose issues and improve system performance. For example, if a developer notices increased response time and error rates on a web application's checkout page, they can use metrics to identify the issue. They can then use tracing to pinpoint where the issue is occurring, and logs to investigate the root cause. Having insight into all three pillars provides complete visibility of the system's health and performance.

To aggregate telemetry data into a single location for visualization and analysis, several smaller problems need to be solved. The first problem is data collection, which is usually achieved using a collection agent installed on each component of the software system. This agent collects data and sends it to a central location. However, before the data is shipped, it needs to be processed and transformed into a suitable format. This is where a data processor comes in.

The central location requires a data storage component that allows querying for visualization and analysis. It should handle continuous data inflow and enable efficient real-time data analysis. Finally, to visualize the data, an intuitive and user-friendly UI is necessary. In summary, a complete observability solution involves data collection and shipment, data processing and transformation, data storage, and data visualization.

In the observability space, there are existing solutions from various companies that aim to meet developers' needs. These solutions provide ease of setup and rich features, including infrastructure monitoring, network monitoring, and error tracking. However, some developers may be concerned about data and infrastructure ownership. Commercial solutions may require relinquishing control over data and infrastructure, which can be problematic for teams working with sensitive data or in highly regulated industries.

To address these concerns, open-source observability tools are available as cost-effective alternatives. These tools offer flexibility in terms of data ownership and infrastructure. However, deploying and managing these tools can be complex, requiring substantial time and expertise. This complexity is mitigated with commercial solutions, but those come at a cost and may create vendor lock-in situations.

Harold bridges the gap between commercial and open-source solutions. It is an open-source observability solution that simplifies the deployment of the elk stack. The elk stack is a popular set of open-source tools commonly used for log management and analysis. It also provides tools for trace and metric data. Harold abstracts away the complexity of setting up open-source tools and allows development teams to maintain data and infrastructure ownership. The only cost associated with Harold is the provisioning and use of AWS resources.

Harold is specifically designed for growing applications where monitoring health and performance becomes increasingly important. It is built on top of the elk stack, which is battle-tested and widely used. While other open-source tools can be combined to create an observability solution, managing these tools can be complicated, requiring familiarity with separate documentation for each tool.

The elk stack, on the other hand, is managed by a single organization, Elastic. Elastic provides unified documentation for the entire stack, making troubleshooting easier. The elk stack's comprehensive documentation, strong community support, and popularity make it an ideal choice for developers new to observability. Additionally, commercial solutions also use the elk stack in their offerings.

Setting up the elk stack can be challenging, especially for developers new to observability. The configuration details for each component can be overwhelming. However, Harold simplifies the process by abstracting away this complexity. With just a few commands, developers can quickly get started with Harold. It provides a pipeline that includes data collection and shipment, data processing and transformation, data storage, and data visualization components.

For data collection and shipment, Harold uses Filebeat for log data and the Elastic APM agent for traces and metrics data. Filebeat continuously scans for new log data and sends it to Logstash for processing and transformation. The Elastic APM agent, installed on the user's application servers, collects tracing and metrics data and sends it to the APM server.

Data processing and transformation are handled by Logstash for logs and the APM server for traces and metrics. Logstash ingests data from Filebeat and applies filters for specific transformations. The APM server processes data received from the APM agent, validating and transforming it into Elasticsearch documents before sending it to Elasticsearch.

Elasticsearch acts as the data storage component. It is a distributed search and analytics engine that stores and indexes data in near real-time. Data from Logstash and the APM server is stored in Elasticsearch, enabling querying and visualization through Kibana.

Kibana serves as the data visualization component of Harold. It allows users to visualize and analyze data stored in Elasticsearch. With Kibana, developers can create interactive dashboards, visualization charts, and perform advanced analytics on their telemetry data.

In summary, Harold is an observability solution that simplifies the deployment of the elk stack. It addresses the challenges involved in implementing an observability solution by providing a pipeline for data collection and shipment, data processing and transformation, data storage, and data visualization. Harold bridges the gap between commercial and open-source solutions, offering developers the benefits of both. It abstracts away the complexity of setting up open-source tools while allowing users to maintain data and infrastructure ownership. By leveraging the battle-tested elk stack, Harold provides a robust and comprehensive observability solution for growing applications. Setting up Harold is straightforward, and it enables developers to gain complete visibility into the health and performance of their software systems. The goal of this coding Capstone project is to output data to Logstash for collecting and shipping traces and metrics data. The project utilizes Elastic APM agents, which are open-source libraries that collect data generated by an application. These agents are written in the same programming language as the application and can be easily installed like any other library. Once installed, the user instrument their code to allow the agents to collect tracing and metrics data. The APM agents then ship the data to the APM server for processing.

One of the challenges to achieve observability is data processing and transformation. This component of the pipeline must be capable of processing data for specific analysis and transforming the data into a format that is accepted by the data storage component. To address this challenge, Harold uses two separate tools for data processing and transformation: Logstash for logs and the APM server for traces and metrics. Within the Harold pipeline, Logstash is configured to ingest data from Filebeat. The user must configure Logstash with an appropriate filter to enable specific transformations of the ingested data to support the application's use case. For example, a user may use the geoip filter to add information about the geographical location of IP addresses. Once the data is processed, it is sent to Elasticsearch for storage and indexing.

The APM server consists of two parts: the elastic agent and the APM integration. Elastic agents are installed on the user's application servers to receive different data types, such as metrics and traces, from the APM agents. The elastic agent configuration can be updated to enable the collection of new or different data sources through agent policies. The APM integration is specified within an agent policy and acts as the APM server, residing entirely on the user's application server. The APM server accepts tracing and metrics data from an APM agent, processes the data by validating and transforming it into Elasticsearch documents, and then sends it on to Elasticsearch.

Another challenge in achieving observability is the data storage component. The data store houses the data and makes it available for querying by the visualization component. Elasticsearch is used as a distributed search and analytics engine and data store. It stores complex data structures serialized as JSON documents. Elasticsearch stores and indexes data in a way that enables near real-time searching and acts as a durable data store, capable of persisting long-term data as needed. Within the Harold pipeline, Elasticsearch receives data from Logstash and the APM server. It serves as a storage component that can be queried through Kibana for visualization.

The final challenge to address is the data visualization problem. Data sitting in the data store is only useful if it can be visualized and analyzed. Kibana is utilized as the data visualization component in Harold. It is a powerful open-source platform for data exploration and visualization. Kibana provides a user-friendly interface for searching, analyzing, and visualizing large volumes of data in real-time. With Kibana, developers can search, analyze, and visualize their data using charts, gauges, maps, and graphs. Developers can view logs, traces, and metrics in Kibana, gaining a better understanding of the health of their system.

To recap the key topics discussed so far, the need for an observability solution was explained, highlighting the role of logs, traces, and metrics in active monitoring and debugging. The challenges associated with implementing an observability solution were discussed, emphasizing where Harold fits into the existing landscape of solutions. The Herald Pipeline, which collects logs, traces, and metrics and transforms them into usable observability data, was also explained.

Moving on to the next phase of the discussion, the focus shifts to how Harold was built and some of the implementation challenges and design decisions faced in the process. The topics covered include building Harold with Amazon Web Services (AWS) and the Cloud Development Kit (CDK), deploying containerized applications, service discovery within the Harold application, secure communication with Elasticsearch nodes, creating a multi-node Elasticsearch cluster, auto-scaling the Elasticsearch cluster, and how each application fits into Harold's overall architecture.

Before delving into the specific details related to building Harold, a high-level overview of Herald's architecture is provided. Harold and the user's application reside within the same virtual private cloud (VPC) in AWS. When deploying Harold, existing VPCs within the user's account are displayed for selection, ensuring seamless communication between the user's application and Harold without additional configuration. In the center of the architecture diagram, a private subnet hosts most of Herald's services, including two Elasticsearch clusters, one for managing all Elasticsearch nodes and the other for auto-scaling data and ingestion nodes. A Logstash cluster is also present for processing log data, and a Fleet server cluster is used for enrolling and managing elastic agents. On the right side of the diagram, a public subnet houses the Kibana application, which requires a public IP address for user queries and requests. Additional AWS resources, such as Cloud Map for service discovery, Elastic File System for centralized volume storage, CloudWatch for application logging, and a Lambda function, are listed as part of Herald's architecture. The public subnet on the left side represents the location of the user's application, which interfaces with Herald using Filebeat for sending log data to Logstash and the APM server for sending traces and metrics data to Elasticsearch.

Harold was built and deployed using AWS's Cloud Development Kit (CDK), an infrastructure-as-code tool that allows developers to provision AWS resources using code written in JavaScript, TypeScript, Python, or Java. All of Harold's applications, including Elasticsearch, Logstash, Kibana, and Fleet server, are installed using Docker containers. Therefore, AWS Elastic Container Service (ECS) is utilized, a fully managed container orchestration service designed to facilitate the deployment, management, and scaling of containerized applications. ECS can deploy containers on AWS Elastic Compute Cloud (EC2) or AWS serverless application hosting service Fargate.

The first components added to Harold's architecture were Elasticsearch and Kibana. Elasticsearch serves as the database for storing and indexing data, while Kibana provides the user interface for querying and visualizing data. Kibana requires a public IP address, so it is placed in a public subnet, while Elasticsearch is placed in a private subnet to ensure it is inaccessible from outside the Herald VPC. Since the IP address of the host server is unknown at the time of configuration when using CDK, AWS Cloud Map is used to create a private DNS network. This allows assigning DNS hostnames to each service, which resolve to the IP address assigned after deployment. With Cloud Map, successful communication between Kibana and Elasticsearch is ensured. Additionally, TLS is used to secure the communication between Kibana and Elasticsearch. A dedicated certificate authority is created using Elasticsearch's certificate generation utility, which generates certificates for Kibana and each Elasticsearch node. These certificates are stored in an Elastic File System volume, which is mounted to the Docker container for each application that communicates with Elasticsearch.

To handle large fluctuations in telemetry data generated by Harold, multiple Elasticsearch nodes are used. These nodes form a cluster that distributes incoming data streams and offers data distribution, replication, and scalability. The cluster is configured to scale up when the CPU utilization reaches 60% or above, ensuring that Harold can handle heavy loads. Auto scaling of the Elasticsearch cluster is implemented to avoid data loss. The cluster only scales up and not down to maintain initial nodes' stability.

Logstash is the next component added to Harold. Since Logstash also needs to handle peak loads, multiple nodes of Logstash are deployed, and a load balancer is used to distribute loads evenly between the nodes. Logstash nodes work independently, removing the need for node discovery.

With Elasticsearch, Kibana, and Logstash added, Harold's architecture takes shape. Elasticsearch and Logstash are placed in a private subnet alongside the Fleet server cluster, while Kibana remains in a public subnet. All applications are deployed within the same VPC to ensure seamless communication. Additional AWS resources, such as Cloud Map for service discovery, Elastic File System for centralized volume storage, CloudWatch for logging, and a Lambda function, are incorporated for enhanced functionality.

In summary, this transcript covered the purpose of the coding Capstone project, which aims to output data to Logstash for collecting and shipping traces and metrics data. It explained the role of Elastic APM agents in collecting data generated by an application and the challenges surrounding observability, data processing and transformation, data storage, and data visualization. The implementation of the Herald pipeline was discussed, including the use of Logstash for data processing, Elasticsearch for data storage, and Kibana for data visualization. The transcript also introduced the overall architecture of Harold, including the deployment on AWS using the Cloud Development Kit, the inclusion of Elasticsearch, Logstash, Kibana, and other AWS resources, and the implementation of auto-scaling capabilities to handle varying volumes of telemetry data. This transcript is about replication across multiple nodes in Elasticsearch to form a single cluster. The first step is to configure the nodes to work together as a cluster, and the second step is to specify the DNS hostnames of the other nodes in the configuration file for each node. By doing this, the nodes can communicate with each other and work together as a single unit. With this setup, a request from Kibana, for example, would be sent to one of the Elasticsearch nodes, and the cluster would determine how to process and respond to the request based on its internal knowledge of node responsibilities and data distribution.

Multiple nodes of Elasticsearch are needed to handle spikes in Telemetry data generation. To ensure that the system can handle these spikes effectively, auto-scaling is built into the Elasticsearch cluster. The cluster scales up when the CPU utilization reaches 60% or above to prevent data loss. However, the cluster does not scale down automatically.

In addition to Elasticsearch and Kibana, Logstash is added to the system to transform and enrich logs. Logstash consists of two nodes with a load balancer in front of them. These nodes work independently, eliminating the need for service discovery.

Now, the architecture diagram includes Elasticsearch, Kibana, and Logstash. Filebeat is installed on the application server to collect logs, which are then sent to Logstash for processing before being sent to Elasticsearch. This completes the logging pipeline of the system.

Next, the tracing and metrics pipeline is added to the system. This requires four new components: APM agents, Elastic agents, Fleet server, and APM server. APM agents collect raw traces and metrics data from applications, while Elastic agents collect a variety of data from different services. Fleet server acts as a centralized management system for the Elastic agents, and the APM server validates and transforms the data before sending it to Elasticsearch.

Herald uses a specific architecture with a centralized Fleet server and a distributed APM server. The Fleet server manages the Elastic agent installed on the application server, which acts as the APM server. This architecture has certain advantages, such as resilience, scalability, and cost reduction. However, it also presents challenges in managing the growing number of APM server nodes and resource sharing with the application.

With the addition of Fleet server and APM server, the architecture diagram is updated. Now, the system consists of Kibana on the far right, followed by Elasticsearch cluster, Logstash nodes, and the APM server. The Fleet server is located in the middle, managing the Elastic agent on the application server.

Building Herald was challenging, especially when it came to encrypting communication with TLS. It required careful configuration of security settings and certificate management. The deployment of the ELK stack programmatically was also challenging, as it is not designed for such deployments.

Although Herald relies on Amazon's Cloud infrastructure, it is possible to build similar solutions on other cloud providers. However, it may be equally challenging due to the nature of the ELK stack and the need to piece everything together automatically.

The decision to use two separate pipelines for logs and traces/metrics was based on the limitations of the Elastic agent. While it is possible for the Elastic agent to collect log data, it can only output data either to Elasticsearch or to Logstash. To leverage the data processing capabilities of Logstash for logs and to separate traces and metrics data, two pipelines were necessary.

A significant amount of additional research was required for this project. While the fundamentals learned from Launch School's Core Curriculum and Capstone were essential, there was a need to delve into AWS CDK and gain a deeper understanding of the ELK stack and its workings.

In terms of future improvements, the team plans to implement auto-scaling for the Logstash cluster, add Kafka to minimize data loss, incorporate AWS S3 cold storage for cost reduction and performance enhancement, and auto-scale the Elasticsearch cluster based on storage and CPU utilization.

In conclusion, the team has successfully built Herald, a robust observability solution. While there is room for improvement and ongoing challenges, the project has demonstrated the ability to handle spikes in telemetry data and provide insights through logging, tracing, and metrics pipelines. The team appreciates everyone's attention and offers the opportunity for questions. In this video, we discussed the cloud infrastructure, specifically Amazon Web Services (AWS). We were asked about the difficulty of building a similar solution with other cloud providers, such as Google or Microsoft. While we cannot provide a definitive answer as we only worked with AWS, we found it challenging to deploy the solution we built using the Elastic Stack (ELK) programmatically. This difficulty is not necessarily specific to the platform, but rather due to the inherent challenges of piecing together all the components of the ELK stack automatically. Therefore, we anticipate that it would be similarly challenging on any other platform. 

Another question was raised about the decision to use two separate pipelines for logs and traces/metrics, rather than a single pipeline for all the data. The reason behind this was that while the elastic agent and APM integration can collect log data, elastic does not allow for two separate outputs. Therefore, we had to choose between outputting everything to Elasticsearch or everything to Logstash. Since Logstash is specifically designed for logs, we decided to use it to process log data, while Elasticsearch was used for traces and metrics.

We were then asked about the amount of time we spent on additional research to fill any knowledge gaps not covered by the Launch School materials. It is challenging to quantify the exact percentage, but we can confidently say that a considerable amount of additional research was required. The fundamentals we learned from Launch School provided a strong foundation, making this project possible. However, we needed to conduct extra research to understand AWS CDK (Cloud Development Kit) and how the ELK stack functions.

The next question was whether observability was an interesting space to build a Capstone project in and if there were any pros and cons that stood out. We found observability to be a fascinating space, and our interest grew as we delved deeper into the project. Initially, we were drawn to this area because setting up Elasticsearch, Logstash, and Kibana was challenging. We also noticed that many commercial solutions use the ELK stack, but there was a lack of automated tools for setting them up. We wanted to build a solution that could meet our team's needs now and in the future.

The distribution of the development workload across the team members was then discussed, along with the proportion of time spent on AWS CDK and configuration. We took a divide and conquer approach, assigning tasks to different team members. As for CDK and configuration, it consumed a significant portion of our time. CDK is an API wrapper for various other smaller APIs, so learning and configuring CDK, as well as all the related APIs, was a time-consuming endeavor.

Moving on, someone asked if we followed any particular collaboration ideology, with Agile being mentioned as a possible example. While we didn't strictly adhere to any specific methodology, our workflow did resemble Agile in many ways. We used a Trello board to organize our tasks, dividing them into different stages: on deck, in progress, and completed. Team members were assigned to different tasks, and we regularly met to discuss any issues or problems.

Lastly, we expressed our gratitude to everyone for attending the session and for asking insightful questions. We appreciated the opportunity to share our experiences and insights regarding our coding Capstone project.