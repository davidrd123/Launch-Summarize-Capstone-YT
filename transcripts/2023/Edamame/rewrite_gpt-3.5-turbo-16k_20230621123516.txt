In this video, we will discuss how we built Edamame, a load tester for real-time collaboration apps. We have a team consisting of Albert, Ginny, Luke, and Rachel from different parts of Canada and the US. Let's dive into the details of our project.

Part A: Problem Definition
First, let's understand what load testing is and why companies conduct it. Load testing involves simulating real application user behavior at large volumes and measuring how the system responds. The goal is to ensure that the system can handle a high load without delays or failures. We'll also examine real-time collaboration apps like Slack, Coda, and Miro and explain why we chose to focus on these types of applications. Load testing for collaboration apps requires additional protocols like websockets to optimize efficiency, which brings about unique considerations. We'll look into existing solutions to see how companies currently address these challenges.

Part B: Our Solution
We'll outline the architecture of Edamame, providing a bird's eye view of how it works. Then, we'll discuss the specific challenges we faced while building Edamame and how we overcame them through our architecture. 

Let's begin with Rachel explaining what load testing is. She uses an example of Ticketmaster crashing due to overwhelming traffic when fans tried to buy Taylor Swift concert tickets. Great user experience is crucial for developers, and load testing helps them prepare for such overwhelming traffic situations. Load testing involves simulating user behavior and measuring the system's response. HTTP benchmarking tools can be used to simulate large volumes of traffic by sending consecutive HTTP requests to a specific server endpoint. However, load testing involves additional considerations like the scale of the test, the protocols involved, the metrics collected, and how they are visualized.

Rachel dives into the scale of load testing, which refers to the total number of concurrent virtual users simulated during the test. Virtual users are programmatic behaviors defined within a test script. The scale depends on the available local resources like CPU and memory. If a developer needs to simulate millions of users, a distributed architecture with additional servers must be used. Protocol considerations are also important, as developers must simulate the types of traffic their application experiences. While HTTP is the main protocol for web applications, there may be additional protocols like websockets or AMQP to consider.

Metrics play a crucial role in load testing. Developers want to collect meaningful data that provides insights into system performance. Server-side data tracks metrics like CPU and memory on the backend server, while client-side data tracks metrics like HTTP response times, which are more meaningful in terms of user experience. Visualizing the collected data is essential, and developers can choose to display it as end-of-test summaries or graphical plots over time. Graphs offer more granular insight and can help identify performance shifts during the test.

Now, Ginny takes the stage to discuss collaboration apps and their specific characteristics. Collaboration apps involve real-time communication, allowing users to interact on a shared platform. Examples include messaging apps like Slack, whiteboarding tools like Whimsical and Miro, and productivity tools like Coda. These apps rely on the websocket protocol for efficient real-time communication. Websockets establish a persistent connection between client and server, allowing bi-directional communication without the need to re-establish the connection for each interaction. This persistent connection enables quick and efficient data transfer with messaging speeds of around 100 milliseconds, creating a seamless real-time experience.

Collaboration apps using websockets face a challenge called fan-out. When a user sends a message on, for example, Slack, an HTTP post request is sent to Slack servers. This request is then broadcasted to multiple subscribers in a process called fan-out. For each user, the message is sent via a websocket connection, ensuring real-time updates on their screens.

To summarize, load testing serves as a crucial tool for evaluating system performance under high traffic conditions. Collaboration apps, with their real-time communication and websocket protocols, present unique challenges that need to be addressed. Edamame aims to provide an effective load testing solution for these types of applications. Next, we'll move on to outlining the architecture of Edamame and discussing the specific challenges and solutions we encountered during its development. The topic of discussion for today is collaboration apps and their load testing requirements. Collaboration apps are applications that incorporate real-time communication. An example is a shared whiteboarding application where users can create visuals together on the same canvas, make edits, see each other's cursors, and comment on things. These apps have gained popularity due to the rise of remote work. Examples of collaboration apps in the real world include messaging apps like Slack, whiteboarding tools like Whimsical and Miro, and productivity tools like Codep. The common characteristic among these apps is their use of the websocket protocol for real-time communication.

Websockets are a protocol that operates over HTTP and uses the underlying TCP layer to create a persistent connection between the client and server. Unlike the traditional HTTP request-response cycle, where each request is followed by a response, websockets enable bi-directional communication. Once a client is connected to a websocket server, they can communicate with each other without waiting for a response. This persistent connection allows for real-time updates in collaboration apps. The websocket server can send unsolicited messages, and clients can send messages without waiting for a response. This efficient communication enables near real-time updates, as the connection does not have to be re-established with each interaction.

A specific challenge that real-time collaboration apps face is called "fan out." Fan out refers to the rapid multiplication of messages when one message is sent to a large number of users. For example, when a user sends a message on Slack, an HTTP post request is sent to the Slack servers, which then sends the message to all other users connected to that channel using websockets. If a channel has a thousand users, a single incoming message will result in a thousand websocket messages being sent out. Additionally, interactions such as liking or reacting to a message can further increase fan out. Each reaction creates a new message that needs to be sent out to all connected users. This can result in a large number of websocket messages being emitted and puts a significant load on the websocket server, which needs to handle all these messages in real time.

Load testing collaboration apps requires simulating this fan out pattern accurately. There are several considerations to keep in mind when building an effective load testing tool for collaboration apps. First, scale is crucial. Collaboration apps often require load tests with a large number of virtual users, typically in the six-figure range. For example, Miro experienced rapid scaling, going from 12,000 to 100,000 concurrent users. Slack's load tests scaled from 5,000 to 500,000 virtual users per test. Such high numbers usually necessitate a distributed load test.

The next consideration is the protocol. To simulate collaboration app users effectively, a load tester should simulate both HTTP and websocket traffic. Collaboration apps typically have separate services for handling HTTP and websocket traffic. If load testing relies only on sending HTTP requests, it won't accurately test the entire system. The load tester needs to simulate websocket connections to ensure that the websocket server has something to talk to and accurately simulate the fan-out pattern.

Another important consideration is collecting relevant metrics. Collaboration apps use both HTTP and websocket protocols, so the load tester should collect metrics specific to both protocols. For HTTP, metrics like response time are important, while for websockets, metrics like abnormal closures and failed handshakes provide insights into websocket server performance. These metrics help developers understand how end users are experiencing the app and find potential performance bottlenecks.

Visualization of data is essential for developers to monitor and analyze load test results. Near real-time graphs are preferred, as load tests often need to be run against production environments. Near real-time data visualization allows developers to react to any performance degradation as it happens, either by scaling up production to handle the load or by stopping the test if necessary.

When it comes to load testing solutions for collaboration apps, there are two main approaches: managed cloud-based services and self-hosted DIY tools. Managed cloud-based services, such as k6 Cloud, Blaze meter, and Gatling Enterprise, handle the complexities of distributed load testing in the cloud. These services are provided by companies that offer open source load testing tools. While the managed services simplify load testing, they have limitations in terms of data ownership and custom configurations. They also come at a price, making them suitable for developers who prefer a hands-off approach.

On the other hand, self-hosted DIY tools involve building and managing a load testing solution in-house. Companies like Slack have built their own proprietary load testing frameworks, tailored to their specific needs. The advantage of DIY tools is the ability to customize and have complete control over the load testing process. However, building and managing such tools can be complex and often require dedicated teams to handle the infrastructure.

For developers who want a middle ground between managed services and DIY tools, there are licensed or open-source solutions that can be self-hosted. This is where edamame fits in. Edamame is an open-source, self-hosted, distributed load testing framework specifically configured for real-time collaboration apps. It supports load tests of up to 200,000 concurrent virtual users, simulates both HTTP and websocket traffic, collects custom metrics, and provides near real-time data visualizations. Edamame offers a plug-and-play solution for self-hosted load testing of messaging, whiteboarding, and productivity tools. However, it does have limitations in terms of scalability, advanced features like CI/CD integration, and scheduled tests.

To set up edamame, users need to install it on their local machine and create an AWS account. Edamame runs on AWS and deploys five main components in the cloud. These components include load generators (powered by k6), a coordinator to manage the load generators, a data pipeline, a database for metrics, and a visualizer for near real-time test results. These resources are provisioned when running a test and allow developers to analyze test results and make necessary adjustments in near real time.

In conclusion, building an effective load testing tool for collaboration apps requires considering scale, simulating both HTTP and websocket traffic, collecting relevant metrics, and providing near real-time data visualizations. Managed cloud-based services and self-hosted DIY tools are two main approaches to load testing, each with its advantages and limitations. Edamame offers a self-hosted, open-source solution specifically tailored to real-time collaboration apps, providing a balance between simplicity and customization. With its ability to simulate large numbers of virtual users, handle both HTTP and websocket traffic, and offer near real-time data visualizations, edamame is a competitive option for load testing collaboration apps. Companies often use licensed or open-source solutions that they host themselves, and this is where Edamame comes in. Edamame is an open-source, self-hosted, distributed load testing framework designed specifically for real-time collaboration apps. We believe Edamame is a competitive plug-and-play solution for self-hosted distributed load testing, particularly for messaging, whiteboarding, and productivity tools.

When considering the requirements for load testing tools, Edamame provides several important features. First, it supports load tests of up to 200,000 concurrent virtual users. It supports both HTTP and websockets for protocols, and it offers a set of custom metrics that provide deeper insight into performance. Additionally, Edamame includes a near real-time dashboard that allows developers to react to live updates.

However, Edamame does have some limitations. It currently does not support tests requiring more than 200k users, and it only provides support for HTTP and websocket traffic. If you require additional features, such as support for more users or other protocols, you would need to extend Edamame yourself. Similarly, Edamame does not provide advanced features like CI/CD integration and scheduled tests. These are areas where Edamame can still improve.

Now let's dive into how Edamame works and how it interfaces with the cloud for distributed load testing. Edamame runs on Amazon Web Services (AWS), so users need to create an AWS account and install Edamame on their local machine. To set up Edamame's cloud infrastructure, users use the command "edamame init". This command deploys five main components to the cloud.

The first two components are related to load generation, which involves generating HTTP and websocket traffic. Edamame uses the open-source tool k6 as its load generating program. The k6 runners act as the muscle that generates load, while the coordinator ensures that the k6 runners are synchronized. The next two components handle data. This includes a pipeline that receives metric data and a database for storing it. Finally, there's the visualizer, which displays the test results in near real-time.

It's important to note that the k6 runners and data pipeline components are not active until a test is run. The "edamame init" command sets up the skeleton of these resources, and they are provisioned only when a test is actually executed. To run a test, users provide a test script using the command "edamame run". Edamame then scales up the necessary k6 runners and data pipeline for the test. The exact number of runners depends on the test script's requirements. Once everything is ready, a signal is sent to the coordinator, which synchronizes and starts the runners. The runners send requests and establish connections to the servers specified in the test script, sending client-side data to the data pipeline for processing. From there, the data is sent to the database for storage. The visualizer retrieves the data from the database and presents live results to the user. After the test is completed, the load test components are scaled down, returning to the initial resting state.

Now let's explore some of the choices we made for the components in more detail. As we developed Edamame, we encountered three major challenges that needed to be addressed. The first challenge was coordinating distributed load tests with over 100k virtual users. The second challenge was processing over a million data points per second in real-time. And the third challenge was extracting useful insights from multiple protocols, specifically HTTP and websockets.

To address the challenge of running distributed load tests with over 100k virtual users, we selected k6 as our load testing tool. However, even with k6, we were still unable to achieve the desired load on a single machine. To overcome this limitation, we distributed the test across multiple machines. By running the tests in the cloud, specifically on Amazon's EC2 instances, we were able to scale the tests beyond the limits of a single machine. To standardize the environment for running k6, we opted to use Docker containers on EC2 instances. This allowed us to bundle all the necessary dependencies with the containers. To ensure synchronization between the distributed tests, we utilized Kubernetes, along with the k6 operator, which automates tasks related to running distributed tests. The k6 operator coordinates the tests, while the runners execute the load testing code. This setup allows us to effectively run distributed load tests across multiple machines and scale to loads of over 100k virtual users.

The second challenge we faced was processing over a million data points per second in real-time. The raw data generated by k6 during a load test is substantial. We explored three approaches to process this data. The first approach involved writing the raw data directly to a database. However, the limitations of databases in terms of write capacity made this option less feasible. The second approach was to aggregate the data on the k6 runners to reduce the overall data volume before sending it to the database. However, this approach introduced challenges in accurately calculating percentiles across distributed runners. To address this challenge, we opted for the third approach, which involved central aggregation using Statsite. Statsite is a performance stats D server that optimizes data aggregation using a probabilistic data structure. It allowed us to reduce the input data rate from over a million data points per second to approximately 20 data points every five seconds. This solution provided real-time data processing capabilities while minimizing the load on the database.

The final challenge was extracting meaningful insights from both HTTP and websockets during load tests. While k6 is a powerful load testing tool, it lacks some specific metrics for websockets by default. To address this limitation, we extended k6 by creating a custom Go extension. This extension emitted our custom metrics, along with the default metrics provided by k6, into the data pipeline. These metrics were then stored in the database and made accessible for visualization. With this extension, we were able to visualize all the necessary data for comprehensive load testing analysis.

In conclusion, Edamame is an open-source, self-hosted, distributed load testing framework designed for real-time collaboration apps. It offers support for a high number of concurrent virtual users, compatibility with HTTP and websockets, and custom metrics for in-depth performance analysis. While Edamame has some limitations, such as the maximum user limit and limited protocol support, it provides a competitive solution for self-hosted distributed load testing. The deployment process involves setting up the necessary components in the cloud and utilizing k6 for load generation, along with a data pipeline and visualizer for processing and displaying test results. We overcame challenges related to coordinating distributed load tests, processing large amounts of data, and extracting insights from multiple protocols by leveraging Kubernetes, the k6 operator, Docker containers, and Statsite. By addressing these challenges, Edamame offers a robust and scalable solution for load testing real-time collaboration apps. During load tests, we encountered several challenges that we needed to address in order to build Edamame. The first challenge was coordinating distributed tests with over 100,000 virtual users. We needed a way to synchronize and aggregate the data from each runner to ensure accurate results.

We initially considered aggregating the response times from each runner and calculating the 99th percentile, but this approach had limitations. If a specific runner had significantly faster or slower response times, it could skew the results. For example, machine one had a 99th percentile of 500 milliseconds, while machine two had 2,000 milliseconds. Taking a straight average resulted in a 99th percentile of 1,250 milliseconds. However, when we combined all the data into one server, the correct calculation for the 99th percentile was 2,000 milliseconds.

From this insight, we realized that to guarantee the correct percentile value, we needed to have all the raw data available on one central machine. So, we decided against aggregating on the runners. Instead, we opted for central aggregation using stat site.

Stat site is a performance stats D server written in C that utilizes the statsd protocol developed by Etsy for implementing and aggregating metrics. It uses UDP to reduce latency and employs a probabilistic data structure to aggregate trend data points such as percentiles. This means it estimates the distribution based on a smaller sample size rather than sorting all the data points, resulting in accurate percentile estimates.

Using stat site, we were able to process over 1 million data points per second in real time and write just 20 data points or less to the database every five seconds. This significantly reduced the amount of data and improved overall efficiency.

The next challenge was extracting useful insights from both HTTP and websockets during our load tests. Initially, we realized that k6, our load testing tool, lacked comprehensive metrics for websockets. To address this, we extended k6 by adding five additional metrics. We wrote a custom extension in Go that emitted these metrics alongside the default ones provided by k6, enabling us to capture and analyze important websocket-specific metrics such as failed handshakes and abnormal closures.

Failed handshakes refers to the number of websocket connections that could not be established, while abnormal closures tracks the number of dropped connections. These metrics were crucial in evaluating websocket load tests and were not included in the default k6 library. With our custom extension, we were able to include these metrics, along with three others, and visualize both HTTP and websocket metrics in Grafana.

By integrating these metrics into our data pipeline, we were able to visualize real-time data and make informed decisions based on the insights gained. Whether it was monitoring the performance of HTTP requests or tracking the behavior of websockets, our solution provided a comprehensive view of the system under load.

To summarize, Edamame addressed three major challenges. First, we successfully coordinated distributed tests with over 100,000 virtual users. Second, we processed more than 1 million data points per second in real time by leveraging stat site for central aggregation. Lastly, we extended k6 to extract valuable insights from both HTTP and websockets. By overcoming these challenges, we were able to build a powerful load testing tool.

We anticipate that future advancements in this space will focus on improving the scalability of Edamame. Currently, we have a bottleneck at the centralized server, where all the data needs to be aggregated. However, by implementing specialized data structures on the runners to aggregate data before sending it to the server, we can increase the number of virtual users. Additionally, the specific needs of each company will determine further improvements to Edamame.

Thank you everyone for listening. We hope this overview was informative. If you have any further questions, feel free to reach out to us.