Welcome to our presentation of Seymour, an open-source, easy-to-configure active monitoring solution. I'm Katarina, and I'm joined by my colleagues Scott, Tim, and Miles. We're excited to introduce our project that we have been working on for the past few months as a fully remote team spanning the US and Europe. Seymour is designed to help engineering teams address the challenges of monitoring complex systems by providing active monitoring capabilities. It allows users to simulate requests from globally distributed locations to test their API endpoints. Seymour measures performance, uptime, and correctness of the payload data. Our goal is to enable rapid issue detection in production before users are impacted. Additionally, deploying Seymour is quick and straightforward using a few CLI commands.
 
Before we proceed further, let me outline the structure of our presentation. We will start with an overview of the problems Seymour is designed to solve. Then, we'll explain the concept of active monitoring and its importance in ensuring system health. Next, we will explore existing active monitoring solutions, their advantages, limitations, and where Seymour fits into the picture. Following that, we will provide a quick demo of Seymour, including how it is deployed and its underlying architecture. We will also discuss the design decisions and challenges we encountered during the development process. Afterward, we'll cover some additional features we plan to work on in the future. Finally, we'll conclude with a Q&A session.

To understand the need for active monitoring, let's first discuss how development teams minimize the risk of bugs reaching production. One common approach is software testing, which involves evaluating and verifying that a software product or application functions as intended. Testing helps prevent bugs and can even improve performance. Typically, tests are run locally during development or in a staging environment before deployment. There are different types of tests, such as unit tests and integration tests. Unit tests focus on testing specific parts of an application and are often run by individual developers. Integration tests involve testing multiple components together. However, even with these tests, issues can still arise in production environments. Conditions change, perfect replication of production is challenging, and third-party service dependencies can be unreliable. These issues can result in performance degradation, incorrect data, or API unavailability. Rather than waiting for users to experience such problems, active monitoring allows for continuous testing of API endpoints in production.

Active monitoring, also known as synthetic monitoring, involves running automated tests against a live production system to detect failing business requirements. It helps monitor server and application performance, even during periods of low user engagement. Active monitoring focuses on testing three main aspects: availability (uptime), performance (latency), and correctness of data. Tests are designed with specific expectations about the API's behavior to ensure the provider meets its commitments. For example, a test might expect a response within a certain timeframe and with a specific status code. When a test fails, engineers are notified through channels like Slack or email, allowing them to quickly troubleshoot and resolve the underlying problem.

Now that we understand active monitoring, let's discuss why it is important. In any software production environment, issues are inevitable. Rather than viewing this as a negative, engineering teams can see it as an opportunity. Active monitoring helps identify problems in production before users are affected. This is particularly crucial in microservice architectures, where APIs depend on various internal and external services that can change dynamically. Replicating the exact production environment for testing is challenging, and even with well-maintained test environments, errors can slip through the cracks. Active monitoring provides valuable insight into how a system is performing for users in specific geographic locations, helping diagnose network-related issues. By incorporating active monitoring into their testing strategies, engineering teams can effectively detect and fix issues before users are impacted.

Now let's delve into existing active monitoring solutions to understand where Seymour fits in. Some notable vendors offering active monitoring services include New Relic and Datadog, along with smaller companies like Uptrends, Checkly, and Runscope. There are also several open-source solutions available, such as Artillery and Monica. Additionally, some teams prefer a DIY approach and build their own in-house solutions using open-source tools like Monica. When considering these options, it's essential to evaluate their capabilities and feature sets. SAS solutions offer geographically distributed tests and require minimal setup. However, they lack data ownership, which may be a concern for some companies. Open-source solutions provide data ownership but often lack geographic distribution capabilities. In-house solutions offer complete control over data but require significant time and effort to develop. Seymour aims to bridge these gaps by providing a self-hosted, open-source solution that supports geographic distribution, easy configuration, and data ownership.

Let's now take a detailed tour of the Seymour UI and see how to create a test and view the results. On the Seymour homepage, we see a table view displaying existing tests, including their names, recent results, and scheduled frequency. We can easily edit, delete, or trigger a test run from this table. To create a new test, we click the "Create Test" button, which takes us to a form with various inputs. The first step is to name the test. Next, we configure the request to hit the specific API endpoint we want to test. We can specify the request method, URL, and request body. We can add custom headers if needed. After configuring the request, we define assertions for the response received from the API server. These assertions can include response time, status code, and properties in the response body. We can also set up multiple locations from which the request will originate to simulate global usage. The frequency of the test and alert configurations can also be defined. We can choose to be alerted through email, Slack, or Discord in case of assertion failures. Once the test is configured, we save it and see it listed in the table of tests. We can manually trigger a test run or wait for the scheduled frequency. Over time, we can view the test results in the table, including success or failure status, response times, and other relevant information.

In conclusion, Seymour is an open-source, easy-to-configure active monitoring solution that addresses the challenges of monitoring complex systems. It allows users to simulate requests from globally distributed locations, monitoring performance, uptime, and data correctness. Seymour distinguishes itself by providing geographic distribution, easy configuration through a user-friendly interface, and data ownership. With Seymour, engineering teams can proactively detect and fix issues in production before users are impacted. Deploying Seymour is simple and cost-effective, leveraging AWS infrastructure. Thank you for joining us in this presentation, and now we're open to answering any questions you may have. In this coding Capstone project video, we will configure a request to hit a specific API endpoint that we want to test. The endpoint we want to test is part of a task management API that is modeled after Trello. Specifically, we want to test the endpoint used to create a new card. To do this, we will make a POST request to a specific URL. This endpoint expects a request body of a particular shape, so we will add that to our request configuration.

For this request, we don't need to add any custom headers, so we can skip that part. Once we have configured the request, we can add assertions about the response received from the API server. First, we will check the response time and make sure it is less than 500 milliseconds. Next, we expect the status code of a successful request to be 201, so we will add an assertion for that. 

We also want to make assertions about the response body. We want to check if the response body contains a "title" property that is equal to the value indicated in the request body. To indicate that we want the "title" property of the response body, we use the syntax "$.title". Next, we want to check if the response body contains a "completed" property that is equal to false and a "due date" property that is null. The server should generate an ID for the card and attach it to the response body, so we will add an assertion for that too. Finally, we will check the connection header and ensure that it has a value of "close".

Now that we have added all our assertions, we can choose the locations from which we want the request to originate. Even though the API we are testing doesn't yet have users all over the world, let's pretend that it does. We want to make sure that clients in different geographies don't experience unacceptable latency when interacting with this endpoint. So, we will select North Virginia, Stockholm, and Montreal as the geographical locations for our test.

Next, we need to configure the frequency of the test and how we want to be alerted in the case of an assertion failure. Let's configure the test to run once every minute, and if any of the assertions fail, we want to be alerted on Discord. We will need to provide the web hook address for the Discord channel on which we want to receive the alerts. It's worth mentioning that we can add as many alerts as we want and also choose from other alert channels such as email or Slack.

With the test configuration complete, we can save it. Now, we can see that the "C-More Demo" test has been added to the table of tests. We have the option to trigger a run of the test by clicking the "Run Now" button, or we can wait for a minute for the results to start populating. For now, let's click into another test that already has results and come back to the newly configured test at the end of the demo.

In the table of tests, we can see a summary of the test results. We notice that 100% of the requests have succeeded, meaning there were no 400s or 500s. However, it's important to note that a successful request doesn't necessarily mean that the test assertions passed. It only means that the response to the request was successful based on the status code.

We can also see that there have been several assertion failures in the tests. We will investigate the cause of one of these failures momentarily. Additionally, we have a summary of response times, including the median and 95th percentile values. The three most recent test runs are displayed, showing the region, status code, response time, number of assertions passed, and the completion time of the test run.

Below the summary, there is a graph that breaks down the response times by region. From the graph, we can observe that the response times from Stockholm are higher than those from Montreal and North Virginia. This is expected since the endpoint we are hitting is served from North America. To view more than just the three most recent runs, we can click on "See All Test Runs".

Let's click into the most recent run of this test, as it has a failed assertion. This test was completed on August 10th, and the request originated from Stockholm. The test is labeled as a failure because the actual response time of 747 milliseconds exceeds the target value of 500 milliseconds. However, all the other assertions have passed. We can see a summary of target values versus actual values.

We can also review the response body and response headers of the failed test. They are collapsible sections that provide additional details about the test run.

Returning to the tests view, we can now see the results for the test we configured, including several failures. Let's click into one of the failure runs to investigate further. In this run, the failure was caused by a response time exceeding the target value. The actual response time was 921 milliseconds, while the target was 500 milliseconds. As a result, the test is marked as failed.

Now, let's check if we were alerted on Discord, as we configured. Sure enough, we can see alerts for this test, including the details of the failure. We have successfully received the alerts on Discord, as expected.

Now that you've seen the UI demo, let's discuss how to get started with C-More. To begin, you will need an AWS account. Once you have set up your account, you can proceed with the following steps:

1. Clone the C-More infra setup repository.
2. Run two CLI commands to spin up the necessary resources in your AWS account.
3. Enter the generated URL in your browser.

After completing these steps, you will be ready to configure your first test. It's worth noting that provisioning AWS resources, though automated, may take up to 20 minutes due to the provisioning of resources in 22 remote regions.

I will now hand it over to Miles, who will delve into the details of C-More's architecture.

Thank you for the walkthrough, Scott. Let's take a closer look under the hood of C-More and explore its infrastructure. The infrastructure can be divided into four main sections, which together form the lifecycle loop of a single test.

First, we have the test configuration phase. In this phase, the user configures the test through the UI. This information is saved as a JSON configuration file and sent from the UI to the backend application. The backend app stores the test configuration in the database and assigns it an ID. The test configuration is then passed to EventBridge, a serverless event bus, which functions as our scheduler service.

The second phase is pre-processing. When a test is scheduled, EventBridge fires off and sends the test configuration payload to a Lambda function called the "route packager". This function reads the location data from the payload and prepares it for routing to the correct regions. The route packager then publishes a message with the test to a topic in SNS (Simple Notification Service).

The third phase is test execution. In each remote region, a queue is subscribed to the SNS topic, and a Lambda function called the "test runner" pulls the message from the queue. The test runner uses the test configuration data to make an HTTP request to the endpoint and compares the response to the expected values defined in the assertions. If any of the assertions fail, the test is marked as failed. The results are then packaged up and sent back to the home region.

The fourth and final phase is post-processing. In the home region, another queue receives the test results. A Lambda function called the "test result handler" processes the results and writes them to the database. If a test fails, the result handler immediately invokes another Lambda function to handle alerting. The alerting function retrieves the test alerting information from the database and sends an alert message to the configured destinations, such as Discord.

To summarize, in the test configuration phase, the user configures the test through the UI and the configuration is stored and scheduled using EventBridge. In the pre-processing phase, the test configuration is prepared for routing to the correct regions. In the test execution phase, the test is executed in each remote region, and the results are sent back to the home region. Finally, in the post-processing phase, the results are stored in the database, and alerts are triggered if a test fails.

Now, I'll pass it over to Tim, who will discuss some of the decisions and challenges we encountered while building C-More.

Thank you, Miles. When we started this project, we faced an important decision: whether to build our solution from scratch or wrap an existing open-source project. We examined Monica, an open-source tool that offered many of the functionalities we wanted for C-More. However, it had limitations, such as the inability to originate tests from multiple geographic locations and the difficulty of use, as it was a command-line tool without a UI.

After careful consideration, we decided against wrapping and extending Monica. While it provided some functionality, it wasn't sufficient for our needs. One critical challenge we identified was the lack of multi-region testing support in Monica. To enable multi-region tests, we would have had to deploy the app to dedicated virtual machines in each of the 22 AWS regions we wanted to support. This approach raised concerns about configuration, synchronization, and maintenance.

In the end, we decided to build C-More from scratch to have full control over the features and address the challenges we encountered. Our goal was to provide an easy-to-use monitoring tool with multi-region testing capabilities. By building our own infrastructure and leveraging AWS services like EventBridge, Lambda, SNS, and queues, we were able to create an architecture that met our requirements.

In conclusion, while Monica offered some functionality, it fell short in terms of multi-region testing and ease of use. Building C-More from scratch allowed us to develop a robust solution that fulfilled all of our requirements. By leveraging AWS services, we were able to create an architecture that enabled easy test configuration, routing to different regions, executing tests, storing results, and triggering alerts.

If you're interested in getting started with C-More, you'll need an AWS account. Once you have an account set up, you can clone the C-More infra setup repository and run two CLI commands to deploy the necessary resources in your AWS account. After that, simply enter the generated URL in your browser, and you'll be ready to configure your first test.

It's important to note that provisioning AWS resources may take some time, potentially up to 20 minutes, due to the deployment of resources in 22 remote regions.

That concludes our overview of C-More's architecture and the decisions we made during its development. Thank you for your attention. In this video, Tim and Miles discuss the decisions and challenges they encountered while building the coding Capstone project, Seymour. They start by discussing the critical decision they had to make during the project research phase. They had to decide whether to wrap an open source project or build something from scratch. They analyzed an open source project called Monica, which provided much of the functionality they wanted to offer to Seymour users. However, Monica lacked certain critical features, such as the ability to originate tests from different geographic locations and a user-friendly UI.

After assessing Monica's capabilities and limitations, they considered wrapping and extending it to meet their requirements. However, they realized that implementing multi-region testing with Monica would be challenging. They would have to deploy the app to dedicated virtual machines in each of the 22 AWS regions they planned to support. This raised questions about security, networking, application configuration, and maintenance. They also needed a way to send the test results back to the home region for processing.

After researching potential solutions, they decided to build Seymour from the ground up using AWS cloud native products. They used Lambda functions to achieve multi-region testing by deploying the TestRunner Lambda function with a queue in each remote region. While this required more custom code, it offered several advantages. TestRunner could be easily deployed to all regions using AWS's Cloud Development Kit (CDK), eliminating the need to configure virtual machines. TestRunner was stateless, and all scheduling and configuration logic remained in the home region. Lambda's ability to send invocation records to a queue in another region facilitated communication of test results back to the home region. Additionally, Lambda functions could scale on demand, ensuring they could handle heavy loads.

They then discussed their design decisions regarding the Route Packager Lambda function, which receives all scheduler rules and test configurations. They wanted to enable geographically distributed testing locations, so they explored different options, including directly invoking remote region TestRunner Lambdas and using EventBridge's event bus functionality. Ultimately, they chose to use Amazon SNS to distribute scheduler events across regions. However, this approach led to inefficient message distribution, as all TestRunner Lambdas would be invoked for each message. To address this, they added message filtering logic to the SNS topic subscriptions, ensuring that each region only received messages intended for it. They also implemented the Route Packager Lambda function, which added region metadata to the messages, enabling the subscription filters to work effectively.

Tim and Miles emphasized the importance of system resiliency in Seymour. They highlighted three pillars of resiliency in the system. First, they utilized AWS serverless offerings, such as Lambda functions, to shift operational responsibility to AWS. This also allowed for decoupling of system components using managed messaging services. If one component failed or a high volume of tests occurred, the system would still process the tests. They also deployed the back-end app using AWS Elastic Beanstalk, which provided automatic failover and managed infrastructure, reducing the risk of failures.

Throughout the project, they faced various challenges. One significant challenge was automating the deployment of AWS resources across multiple regions. They used AWS Cloud Development Kit (CDK) to deploy and configure resources within the home region but faced difficulties connecting resources between the home and remote regions. They considered using a CDK pipeline but found it added complexity for users. They eventually used the Software Development Kit (SDK) for cross-region communication at runtime, reducing complexity and providing a lean deployment process for users.

Lastly, they mentioned some future improvements they would like to make to Seymour. They plan to implement alert thresholds and aggregation options to prevent multiple alerts for the same failure and reduce noise. They also want to include tear-down scripts so users can clear out any test data generated by Seymour. Additionally, they aim to integrate Seymour with CI/CD pipelines, enabling users to trigger tests as part of their DevOps processes.

In conclusion, Tim and Miles described the decisions and challenges they encountered while building Seymour. They explored the option of wrapping an open source project but ultimately decided to build Seymour from scratch using AWS cloud native products. They discussed their design decisions regarding multi-region testing and the Route Packager Lambda function. They prioritized system resiliency and utilized AWS serverless offerings and managed messaging services. They also mentioned the challenges they faced in automating resource deployment across regions. Lastly, they highlighted future improvements they plan to make to Seymour, including alert thresholds, tear-down scripts, and integration with CI/CD pipelines. In this video, we will discuss using alternative mechanisms to clear out data generated by Seymour in their production system. Additionally, C-More tests are designed to run on a set schedule but can also be triggered on demand with the "run now" button. In the future, we aim to give users the ability to trigger tests from a CI/CD pipeline, fully integrating C-More with DevOps processes.

We appreciate you taking the time to listen. Now, let's move on to the Q&A session. We will wait for a moment to see if any questions come through.

Q: What was the most challenging and exciting part of working on Seymour?

A: One team member finds the most exciting part of the project was working on something with the overall geographic distribution of tests. They found it fascinating to build something that could test and ensure that the system works from various locations around the world. However, this also posed challenges, particularly in working with the CDK and connecting the home region with remote regions. Despite the challenges, it was very rewarding.

From a technical perspective, another team member found the most exciting aspect to be learning about the different AWS resources that could be used to implement their design. They found it interesting and learned a lot during this process. At a high level, they also found it exciting that Seymour fills a niche that is not addressed by existing solutions in the marketplace, despite requiring further development.

Another team member mentioned that the most exciting part was the team collaboration in deciding on the architecture and weighing the pros and cons of each engineering decision. They found it exhilarating to see the infrastructure grow over time as they added new components and functionalities. However, they also acknowledged that the weight and impact of each decision had to be carefully considered, making it challenging.

One team member echoed the sentiment of the exciting part being the global distribution of tests during the research phase and how it sparked their imagination. They also noted that learning about AWS as a first-time user was also exciting, although there was a steep learning curve. The team had to quickly familiarize themselves with AWS and how to connect the different pieces.

Q: How did you come up with the idea for this project?

A: The team's initial interest stemmed from the concept that things can go wrong in production, leading them to explore testing. This led them to discover fuzz testing, which generates edge cases for tests that developers may not think of. From there, they learned about active monitoring and the existing products provided by SaaS solutions and open source projects. They saw an opportunity to build something unique and interesting.

Q: Where did the inspiration to build Seymour come from?

A: The team's inspiration was rooted in their realization that there was a gap in the market for a product like Seymour. They observed that the existing solutions did not fully address the needs they had identified. Although there is still work to be done to make Seymour suitable for company use, they believe it fills an unmet need in the market.

Q: Did you choose EventBridge solely for its scheduling functionality, or did you consider other options?

A: Initially, the team considered EventBridge for its scheduling functionality. However, as they delved deeper into its capabilities, they discovered that it can be used for event-driven architectures and sending event messages. They explored using other services for scheduling but ultimately found that EventBridge, combined with other components, provided a comprehensive solution.

Q: You mentioned data ownership as a con for larger enterprise solutions like New Relic and Checkly. Can you explain this further? What kind of data is sent to these solutions?

A: When the team refers to data ownership, they are primarily concerned with sensitive information such as healthcare or financial data. In traditional SaaS solutions, the data generated from an API endpoint travels to the SaaS provider's servers, where the checks and sessions are run. This data is also stored for future viewing. The team identified potential privacy issues in certain contexts. Therefore, they designed Seymour to allow users to maintain control of their data by hosting it themselves.

Q: What is the most valuable thing you learned as a software engineer while working on Seymour that you will apply to future jobs?

A: Teamwork was highlighted as the most valuable lesson learned during the project. While it took some time to synchronize processes and establish a workflow, the team eventually found their footing. They appreciated how everyone's unique strengths and weaknesses contributed to a cohesive and successful outcome. Additionally, conducting research on technical topics and working on a project collaboratively, which can be utilized by others, were also significant takeaways.

Q: Can Seymour monitor applications that are not hosted on AWS?

A: Yes, Seymour can monitor applications that are not hosted on AWS. While Seymour is designed to take advantage of AWS services, the user's infrastructure can be hosted on any cloud provider or on their own on-premises setup. Seymour's infrastructure is separate from the user's, so it does not require specific hosting on AWS. However, users will need an AWS account to host Seymour.

Q: How does Seymour maintain multi-regional infrastructure?

A: To connect to remote AWS regions, Seymour uses a queuing mechanism. Each remote region's queue subscribes to an SNS topic, creating a pub-sub model. The SNS messenger in the home region publishes a message to all subscribers, using the ARN of the topic. During deployment, each queue is set up to subscribe to the topic, ensuring that only the appropriate queues receive the location-specific messages. This method allows Seymour to maintain and manage multi-regional infrastructure effectively.

Q: What was the most challenging bug or obstacle encountered while building Seymour?

A: The most challenging bug or obstacle was encountered during the development of the test loop. Each team member worked on independent parts of the loop initially, but they needed to connect all the pieces and ensure that a test could go through the entire loop successfully. They faced difficulties in making the test configuration consistent throughout the process, as there were small differences in naming conventions. However, they resolved these issues and learned the importance of setting up consistent naming conventions in advance.

Q: How were you able to research topics and find ideas for Seymour?

A: The team used a combination of following interesting leads and conducting thorough research. They cast a wide net initially to explore various ideas and challenges. It was crucial to keep an open mind and be willing to pivot if a dead end was reached. The team engaged in discussions, which sparked their imagination and fired up their interests. Ultimately, they followed the research process, selecting the most promising ideas and considering the trade-offs associated with each. They iteratively refined their ideas and collaborated to create something valuable. Yes, our design for Simult was specifically tailored for the cloud, particularly AWS. We optimized our design to fully leverage all the services offered by AWS. However, it's important to note that Simult's infrastructure is completely separate from a user's own AWS or other cloud provider accounts. So, while it is not necessary for the user's infrastructure to be hosted solely on AWS, they do need to have their own AWS account to host certain components of Simult.

When it comes to researching topics and generating ideas, one tip is to follow your interests. During our research phase, there were many API-related topics that caught our attention. Personally, I delved into topics like GRPC and fuzz testing. By engaging in team conversations and considering input from others, our imaginations were sparked. For example, the idea of geographic distribution sparked my interest. It's important to cast a wide net initially, as this allows for exploration of various ideas. This ensures that you don't narrow down too quickly and potentially miss out on valuable research. As for the build versus wrap discussion, I initially leaned towards the wrap approach. However, keeping an open mind and being willing to listen to my teammates' perspectives allowed me to see the merits of the build approach. This research process taught me the importance of having an open mind and how even dead ends can inform the ultimate path taken.

In our team, we employed a research strategy where we explored as many topics as possible. We dedicated daily meetings to research for approximately two hours. We would present our findings to the team, and if a topic generated enough interest, we would continue researching it. However, if a topic didn't capture the interest of the team, we would move on and explore other avenues. The first week of research focused on gaining a broad understanding of what was available before delving deeper into specific topics.

When assigning team members to work on the independent parts of Seymour, we were fortunate to have overlapping interests. This allowed each member to work on the aspect that excited them the most while still contributing to the overall project. There was no need for anyone to take on a task they weren't interested in, as each team member had a unique set of strengths and preferences.

Regarding technical disagreements or conflicts within our group, we did encounter them. One notable instance was during the early stages of our discussions on how to proceed with the idea that eventually became Seymour. While we initially believed we were in agreement, as we delved deeper into specific aspects, we realized our thoughts were not entirely aligned. We took some time to thoroughly examine the technical aspects of wrapping Monica versus building from scratch. We engaged in conversations, conducted research, and explored alternate viewpoints. Through this process, we were able to find productive solutions. It's worth mentioning that we were able to separate our personal attachments to ideas and focus on objectively weighing the pros and cons of each option. Ultimately, we made decisions based on the merits of each approach, whether it involved database choices, infrastructure decisions, or even non-technical aspects such as organizing our efforts.

As we approach the end of our presentation, we can take a few more minutes to address any final questions that may arise. Please feel free to ask them now.

It seems we have covered most of the questions, so we'll give it another minute before wrapping up. Thank you all for joining us today and allowing us to present Seymour, our project. We appreciate your time and interest.