foreign welcome everyone thank you for joining us on this wonderful Monday in today's presentation we will be introducing constellation constellation is an open source serverless end-to-end framework that simplifies the challenges of geographically distributed API load testing I'd like to introduce the constellation team Andrew Jake Jason and myself Stephen unfortunately Jason is ill so Jake will be filling in for him today otherwise you'll hear from each of us throughout the presentation we'll start with exploring the problem space that inspired constellation see where constellation fits in the solution space talk about its engineering design and architecture decisions and lastly discuss some of the challenges and future work we'll start off with what load testing is in order to better understand constellations problem space load testing measures how a software program reacts to multiple concurrent users requests a load in this context is a set of requests made over a period of time to any program that handles requests these can be websites web apps or apis the illustration shows that virtual users represent real users in making requests to an API endpoint so why is load testing important for Developers load testing is important because it helps to confirm system performance assumptions by getting insights like the maximum amount of users the API can handle the effect of traffic on response times and number of successful versus failed requests as an example say Amazon has 3 million customers trying to make purchases simultaneously on Black Friday the developers want to ensure that the service can handle that amount of traffic ahead of time developers do not want to discover that the system cannot perform as expected on Black Friday Amazon found that every 100 millisecond delay in page load costs one percent of sales as of 2021 this one percent of lost sales revenue would be approximately 3.8 billion dollars and a Pages load and response times can suffer under a high load if users are located further from the servers and the servers are not optimized to handle such a large volume of requests what about manually load testing manually mimicking 3 million users accessing Amazon would be time consuming and expensive a single person or multiple people without test automation tools could not replicate this load let's look at two load testing approaches browser-based and protocol based that address this challenge browser-based load testing simulates web traffic with virtual users following a script on how to interact with application elements in actual browser instances the goal is to simulate actual user Behavior flows or transactions in an application an example would be a user logging into Amazon and going through the checkout process for a purchase protocol based load testing on the other hand simulates loads to servers using the underlying Network protocol without a browser an example is virtual users sending HTTP requests to Amazon without using a browser and then measuring the website response we chose to focus on protocol-based load testing for the following reasons test scenarios can be run without the need to develop a user interface it is less resource intensive in terms of CPU and memory usage because no browser needs to be launched this means you can generate more virtual users with the same amount of resources and the most suitable use case is for explicitly testing apis developers can encounter many challenges in developing apis as apis integrate with more services and get increasingly complex it can become difficult to determine where performance degradation occurs and what areas to optimize the location of consumers can also affect API performance in an ideal situation two consumers anywhere in the world would experience similar performances constructing the infrastructure to test that is a non-trivial problem if we look at the picture here the API provider is located in Europe one consumer is located in South America and has a response time of 100 milliseconds and another consumer located in Australia has a response time of 225 milliseconds in this case developers must investigate why these regions are experiencing service differences this form of load testing where the load is generated from distinct Geographic locations is called geo-distributed load testing many open source load testing applications exist but are challenging to use synchronously in different geographic regions that capability geo-distributed load generation is usually in the premium version of their open source tool these premium cloud-based Solutions include artillery scale Blaze meter and k6 Cloud while developers can easily leverage these tools to perform load testing they must consider the service limit trade-offs looking at the table we can see that there are limits on the number of virtual users test duration and data retention we built constellation which addresses some of these limitations let's look at each of the headings next virtual users there are different tiers for each of the premium cloud-based load testing Solutions the number of virtual users is limited by the subscription tier selected virtual user limits can be increased by upgrading the subscription tier with Max test duration having a maximum test duration with no limit is essential if developers want to test the system over several hours to validate system behaviors and uncover bugs and reliability issues again looking at the table constellation and artillery scale have no limits on the max test duration while k6 cloud and Blaze meter are limited to 1 and 2 hours again you can get a longer Max test duration by upgrading your subscription tier better attention the cloud-based SAS Solutions retain data on a rolling subscription basis once a subscription ends however the data is automatically deleted or there may be an option to purchase data retention constellations data retention period is 12 months aws's maximum period this means constellation can keep data for an extended period without paying a monthly subscription outside of the AWS fees in comparing constellation with the existing Cloud Solutions in terms of features constellation is limited to http requests parallel testing with a single test script and the visualizer displays limited metrics without further analysis constellation is for developers who need a flexible scalable open source solution or cloud-based tiered SAS Solutions are too restrictive excessive or costly next I'll hand it over to Andrew who will talk more about constellation and its design decisions thanks Steven first I want to give you a quick overview of the constellation infrastructure the framework is run from the command line given a couple of user generated setup files constellation then uses this information to deploy several Cloud components using AWS services these components are split into home and remote regions that the user identifies the home region is where they want to store the data and the remote regions are where they want load to come from during their load test Jake will discuss these files and components in more detail later in the presentation but before we get too far into constellations architecture there were several design decisions we needed to make prior to and during development of constellation and we'll walk through a few of them now first we had to decide how we were going to perform the testing itself given an API to test there are two main testing approaches usually referred to as non-scripted and scripted non-scripted testing is relatively simple the test hits a single Target endpoint with requests in a given time frame typically measured as requests per second the results are relatively straightforward it shows how performance varies given a strictly defined load on an endpoint what happens to the system with a thousand requests per second or a hundred thousand requests per second and so on while this can be useful for finding some performance issues these tests don't typically simulate real world use very well overloading an endpoint could affect the performance of another endpoint for a variety of reasons such as it being a direct prerequisite to its use or consuming shared resources scripted tests on the other hand test an API as part of a defined workflow a virtual user performs some scripted operations for example it may make requests to log in Fetch user data make some database changes and finally log out these requests kind of pauses in between or be made simultaneously whatever most accurately represents how a user will interact with the API the test load is then scaled by adjusting the number of concurrent virtual users what happens with a thousand concurrent users 100 000 concurrent users Etc however setting up a scripted test is a much more involved Endeavor developing the framework for simulating a user requires a significant effort in order to avoid restrictive resource requirements because while 10 000 users may be using 10 000 devices in the real world we'd rather not have to requisition that much Hardware in order to perform a test additionally developing the test itself how many users will perform what actions requires a clear understanding of the api's use case and it's very easy to perform a test that doesn't accurately represent how a user will actually consume the API despite this increased complexity we decided to use the virtual user scripted strategy for constellation scripted testing is just a significantly more realistic way to test an API as a whole and this allows constellation to accurately simulate users consuming an API simultaneously from around the world once we decided to use Virtual users the next question was how do we Implement them a Vu must simulate a user as closely as possible while still operating as efficiently as possible the less resources it takes to simulate a single user the more vus can be generated with the same infrastructure the vu's should also be independent from each other if one Vu encounters an error or has poor performance it shouldn't impact any of the other vus which requires some amount of parallel processing we wanted to build the load generation tool using JavaScript and there are several ways we could go about simulating users in node.js including promises child processes and worker threats we evaluated these options by looking at their ability to perform concurrent processing if they were limited in quantity the processing overhead of running them and how optimized they were for input output tasks such as making HTTP requests node.js worker threads enable parallel JavaScript threads within a single node process we disregarded them early on because they are primarily a way to take advantage of multi-core processors for concurrent CPU intensive tasks like say some calculation that takes 10 seconds to complete they are limited by the number of cores in the hardware because each thread is meant to be processing simultaneously child processes on the other hand generate separate node.js processes which is an excellent simulation of individual users each virtual user would operate independently of any other virtual user however child processes have a significant performance overhead as each process has provisioned memory and depends on the cpu's process management node.js promises don't allow for concurrent processing but they are optimized for concurrent idling five HTTP requests will be done one at a time and the responses will be processed one at a time on a first come first serve basis but the waiting period between the requests and the responses is done simultaneously and the number of promises is only limited by the amount of memory available ultimately we decided to use promises this does mean that two requests can't be sent at precisely the same time but they will be executed within a few CPU cycles of each other which is sufficient for load testing because latency differences would most likely prevent them from reaching the endpoint at the same time anyways the last major design decision that we'll discuss today was the question of what data do we store load testing services can generate a huge amount of data they are generating a large number of requests and store some details for each response that is received the responses can vary from a simple 200 okay to a large content download even when only storing metrics like the response's size and status code the sheer number of them can be daunting easily in the order of Millions because load testing tools generate so much data the tool can be seen conceptually as a large data Pipeline and there are two common approaches to managing a data pipeline ETL and elt these acronyms Define the order in which three processes occur extract which is collecting raw data from a data source transform processing and converting that raw data into a usable form and load putting the transform data into the target system the difference between ETL and elt is Windows transformation take place an ETL pipeline will transform the data prior to loading it into the target resulting in a longer loading process and a faster analysis after the data transfer is complete as a result raw data is lost and only the transformed data is stored if you need a different transformation later you need to reacquire the raw data an elt pipeline loads the data directly into the Target and the target system performs any Transformations it requires this allows transformation to be performed as needed on subsets of data and for different transformations to be performed at any time however this usually increases the total data loaded into the target we took the elt approach for constellation's primary data pipeline from the load generation service to the database this means that the complete data set is then available for inspection by the user either using the built-in constellation visualizer or using other third-party software to query the database while this results in much more data being stored in the database it allows users to access the data directly and perform any Transformations they need on Constellation test results without any loss of data or processing delays from a generic transformation process now I'll pass things along to Jake for a look into constellation's final architecture thanks Andrew now that we've talked a little bit about why load testing is a problem that needs a solution and about some of the design decisions that we made along the way while developing constellation I want to now talk a little bit about the internals of constellation and what actually goes into a geodistributed load testing application constellation is a service that is installed on a user's local machine and uses the cloud in order to enable distributed testing the constellation Cloud architecture includes a home region and some number of remote regions each piece of constellations architecture is made up of multiple components that make testing possible each part of constellations architecture holds one or more of the following components the CLI load generator data aggregator and visualizer and I'm going to go more in depth with both the architecture and the components in later slides every test will start with some sort of user input so we'll start by taking a look at the CLI interacting with the constellation framework requires the locally installed CLI application and two user-generated files the configuration file and the test script file more specifically the configuration file is used to determine the number of views and the number of regions the infrastructure needs to accommodate the test script is responsible for the details of the user Behavior to simulate and is uploaded to an S3 bucket to be later used by the load generators once the test has created the configuration file and the test script the user can then initialize infrastructure and execute the test accordingly let's not draw our attention to the home region where the first step of the testing process begins the home region acts as a hub that sits in between the user's local system and the remote regions containing orchestration and data storage using the configuration file to initialize the remote architecture and receiving the test script to be sent to the remote regions finally returning any testing data from the remote regions to a Time stream database in the home region once the initial setup is complete the focus moves to the remote regions and generating the actual test load each remote region hosts some number of low generation containers depending on the desired number of you use each load generator is limited to 200 views to provide flexibility for test scrubs the load generators retrieve the test script and configuration from the home region the load generator fulfills constellations needs to simulate views that repeatedly execute the user-defined script generating requests and passing the resulting metrics to the data aggregation container drawing attention to the diagram the API call that retrieves the test script is represented by the spinning arrows on the left and the load generator itself is represented by the person in the very middle of the diagram while on the right we see an example of what the resulting test object looks like after a single run of the test script this object contains a start time and run time for the test script as well as the start time latency and other defining characteristics of the HTTP calls made during that run these test record objects are sent to the data aggregator and batches every 10 seconds once the test duration ends constellation sends a final bash of tests to the data aggregator next I'm going to be talking a little bit about why the data aggregator is so important and what its function is in Beach remote region and the load generation process in addition to the load generators each remote region hosts only one data aggregator that receives data from each load generator in their respective remote regions as each Regional load generator sends its completed test results to the data aggregator they are saved in a sqlite database that acts as a temporary data store that we will name the cache the aggregator has a single route that is responsible for parsing and formatting the incoming data from the load generators and saving the data to the cache the aggregator then writes the data from the cache to the time stream database in 10 second intervals the aggregator is also responsible for utilizing timestream's ability to handle batch write requests of 100 records per write and handles AWS throttling exceptions to achieve more efficient write speeds at the end of the test the aggregator continues attempting to send data to timestream until it stops receiving data after the data from the aggregators has been written to the timestream database the data can then be accessed by the visualizer app as the very last stop of its Journey let's now take a look at what the data from a test will look like once testing is complete and the data is being visualized for reference the graphs in the next series of short videos is showing the data for a test that ran for a total of 10 minutes testing two different API endpoints from five different regions the data visualizer defaults to the Consolidated Regional latency graph which is the long way of saying that we can see the average latencies of every region we have tested in one place being aggregated by the same amount of time now this is quite a lot of data points let's talk next about how we can clean this data up and what we're already doing to make the data look a bit cleaner the first thing I want to mention that's going on in this GIF is the exclude first two percent button at the top right corner of the screen we noticed during testing that no matter what API we were testing there's a large latency Spike at the very beginning that wasn't representative of the rest of the data we decided to place this button in the UI because it allows the user to gain a more useful perspective on the test data without deleting any potentially useful data in the process in addition to this button the user can choose to see their data aggregated by either a 1 5 or 10 second interval this feature becomes invaluable the longer that the test is run for the visualizer app also allows the user to see only one region at a time by selecting which region you would like to view using the drop down we can also see the ratio of success to errors in easy to read bar graph next to the regional test latency graph finally you can also choose to see the graphs for individual regions all in one place with the all option and the Region's drop down so far we have gone over the components that make up constellation as well as constellations architecture starting from a local system moving into the cloud and finishing with the data being visualized back in the local system next we're going to dive into some challenges that we Face When developing constellation and what we have done to overcome them the constellation framework allows the user to test an API with virtual users that are coming from one or more regions from the perspective of the infrastructure the amount of virtual users in a test dictates the number of components involved in creating the infrastructure in addition to this the regions chosen by the user dictate how these components are distributed while developing constellation handling this manner of distribution presented significant challenges in this section I will be highlighting a couple more interesting challenges and the solutions we came up with to taggle them the first challenge is minimizing deployment time the framework allows testing from as many regions as AWS provides as such up to 23 regions can be involved for a single test before trying to optimize our deployment strategy for Speed our initial approach was synchronized deployment this involved waiting for one region to finish deployment before starting another the diagram illustrates the manner of deployment for three regions using the strategy during development we have found that each region takes around five minutes to deploy of 23 regions are used use relatively up to two hours before their test even executes this is clearly far too long per solution we implemented a parallel deployment strategy here we managed to isolate each Regional deployment as a singular process which is then executed in parallel because all regions start deployment at exactly the same time the user will only have to wait for a limited amount of time before the test is run the wait time now becomes just as long as the slowest region we'll take to deploy as such a user will only have to wait for around five minutes no matter how many regions they chose to involve in a test the Second Challenge I would like to highlight is test synchronization during development we have found that only 200 views can be generated by a single load generating component due to memory and CPU resource limitations since constellation allows simulation of up to 10 000 views the responsibility of load generation must be distributed to multiple components however Distributing work into multiple components presents its own challenges if multiple components are involved they will execute their load generation at different points in time this means that the overall load generation is staggered from the perspective of the API being tested staggered load generation means that it will not experience all 600 views at the same time as such the measured performance for that API will not be accurate the issue then is how to synchronize components so that load generation happens at the same time despite being a distributed responsibility furthermore our architecture demands the existence of an additional component in our remote regions the data aggregator this component receives data from the load generators for further processing and the diagram we illustrate a load generator sending data to an aggregator that's still getting ready since the data is not ready to be received it is dropped as load generators and data aggregators are separate components this could happen without proper synchronization in summary the need for synchronization comes from one the need to prevent data loss resulting from sending data to an aggregator which is not ready to receive data and two they need to have all load generators execute at the same time in order to tackle the problem of test synchronization we introduce an additional component the orchestrator this component is essentially a central Lambda responsible for interfacing with the distributed components to achieve test synchronization the diagram here illustrates where the orchestrator sits relative to other components already presented to illustrate the job of the orchestrator we decided to lay out three scenarios of increasing complexity the first is a single region with a single load generator the second is a single region with multiple load generators and the third and final scenario involves multiple regions this last scenario is precisely the kind of geo-distributed load testing that constellation facilitates in the first scenario we have a single load generator in a single data aggregator the requirement here is that the load generator should only undertake low generation once a data aggregator is ready to illustrate how synchronization would work let's draw our attention to the diagram with the three main components in this process shown the first component is a violet bar which represents the data aggregator the second component is the load generator this has an orange bar representing the actual bu simulation and a gray bar which is not a component but represents the blocking process the third and final component is the orchestrator to the left in this example the load generator is ready first but the blocking process prevents the load generator from beginning early in essence this blocking process continually pulls the orchestrator waiting to receive a signal if the load generation should begin from the perspective of the orchestrator that will keep the blocking process going until a ready signal from the data aggregator is received overall we can see that this has an effect of guaranteeing that an aggregator is ready before any load generators begin sending data in this second scenario we now have multiple load generators One requirement here is that the load generator should only execute once a data aggregator is ready another requirement is that all load generation should start at the same time cross the distributed components to Aid in demonstrating how synchronization would work in the scenario we represented it in the following diagram here we see three load generating components which are ready at different points in time but low generation is prevented from starting early this blocking process eventually receives a time to execute or tte this is represented as a watch and a diagram in essence this indicates the point in time in which low generation starts and the perspective of the orchestrator the tte is only calculated when it receives a ready signal from the aggregator at a high level since all load generators receive the same tte Vu simulation is synchronized in the diagram this is illustrated by the three orange bars being perfectly lined up against one another in this third and final scenario we now have multiple regions which is most reflective of what constellation facilitates here each region contains a local aggregator accompanied by multiple load generators the first requirement here is that all load generation must start at the same time for all components independent of region the second requirement is that the respective data aggregators are listening before any data is sensitive in this example we illustrate three regions with one load generator each we again see that the load generating components start at different points in time and just like before the blocking process halts any low generation from starting early for this scenario the calculation of the tte is slightly different turning our attention to the top left hand side of the diagram we can see that the orchestrator knows which regions to expect ready signals to come from as a local aggregators from the three regions become ready their respective signals are sent and received by the orchestrator once all expected ready signals are received only then is the tte calculator which is then passed on to load generators overall this has the effect that all load generators across regions execute at the same time while also guaranteeing that aggregators are readily available to receive data at a high level this is how the constellation framework achieves the requirements of test synchronization thereby ensuring accuracy and preventing data loss despite working with components spread across the globe of course software is never done and we have several ideas for improving and expanding constellation as stated earlier currently all of the test results are stored in the database while we prefer this approach as a default not all of this data is useful for all users we'd like to give users the option to provide some data transformation before storing the data if they would like to additionally both the load generator and data aggregator would benefit from being implemented in a more efficient language such as go to improve performance which would increase the number of views a single instance can produce and with that the rest of the constellation team and myself would like to thank you for watching our presentation we'd like to open up the call for any questions you may have about constellation or our process of development so Scott says what do you use for those great diagrams oh shoot I think uh Jason that's uh this question for you but that's a secret um sorry now that's we use Excalibur um highly recommend it and then uh Juan says what are your favorite problems to devise a solution for um I mean I can only you know speak personally I worked on the data aggregator um I think my favorite problem was figuring out how to uh receive data while simultaneously sending it to time stream I know the other group members have a different answer to this question actually we'll pass that one around uh you know Andrew Jason Stephen any any favorite problems uh it was it was very interesting looking into the different ways that we could uh create these virtual users um this is why why one of the section I was presenting on there was just the the different options on how to simulate multiple people all attacking an API all at the same time yeah and as for my section um I worked on the orchestration and the infrastructure and um just making all of the components work across the globe and trying to even think about that was a really challenging both challenge to to begin with um and I thought that was an awesome problem to solve and that's why we dedicated a lot of the presentation for that orchestration bit um because it was a really big challenge you got one Stephen uh mine is similar to Andrews I was working with him on the load generator the concurrent users creating the virtual users that was the most interesting problem yeah great thanks guys and then for Mitch he says how did you decide to take on this particular problem and how did your project change as you delved into the problem space you know what's funny is that we were actually looking at observation at first um and then you know as we started looking to the problem space a little bit more I think we all can probably agree we started losing interest in the problem space um and then Jason might be able to expand on this a little bit but it's thanks to him that we landed on this uh this issue um it was just a really neat problem to see a load tested across the globe that's something that we hadn't talked about before and we all know Jason at least in our group that Jason's excitement can rub off on all of us so I think that's that's really how it got started thanks Jake I appreciate it um yeah I mean at the start of our project we um only looked into stitching together open source projects um but eventually we were convinced that we had the capabilities to build everything ourselves so we could have used an open source tool for load generation we could have used an open source tool for data aggregator but um we decided to write everything ourselves and um that's how we kind of like evolved we evolved by expanding our scope um but overall we're very proud of what we achieved in this one I agree I agree uh Anonymous attendee says really cool project well done you manage rewarding data loss by making the service wait until data aggregators are ready what happens if a data aggregator crashes while transporting data which are solutions still preserve data might be a question for actually that'd be a question for me and Jason well I know that so we built the data aggregator with a sqlite database within the aggregator so sqlite is an in-file system database so as it's receiving data it's constantly writing data to that sqlite database if this uh the aggregator would crash that the data would still exist it'd be another question that how do we retrieve that data um I don't know if Jason had anything to add on that because I know he's on the architecture side yeah um so ultimately the data aggregator is actually a monolithic solution um Andrew I don't know if you can find a data at Gator um slide but yeah you have a receiver you have a cache in the middle and then you have a Ascender on the right hand side um and essentially there's some one of the monolithic solution and so the sqlite database is kind of like in memory yeah there it is I can see it um I believe that if it crashes it actually loses everything because it's just a container right um we did have we did think about using a separate service like Amazon dynamodb for cash or redis or RDS but essentially that's using a separate service to act as a cache that we only need for a very specific amount of time and so the question here is that do we keep a monolithic simple solution that's a bit less resilient or do we um build build in resiliency by keeping the cache a separate service and not a SQL database within same container um but it's a good question when it crashes it leaves the data Joey says were there any alternatives to orchestration with a Lambda that you considered um I know that there's some Cloud watch where you can look at events as things are spinning up um I know that they exist but um we we didn't have time to kind of like look at other orchestration Solutions but it's another good question thanks Joey another one from Scott how difficult was utilization at AWS to deploy in these different regions a lot of problem solving seem to be around the end solution but was figuring out that via AWS a hurdle uh yes massively um Andrew if you if you go to the synchronized deployment part of the parallel lines deployment part um so what we used AWS cdk to um to deploy into different regions well we initially found is that there were a lot of problems with tackling um multi-region deployment and so I think the the way that we kind of like did that is just having a really robust CLI and that um Andrea I believe the third slide from the last would would show them the CLI and I think that's a good part to show the people here um it has a it has a lot of checks to make sure that our configure the configuration file that the user creates first has a lot of checks to make sure that when it's deploying to different regions all of your configurations correct from AWS side otherwise the CLI will just call you out it will give you instructions on how to fix your deployment before trying on all of these different regions um yeah I hope that answers your question okay Michael says I like tte as a solution to synchronizing execution across regions very neat could you talk about how you guys decided on this and any potential Alternatives were there any challenges in calculating this oh yeah um yeah DTE was a was a really cool bit um yeah if we just click the slide to the multi-region deployment synchronization um yeah um during our first live demo with with our mentors um trying to figure out synchronization was a really big challenge we didn't really have time to look at other potential Solutions again we could have done some kind of driven event-driven programming in this side but um there is some limitations of DTE that we actually didn't talk about um yeah okay well it looks like there's no more questions with that I'd like to thank you all again for coming to our presentation it means a lot to us that you guys came and stayed through the whole thing and with that we hope to see you around in the launch School general chat 