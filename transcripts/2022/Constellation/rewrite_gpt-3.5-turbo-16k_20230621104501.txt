Welcome everyone! Thank you for joining us on this wonderful Monday. In today's presentation, we will introduce Constellation. Constellation is an open-source serverless end-to-end framework that simplifies the challenges of geographically distributed API load testing. The Constellation team consists of Andrew, Jake, Jason, and myself, Stephen. Unfortunately, Jason is ill, so Jake will be filling in for him today. Throughout the presentation, each of us will share our insights.

First, let's explore the problem space that inspired Constellation. Load testing measures how a software program reacts to multiple concurrent user requests. It helps confirm system performance assumptions. For example, developers need to know the maximum number of users an API can handle and how traffic affects response times. Load testing is especially crucial for large-scale events like Black Friday, where performance can greatly impact sales.

Manually load testing with millions of users would be time-consuming and expensive. That's why we have two approaches: browser-based and protocol-based load testing. Browser-based load testing simulates web traffic with virtual users following a script in actual browser instances. Protocol-based load testing simulates loads to servers using the underlying network protocol without a browser. We chose to focus on protocol-based load testing because it allows for more efficient resource usage and is suitable for explicitly testing APIs.

Developers can face challenges in API development, especially as they integrate with multiple services and become more complex. It can be difficult to determine where performance degradation occurs and what areas to optimize. Additionally, the location of users can also affect API performance. The goal is to provide consistent performance across different geographical locations. This challenge is known as geo-distributed load testing.

While many open-source load testing applications exist, synchronously using them in different geographic regions can be challenging. Geo-distributed load generation is typically a premium feature in cloud-based load testing solutions. These solutions have limitations on virtual user numbers, test duration, and data retention.

To address these limitations, we built Constellation. Compared to existing cloud solutions, Constellation offers no limits on virtual users and test duration. Additionally, it provides a longer data retention period, up to 12 months. Constellation is designed for developers who need a flexible, scalable open-source solution or find cloud-based tiered solutions too restrictive or costly.

Now, I will hand it over to Andrew to discuss Constellation's design decisions.

Constellation's infrastructure is run from the command line, using user-generated setup files. It deploys several cloud components using AWS services. The components are divided into home and remote regions. The home region is where data is stored, and the remote regions are where the load is generated from during load testing.

Before diving into the architecture, let's discuss some of the design decisions we made. First, we had to decide on the testing approach. There are two main approaches: non-scripted and scripted testing. Non-scripted testing involves hitting a single target endpoint with requests in a given timeframe. This approach is simpler but may not accurately simulate real-world use.

Scripted testing, on the other hand, involves testing an API as part of a defined workflow. This approach accurately simulates user behavior by performing scripted operations. We chose the scripted approach as it provides a more realistic way to test an API.

Next, we needed to implement virtual users (Vu) that simulate users as efficiently as possible. After evaluating different options, we chose to use promises in JavaScript. Promises allow for concurrent idling, ensuring efficient resource usage.

Lastly, we had to decide on our data storage approach. Load testing generates a significant amount of data, so we had to determine how to manage it. We opted for an ELT (Extract, Load, Transform) pipeline, where the data is loaded directly into the target system, allowing transformation as needed. This approach ensures that all data is available for inspection without any loss or delays.

Now, let's hear from Jake about Constellation's final architecture.

Constellation is a local service that leverages the cloud for distributed testing. Its architecture consists of a home region and multiple remote regions. Each part of the architecture contains components such as CLI, load generator, data aggregator, and visualizer.

The CLI is responsible for running Constellation and is installed on a user's local machine. It uses user-generated setup files to deploy the cloud components. The load generator generates the load by simulating virtual users, following the scripted operations. The data aggregator collects and stores the test data. And finally, the visualizer provides a built-in tool for visualizing test metrics.

In conclusion, Constellation addresses the challenges of geographically distributed API load testing. It offers a flexible, open-source solution without limitations on virtual users and test duration. With its ELT pipeline and distributed architecture, Constellation provides efficient load testing with data storage and analysis capabilities. Thank you for joining us today, and we hope you find Constellation useful in your load testing endeavors. This video discusses the coding Capstone project, which focuses on requests and storing details for each response received during load testing. Load testing tools generate a large amount of data, with responses ranging from simple 200 OK messages to large content downloads. Storing these metrics, such as response size and status code, can be daunting due to the sheer number of responses, often reaching millions.

In managing the data pipeline for load testing, two common approaches are ETL and ELT. ETL stands for extract, transform, and load, meaning the data is first extracted from the source, then transformed into a usable form, and finally loaded into the target system. In contrast, ELT involves loading the data directly into the target system, with transformations being performed as needed. While ETL pipelines result in faster analysis after data transfer, they discard raw data and require reacquisition if different transformations are needed. ELT pipelines, on the other hand, retain all data but may increase the total data load.

The constellation primary data pipeline, which involves transferring data from the load generation service to the database, follows the ELT approach. This means that the complete data set is stored in the database, allowing users to access and transform the data as needed without any loss of data or processing delays.

The architecture of the constellation project is divided into multiple components, each serving a specific purpose. These components include the CLI, load generator, data aggregator, and visualizer. The CLI, installed on the user's local machine, interacts with the constellation framework using the configuration file and test script file provided by the user.

The testing process begins in the home region, acting as a hub between the user's local system and the remote regions. The home region initializes the remote architecture based on the configuration file and sends the test script to the remote regions. It also receives testing data from the remote regions and stores it in a Time stream database.

In the remote regions, the load generators generate the actual test load. Each region hosts multiple load generation containers, each limited to 200 views to accommodate test requirements. The load generators retrieve the test script and configuration from the home region, execute the user-defined script, and pass the resulting metrics to the data aggregation container. The data record objects generated during testing are sent to the data aggregator in batches every 10 seconds.

The data aggregator, present in each remote region, receives data from the load generators and saves it in a temporary data store called the cache, implemented using a SQLite database. The aggregator parses and formats the incoming data, writing it to the cache every 10 seconds. It handles batch write requests and AWS throttling exceptions for more efficient write speeds.

Once the test concludes, the data aggregator continues attempting to send data to the Time stream database until it stops receiving new data. The visualizer app can then access the data stored in the Time stream database, allowing users to visualize and analyze the test results using various graphs and data representations.

The data visualized includes average latencies of different regions, success-to-error ratios, and graphs for individual regions. The visualizer app provides features such as excluding initial latency spikes, aggregating data at different time intervals, and selecting and comparing specific regions.

During the development of the constellation project, several challenges were faced and overcome. One challenge was minimizing deployment time, especially when testing from multiple regions. Initially, a synchronized deployment strategy was used, but it proved inefficient, taking up to two hours for tests involving 23 regions. This led to the implementation of a parallel deployment strategy, where each region's deployment is isolated and executed in parallel, significantly reducing the wait time.

Another challenge was test synchronization, particularly when distributing load generation among multiple components. As load generators and data aggregators operated independently, synchronization was crucial to prevent data loss and ensure all load generators started simultaneously. To address this, an orchestrator component was introduced, acting as a central component that coordinates the distributed load generation and data aggregation processes. With this orchestration, synchronization is achieved, ensuring that data is sent to aggregators only when they are ready.

In conclusion, the constellation project aims to provide a solution for load testing by efficiently managing the data pipeline, enabling users to store, access, and transform the test results without any loss of data. The architecture involves multiple components, including the CLI, load generators, data aggregators, and visualizers, which work collaboratively to execute and analyze load tests. Challenges such as deployment time and test synchronization were addressed through parallel deployment and the introduction of an orchestrator component. The visualizer app allows users to analyze test results through various graphs and data representations, providing valuable insights for load testing purposes. The purpose of this transcript is to explain the concept of synchronization in the context of a coding Capstone project. The project involves a load generator and a data aggregator, which are separate components. Without proper synchronization, data loss can occur due to sending data to an aggregator that is not ready to receive it. Additionally, all load generators need to execute at the same time. To address these synchronization challenges, an orchestrator component is introduced. The orchestrator acts as a central Lambda responsible for coordinating the distributed components to achieve test synchronization.

In the first scenario, there is a single load generator and a single data aggregator. The requirement is that the load generator should only generate data once the data aggregator is ready. To illustrate how synchronization works, we can refer to a diagram that shows the three main components: the data aggregator, the load generator, and the orchestrator. The load generator is ready first, but the orchestrator uses a blocking process to prevent it from starting before receiving a signal that the data aggregator is ready. The blocking process keeps the orchestrator waiting until it receives the ready signal from the data aggregator. This ensures that the aggregator is ready before the load generator starts sending data.

In the second scenario, there are multiple load generators in a single region. The requirements remain the same: load generators should only execute once the data aggregator is ready, and all load generation should start at the same time. To demonstrate synchronization in this scenario, a diagram is used with three load generating components that are ready at different times. However, the blocking process prevents any load generation from starting early. Eventually, a "time to execute" (TTE) signal is received by the orchestrator, indicating the point in time when load generation should start. The TTE is calculated by the orchestrator based on the ready signal from the aggregator. Since all load generators receive the same TTE, their virtual user simulation is synchronized.

In the third scenario, multiple regions are involved, reflecting the geo-distributed load testing facilitated by the project. Each region has a local aggregator and multiple load generators. The requirements are the same as in the previous scenario: all load generation should start at the same time for all components, independent of the region. Additionally, the data aggregators must be listening before data is sent. The diagram shows three regions with one load generator each. As in the previous scenarios, load generators start at different times, but the blocking process ensures that they start simultaneously. The orchestrator expects ready signals from the local aggregators in each region and calculates the TTE. Once all the expected ready signals are received, the TTE is calculated and passed on to the load generators. This ensures synchronous execution of load generators across regions and guarantees that data aggregators are ready to receive data.

The constellation framework successfully achieves the requirements of test synchronization, ensuring accuracy and preventing data loss despite the distributed nature of the components. However, there are still opportunities for improvement and expansion. One potential improvement is to allow users to transform data before storing it in the database, as not all data may be useful to all users. Additionally, implementing the load generator and data aggregator in a more efficient language, such as Go, could improve performance and increase the number of virtual users a single instance can handle.

In conclusion, the transcript described the synchronization concept in the context of a coding Capstone project. It explained the need for synchronization to prevent data loss and ensure synchronous execution of load generators. The introduction of the orchestrator component facilitated test synchronization, ensuring accurate results. The project team expressed their gratitude for the viewers' attention and offered the opportunity to ask questions about the project or development process. The transcript concludes with a Q&A session, addressing various questions about the project, including the challenges of deploying on AWS and the decision-making process behind the solution's design. During the presentation, we discussed the importance of properly configuring the configuration file that the user creates. This is crucial because it ensures that all configurations are correct from AWS's side when deploying to different regions. If there are any issues, the AWS CLI will notify the user and provide instructions on how to rectify the deployment before attempting it in various regions.

One of the audience members, Michael, asked a question regarding the solution for synchronizing execution across regions. We explained that we used something called DTE, which stands for "Deploy to Everything." It is a neat solution that allows for synchronization during multi-region deployment.

Michael's question prompted us to discuss how we arrived at the decision to use DTE and if we considered any alternatives. Due to time constraints, we were unable to explore other potential solutions. Although event-driven programming could have been an option, DTE provided certain advantages that we did not delve into during the presentation.

At this point, there were no further questions from the audience. We expressed our gratitude to everyone for attending the presentation and staying engaged throughout the entire session. It meant a great deal to us that they took the time to learn about our project. Finally, we hoped to continue interacting with them in the Launch School general chat and looked forward to future conversations.