Hello everyone, thank you for joining our presentation. My name is Adam, and I'm here with my teammates, Alejan, Pavlo, and Riley. Today, we're excited to share with you our project called Bastion. Over the past few months, we have been working hard on developing and refining this project.

Let's start by discussing what a backend-as-a-service (BaaS) is and how Bastion fits into the current BaaS landscape. Bastion is an open-source customizable BaaS solution that is deployed using AWS resources. It offers flexibility and extensibility by integrating with AWS Lambda to provide cloud code functionality for custom use cases.

In essence, Bastion serves as a pre-built backend that front-end developers can utilize for their applications. This eliminates the need for them to spend time building their own backend, enabling them to bring their products to market much faster.

Before diving into the specifics of Bastion's use case and features, let's take a step back and provide some context. A web application can be divided into two parts: the front end and the back end. The front end refers to the client-facing code that runs on browsers and mobile apps, responsible for the user interface. On the other hand, the back end stores information needed by the front end in a database, tracks user interactions, handles user authentication, and connects to external services.

Now, let's consider the case of Fortress.io, a small company developing a new application. While their main focus is on the front-end code, they still require a simple back end to manage user data, handle files, and implement user authentication. Additionally, their application needs to integrate with external APIs.

In the past, companies like Fortress.io would have to develop their own back end from scratch and host it on their own hardware. However, this approach is expensive and time-consuming, especially for new companies with limited resources. Alternatively, they could use cloud hosting services like Digital Ocean or Heroku, which abstract away the back end to varying degrees. While this reduces the development effort, it may not efficiently cater to Fortress.io's specific back-end needs.

Another option for Fortress.io is to use a BaaS product like Google Firebase, which provides pre-built back ends. This allows them to quickly get their products to market. However, the trade-off is limited customization and control over the back end code and infrastructure.

To address the customization limitations, BaaS providers offer a feature known as cloud code. Cloud code allows users to run functions on the server side in response to HTTP requests, even if the functionality is not natively supported by the BaaS provider. For example, Fortress.io can use cloud code to securely integrate third-party APIs like Stripe into their application.

Now, Fortress.io must decide whether to use a managed or self-hosted BaaS service. Managed BaaS services, such as Google Firebase or AWS Amplify, handle all aspects of the back end infrastructure and code, providing ease of use and support. In contrast, self-hosted BaaS solutions like Appwrite or Parse offer full control but require manual deployment and maintenance.

To make an informed decision, Fortress.io weighs the pros and cons of each option. Managed BaaS services offer quick deployment, support, and minimal configuration. However, they lack customization and may result in vendor lock-in, making it difficult to migrate to a different service in the future. Self-hosted BaaS solutions provide control and customization but require more configuration and bear the responsibility of deployment and maintenance.

To address these concerns, Bastion enters the picture. Bastion is an open-source BaaS solution specifically designed for small companies like Fortress.io. It allows them to quickly get their products to market while maintaining control over their code and infrastructure. Bastion also includes cloud code functionality, enabling easy integration with third-party APIs.

To deploy Bastion, users need to install the AWS CLI and link it to their AWS account. They can then install the Bastion CLI and use the "bastion deploy" command to deploy the admin app to their AWS account. This admin app provides a dashboard for managing and creating back ends for different projects. For example, users can create a back end for a restaurant app or a separate back end for a shopping app.

Each deployed back end runs in its own virtual private cloud (VPC) within AWS. Traffic to and from the VPC is routed through an application load balancer. The admin app is built using Express and MongoDB, which run in Docker containers managed by AWS Elastic Container Service with Fargate.

The admin app dashboard provides an overview of the deployed back ends, including their creation dates, names, and API keys. These API keys are crucial for front-end applications to communicate with the Bastion back ends. From the dashboard, users can create and delete back ends, as well as access specific information for each back end.

In the collections tab of the dashboard, users can create and manage collections, which store data for each back end. The data within these collections can be manipulated using the Bastion SDK, which provides methods for database operations, user authentication, file storage, and cloud code functions.

In summary, Bastion offers a customizable and extensible BaaS solution that can be deployed using AWS resources. It empowers small companies like Fortress.io to quickly bring their products to market while maintaining control and flexibility over their code and infrastructure. With features like cloud code, Bastion enables easy integration with third-party APIs. The admin app provides a user-friendly dashboard for managing back ends and data collections.

Thank you for your attention thus far. In the coming sections, we will delve further into the architecture and design decisions of Bastion, followed by a demonstration and discussion of future work. We will conclude with a question and answer session. Let's continue with Pavlo, who will provide a more detailed overview of Bastion. The video is about a coding Capstone project called Bastion. Bastion is a cloud-native application that allows users to create and manage backends for their front-end applications.

When using Bastion for the first time, the user is prompted to choose a username. A password is generated, which can be used to log into the admin application. Once all the prompts are followed, a cloud formation script is executed, which automatically provisions the necessary infrastructure in AWS to run the admin application.

The user can use the "bastion show" command to see a list of their deployed infrastructure, including the username and password for each instance. If the user forgets to write down this information, they can find it in the admin application.

To tear down a particular Bastion account, the user can enter "bastion destroy."

The admin application is made up of the admin dashboard and the admin app server. It is used to manage and deploy Bastion backends, such as the shopping app backend and the restaurant app backend.

The infrastructural overview of Bastion shows that it is deployed to AWS. The admin application and individual Bastion backends are contained within a virtual private cloud (VPC). All external traffic is routed through an application load balancer before reaching its destination.

The admin app dashboard, running in a browser, sends requests to the admin app server, which is a Node.js application built with Express. The server uses MongoDB for data storage. Both the Express application and MongoDB run in Docker containers managed by AWS Elastic Container Service (ECS) with Fargate.

The admin dashboard provides information about each Bastion backend, including its creation date, name, and API key. The API key is necessary for the Bastion SDK, which is used by front-end applications to communicate with the backends.

From the admin dashboard, users can create new backends, delete existing ones, or view information specific to each backend. Creating a new backend triggers another cloud formation script, which provisions the necessary infrastructure in AWS.

Clicking on a backend in the dashboard reveals details about that instance. The sidebar links change to allow navigation between collections, users, cloud code, and files.

The collections tab shows all the collections in a backend. Users can create and delete collections and manipulate the data within them using the SDK.

The users tab enables user management. Users can view a list of existing users, delete users, and create new ones.

The cloud code tab allows users to view all the cloud code functions they have created. Users can create new functions and delete ones they no longer need. Creating a cloud code function requires uploading a zip file containing the code and its dependencies.

The files tab allows users to view uploaded files associated with each backend.

The admin application consists of a front-end interface (the dashboard) and a back-end that handles basic CRUD actions from the dashboard and stores data about existing backends. The main goal of the admin app is to create and manage these backends.

Each Bastion backend, represented by Application 1 and Application 2 in the diagram, is deployed as a separate ECS cluster. Each cluster has two services: one for the Express server providing the backend API and another for the MongoDB server for data storage.

AWS Cloud Map provides service discovery between server and database instances. Docker volumes are used for data persistence, while AWS Elastic File System (EFS) provides file storage.

The Bastion backends handle requests from both the admin application and front-end applications built with the Bastion SDK. They provide services such as authentication, execution of cloud code functions, file storage, and database operations.

Creating collections and manipulating collection data is a fundamental action of the Bastion backends. When a collection is created, it is stored in the backend's database server, and API endpoints are dynamically created on the app server to provide basic CRUD functionality.

File storage is initiated using the Bastion SDK. Files are uploaded to the app server, which then uploads them to a designated S3 bucket. The URL of the uploaded file is stored in the database server, so when a read request comes in, the server only needs to return the URL instead of the entire file.

The final component of Bastion is the client SDK, which connects front-end applications to their respective backends. It provides methods for CRUD actions on collections, login and authentication functionality, execution of custom cloud code functions, and access to file storage.

Each backend has its own unique API key, which is needed for the SDK to connect to the backend. The initialize method of the SDK requires the domain name chosen during the deployment of Bastion and the API key.

The SDK provides various methods that enable developers to interact with the Bastion backend, such as getting all items in a collection or executing custom cloud code. These methods allow front-end developers to integrate Bastion's functionality into their applications.

To ensure flexibility, resilience, and manageability, the Bastion project chose to use Docker containers for its backends and the admin application. Docker containers are lighter and more resource-efficient than virtual machines because they do not require a separate operating system.

For container orchestration in AWS, the project decided to use Elastic Container Service (ECS). ECS is an AWS-managed service that offers better integration with AWS and is simpler to use compared to Kubernetes.

Bastion utilizes ECS Fargate, a serverless compute engine for containers, to dynamically allocate compute resources as needed. This results in a more cost-effective and low-admin overhead solution.

Different ECS configurations were used for the admin application and each Bastion backend. The admin application is expected to have low traffic, so auto scaling was not necessary. The application and database containers run in the same ECS task.

For the Bastion backends, auto scaling was enabled for the application server. This allows the server to scale horizontally by adding more instances as needed. The database server, on the other hand, can handle higher traffic and does not require auto scaling.

To ensure data persistence, Docker volumes and AWS Elastic File System (EFS) are used. Docker volumes provide a way to store data even when the container instances are reprovisioned, while EFS is used for file storage.

The responsibility of the admin application is to handle functionality that should be hidden from the client applications. This includes creating and deleting collections, managing cloud code functions, and initiating file storage.

The client applications, using the Bastion SDK, can interact with the collections, triggering cloud code functions, and accessing file storage. The SDK provides methods for performing CRUD operations on collections, as well as login and authentication functionality.

Each backend has its own API key, which is needed by the client SDK to connect and interact with the backend. The SDK methods allow developers to incorporate Bastion's functionality into their client applications, enabling them to easily manage their backends.

With this overview of Bastion and its architecture, the team has made design decisions that prioritize flexibility, resilience, and manageability. The use of Docker containers, ECS, and other AWS services ensures efficient and scalable deployment of the backends and admin application. We chose MongoDB as our database for the project, primarily because it can handle more than 50,000 concurrent requests. We opted for a document-oriented database over a relational one to avoid imposing schema definition and model relationships on our users. This allows users to create collections and manipulate data without needing to define a schema beforehand. We also chose MongoDB over AWS managed DynamoDB for the ease of local development.

To address the issue of data persistence when running containerized applications in the cloud, we utilize Docker volumes and AWS Elastic File System (EFS). We attach EFS mount points to the Docker volumes we define so that even if instances are stopped, started, or reprovisioned, the data remains intact.

Another key feature of our solution is file storage. Instead of using MongoDB with GridFS, which splits large files into multiple parts, we decided to use Amazon S3 for its simplicity. When a client application uploads a file to the app server, it is saved in a public S3 bucket dedicated to each bastion. The S3 URL of the uploaded object is then stored in the database. When the client application requests the file later on, the app server retrieves the file information from the database and returns the corresponding S3 URL. This approach offloads the transfer of large files and reduces the load on our application servers.

Now let's discuss the different parts of Bastion and how responsibilities are divided between them. The CLI is responsible for deploying the base infrastructure and running the admin application. The admin application, on the other hand, handles the creation and management of Bastion backends. We've defined a shared responsibility model between the client applications, the client SDKs, and the admin application. While the client applications can create, read, update, and delete data from existing collections, the creation and deletion of collections are restricted to the admin. Similarly, client applications can trigger the execution of cloud code functions, such as running the charge customer function, but the management of these functions is handled by the admin.

Cloud code is a key feature of Bastion, allowing users to define custom functionality for their applications. Initially, we considered deploying small containerized applications for each cloud code function, but this approach had drawbacks in terms of configuration overhead, cost, and resource inefficiency. Instead, we chose to use Lambdas, which are easier to provision, cost-effective (as you pay per execution with a significant free allowance), and well-suited for running specific well-contained tasks.

Let's touch upon the relationship between Bastion, CLI, and the admin application. When you deploy your Bastion VPC using the CLI application, the configuration information, admin username, and password are passed down to the admin application's environment variables. This ensures that the admin application is aware of the configuration and login settings, allowing it to create and manage Bastion backends accordingly.

Now let's dive into some higher-level decisions and discuss the Bastion architecture. After a user creates their Bastion VPC, they can log into the admin dashboard and provision multiple Bastion backends with various cloud code functions. The Bastion VPC, as a whole, consists of four subnets: one private subnet for the database tier, containing Bastion backend database servers; one private subnet for the application tier, housing Bastion backend servers, admin application, and cloud code functions; and two public subnets for internet-facing networking components.

The security of the Bastion VPC was a key consideration. By default, there is no public access to the key components, thanks to the networking components explicitly handling access. The design of Bastion VPC also takes future growth into account. It's designed for small teams with scalability in mind, and users can take over the Bastion VPC without the need to redeploy the infrastructure from scratch. The single availability zone (AZ) deployment for cost reduction purposes still allows for future expansion or higher availability through the use of multiple AZs.

To deploy your Bastion VPC, you need a domain registered with a hosted zone in AWS Route 53. It's completely fine if the domain is registered with other registrars; you can use AWS Route 53 for DNS hosting to obtain your hosted zone. Alternatively, if you're registering a new domain, you can use Route 53 for both registration and DNS hosting.

In terms of individual components, the admin application is deployed to the app tier private subnet. To allow traffic to the admin application, we configure an application load balancer (ALB) that forwards traffic to the admin application when accessed with the domain. This initial configuration is straightforward.

When a bastion backend is added, a stack creation is initiated by CloudFormation through the admin application. The CloudFormation script utilizes an image from a public ECR repository to deploy the bastion backend to the app tier private subnet. This process can be repeated for multiple backend deployments. CloudFormation provides control over the provisioned resources.

Now, let's consider how traffic is allowed to the backend servers from client applications. The ALB's rules are configured by CloudFormation to handle path-based routing based on the request URL. This allows incoming traffic to be directed to the relevant bastion backend server. In addition to incoming traffic, outgoing traffic is also necessary. Cloud code functions, for example, need to connect to external APIs or public internet services. ECS tasks also require access to public ECR repositories for provisioning Docker images. To handle this, we use an NAT gateway. Outgoing traffic from private subnets is routed through the NAT gateway.

The NAT gateway uses a process called IP masquerading. It replaces the private IP of outgoing IP packets with its own public IP and forwards the packets to the target. When a response is received, it replaces the receiver IP with the original sender IP and forwards it back. This allows both communication with external resources and public access to the Docker images.

During the development of Bastion, we encountered various architectural and code-level challenges. One of these challenges involved implementing user authentication. We decided to use session cookies to uniquely identify users. When a user logs in, they receive a cookie stored in the browser. Simultaneously, the server creates a session token in the database for session validation. During each request, the cookie is authenticated against the token in the session store to ensure a valid session.

To ensure secure cookies, we rely on HTTPS. As a result, we needed to issue SSL certificates. By utilizing SSL offloading and configuring the load balancer to forward requests over HTTP, we could minimize the burden on the application server to encrypt and decrypt secure traffic. This approach not only reduces resource usage but also eliminates the need to issue additional certificates for each backend server.

Communication between application servers and database servers posed another challenge. To determine which database server to communicate with, we considered using an internal load balancer or AWS Cloud Map for service discovery. Ultimately, we chose Cloud Map to avoid the infrastructure and complexity associated with the internal load balancer option. With Cloud Map, containers can be registered with a custom name, resolving to the internal IP address of the container. This allows direct communication between application and database containers.

Implementation of cloud code functionality presented additional challenges. We needed to determine how to create the functions and manage their dependencies. To restrict the creation of cloud code functions and prevent unauthorized access, we limited the functionality to the admin application. Additionally, we had to ensure that these functions could interact with resources within the user's AWS infrastructure and external resources like public API services.

These are just a few examples of the challenges we faced while building Bastion. To conclude, Bastion is a sophisticated solution that utilizes MongoDB, Docker, AWS services, and various architectural patterns to provide a scalable, secure, and user-friendly platform for managing backend infrastructure and custom functionality. We are excited to demonstrate the powerful capabilities of Bastion through a live demo showcasing a social media implementation. Now, Riley will take over and walk you through the demo. This is a transcript of a coding Capstone project video. Today, I will discuss the issue we encountered with HTTP in SSL offloading. The problem was that when requests with cookies were sent to our load balancer over HTTPS, they would be routed to our app server over HTTP. This caused the cookies to be refused, even though they were still technically secure. To solve this problem, we configured our server to use something called a trust proxy. This tells the server to trust the request coming from our load balancer, which is located one network hop away. Since we know the load balancer receives requests over HTTPS, we can be sure it hasn't been tampered with and that the server can trust it. This allows the cookies to pass through and be accessible to our application server.

Another challenge we faced was determining the best way for application servers and database servers to communicate with each other. Each app server stores data in a separate database to separate concerns. This means that each app server needs to know which database to talk to. We considered two options. Option one was to use an internal load balancer, which would serve as a centralized location for managing all connections between each service. App servers would route traffic through this load balancer, which then decides which database server to route the request to. The other option was to use service discovery using AWS CloudMap. This allows for direct communication between application and database containers. CloudMap allows you to register container tasks with a custom name, which gets resolved to the internal IP address of the container. When a new backend is created, a new private DNS namespace is also created. We chose to use CloudMap because we wanted to avoid the extra infrastructure and complexity of the internal load balancer option, which would lead to higher costs and increased maintenance.

Implementing our cloud code functionality was also a challenge. We needed to figure out how to create our functions and handle dependencies. We decided to limit the creation of cloud code functions to our admin application to prevent unauthorized access. We also needed to figure out how our customers would execute these functions and interact with resources within their AWS infrastructure, as well as resources available through the public internet, like external APIs. We chose to upload a zip file with all the function dependencies to an S3 bucket. Lambda would then pull the necessary files for execution. This approach allowed for a cleaner process, although it did require adding an additional infrastructure component with the private S3 bucket.

One challenge we encountered with the invocation of our cloud code functions was ensuring they could interact with both private AWS resources and resources on the public internet. The public access method, shown on the right, was straightforward. It requires no configuration and allows access to external resources like third-party APIs. However, it can't interact with our own AWS resources. To enable interaction with existing resources, we needed to configure our functions with the correct security credentials to work within our VPC. We also had to provide the correct subnet information for access to components within our infrastructure. This involved the option shown on the left. By configuring these correctly, we ensured our cloud code functions could add extensive functionality while maintaining security.

Now, let's look at an example application that integrates with Bastion. The application utilizes our SDK to communicate with created Bastion backends. It demonstrates how functionality can be easily integrated using our SDK modules. Users can create new users, log existing users in and out, and perform actions on the database collections. Uploading files is also supported, creating entries in the database with the relevant URLs for retrieval. Accessing files by their ID is as simple as using the public S3 URL retrieved from the database. This demonstrates how our SDK allows customization of the front-end to execute functionality created in the backend.

To use Cloud Code functions, you can refer to how Fortress IO implements them in their front-end code. They utilize the Bastion SDK with the `bastion.ccf.run` function. This allows them to run cloud code functions that have been defined in the admin dashboard. They can interact with external APIs, such as Stripe, by passing the function name and any necessary parameters. This provides flexibility and extensibility to the front-end development process. Fortress IO's application serves as an example of how cloud code functions can be used to integrate with external APIs, like Stripe payments.

Regarding future development of Bastion, there are a few areas we would like to focus on. First, we would like to add the ability to whitelist front-end domains. This would improve the security of client applications interacting with Bastion, allowing a list of allowed domains to access each server, reducing the risk of API key exposure. Currently, our SDK only supports JavaScript for front-end web developers. We plan to add support for other languages, such as Java and Swift, to cater to mobile developers. Additionally, we would like to add the ability to use Redis for session storage. While our current use of MongoDB fits our needs, Redis can handle session storage more efficiently at scale. Lastly, deploying Bastion in multiple availability zones would increase availability and resilience against outages.

Thank you for attending our presentation. We hope you found it informative. We will now take some time to answer any questions you may have. You can submit your questions in the chat or in the Q&A section. During our development process, we performed multiple iterations, making it relatively easy to incorporate fashion as a functional component of our infrastructure for a longer period of time. Rather than relying on a managed bad service that limits flexibility and makes it challenging to implement changes or add new functionality, our approach allows for more control. Unlike obfuscated code, which can cause frustration when encountering limitations or the need for modifications, our method offers a more seamless experience. 

Let's dive into how we utilized Cloud Map to connect containers in private subnets. Cloud Map serves as an internal private DNS solution. When we create a bastion backend, we establish a new namespace. This namespace provides a dedicated location and a user-friendly name to access it. When we need to reference the namespace from another container, such as when requiring a URL, we can simply use the name as a prefix. For instance, we might use "name." or "db.name." By implementing this approach, the namespace resolves to the address of the corresponding service we registered, akin to how DNS functions on the public internet. Cloud Map acts as the AWS-hosted version of this technology. 

We have received a question about whether a microservice architecture can utilize bastion by having multiple bastion instances communicating to form a system. It's important to clarify that bastion instances are not designed for a microservice architecture. By nature, back-end instances are not meant to be modified, according to our current configuration. However, if someone were to take over our architecture and modify our Docker images, it would indeed be possible to align with the principles of a microservice architecture. Nevertheless, the primary use case for bastion as a service is not geared towards a microservice architecture. Instead, our target audience consists of small teams, predominantly composed of front-end developers who aim to focus on front-end development rather than building back-ends. Essentially, they seek a straightforward server solution. 

We appreciate you taking the time to watch our presentation and hope you found it insightful. Thank you for joining us today.