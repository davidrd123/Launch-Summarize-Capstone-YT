Thank you for joining our presentation on BART, an open-source session replay tool for viewing and analyzing user sessions. We are excited to share our project progress with you. Let's begin by introducing the team. Our fully remote team is spread across three different time zones. Morrison is in Vancouver, Nino is in Boston, Jean is in Tulsa, and I am Aaron, based in Austin. Today's presentation will be divided into six sections: problem domain, what is BART and its use, BART's architecture, major design decisions, challenges faced during development, and deployment options.

To understand the problem domain that BART aims to address, we need to discuss a few concepts. A user session refers to a sustained interaction of a user with a web application. It begins when the user starts interacting with the application and concludes when the user leaves the page or remains inactive for a certain period. User conversion refers to an action that developers want users to complete, such as subscribing to an email or making a purchase. Understanding user experience and interaction with an application is crucial for developers looking to improve conversion rates. However, developers often have limited insight into user experiences, making it challenging to identify reasons for low conversion rates.

To gain insight into user behavior, developers can use tools like heat maps, which provide a visual representation of user interactions on a website. While heat maps are useful for understanding user attention and interaction, they lack the ability to show the full context of why users deviate from the intended conversion path. Metrics, on the other hand, offer high-level information about website performance, including traffic, top viewed pages, and conversion rates. However, metrics alone cannot provide the qualitative data and context needed to understand why users may fail to convert.

This leads us to session replay as a solution that combines qualitative and quantitative data. Session replay allows for a reproduction of a user's session, providing insight into their interactions and difficulties encountered while using the application. By analyzing session recordings, developers can identify areas where users deviate from the conversion path. Session replay offers a comprehensive view of user behavior, including conversions, errors, and interaction patterns. However, it is important to note that session replay does not provide a complete picture of the overall application health or collective data.

Existing session replay tools, such as post hog and open replay, offer extensive features like metrics, heat maps, and conversion analysis. However, these tools often require users to relinquish ownership of their data and may impose storage costs. DIY solutions, like RR web, offer flexibility but require significant effort, time, and expertise to implement and maintain. As a simpler alternative, we developed BART to prioritize simplicity, data ownership, and easy deployment. BART allows users to quickly deploy the tool, retain data ownership, and perform simple conversion analysis.

Now, let's delve deeper into what BART is and how it is used. BART is an open-source session replay and conversion analysis tool. It enables the review and analysis of user sessions, allowing application owners to filter and view recorded sessions as if they were videos, analyze conversion funnels, and gain valuable insights. BART's user interface displays a list of recorded sessions that can be filtered based on various criteria such as date, duration, application name, and errors. Users can select a session to view and play back the user's experience.

During session playback, the progress bar highlights custom events and errors logged to the console, making it easier to locate interesting moments in longer sessions. While the playback may resemble a video, it is actually a stream of timestamped data representing DOM mutations and browser events generated during the user's interaction with the web application. Each recorded data point is transformed into an event with a type, timestamp, and specific event data.

Additionally, BART includes conversion analysis functionality. Users can create and analyze conversion funnels, consisting of predefined steps leading to the desired conversion action. For example, a funnel could track the percentage of users who successfully complete a purchase after adding an item to their cart and clicking the checkout button. By examining funnel results, application owners can identify where users drop off along the conversion path. Analyzing individual user sessions within the context of the conversion funnel allows for efficient debugging and issue resolution.

Now, let's take a closer look at the architecture of BART. It comprises eight components that can be categorized into three groups: collection, data processing and storage, and analysis and replay. The collection group includes the agent, which is responsible for collecting session data from web applications. The agent is implemented as an npm package named Bard RR (record and replace). It monitors the browser and collects the necessary data to reconstruct user sessions, which is then sent to BART's backend. The agent records DOM mutations, user events, and expands upon RR web to enable additional features.

The data processing and storage group handles the incoming session data. BART's backend processes and stores the data. Finally, the analysis and replay group is responsible for analyzing the session data and facilitating session replay. BART's user interface allows users to view and analyze recorded sessions, create and manage conversion funnels, and gain insights into user behavior.

In conclusion, BART is a user session replay and conversion analysis tool designed to simplify the analysis of user experiences and conversions in web applications. It bridges the gap between qualitative and quantitative data, allowing developers and application owners to gain valuable insights into user behavior. BART prioritizes simplicity, data ownership, and easy deployment, making it an accessible solution for those seeking to understand and improve user conversion rates. In this video, we will discuss the event sequence and steps involved in purchasing a Chemex Coffee Brewer. The first step is adding the Chemex to the user's cart. The second step is clicking the "place order" button, and the third step is the conversion, indicating that the Chemex was included in the order.

Moving on to viewing an existing funnel, the funnel's results provide information about how many user sessions entered, how many completed or dropped at each step, and the completion percentage of each step based on the initial number of sessions.

For example, we have a funnel for user sessions of the Better Brew app, where the user conversion is defined as completing an order. Looking at the last step, we can see that 55% of sessions that entered the funnel successfully placed an order. Interestingly, three out of the nine sessions that completed step three, clicking the checkout button, did not end up placing an order.

This is where Bard comes in. Bard allows us to view these user sessions from the funnel page, providing context as to why users are having trouble placing an order. If we select one of the dropped user sessions, we can see that the checkout form went blank on the user twice after they filled it out. This likely caused frustration for the user, leading them to take their business elsewhere without reporting the issues faced. Putting this session in the context of the conversion funnel allows application owners to quickly identify where issues occur on their web applications. This can be a great starting point for debugging, without the need to track down the specific user to gain context for the problem.

Now, let's take a closer look at the architecture of Bard. Bard consists of eight components that can be divided into three main groups: collection, data processing and storage, and analyze and replay.

Starting with the collection group, we have the agent, which is contained in an npm package called Bard RR (Bard Record and Replace). The agent monitors the browser and collects the data needed to reconstruct user sessions. This data is then sent back to Bard's backend. The agent records Dom mutations, such as adding or removing elements, as well as user events like mouse movements, clicks, and scrolling. It expands upon RR Web, the session recording engine, to enable additional features such as data authentication, session persistence, and custom event tracking.

Moving on to the data processing and storage group, we have five components. The agent API receives and processes the data sent from the agent instances. It performs tasks such as data authentication, identifying conversion events, tracking session metadata, and capturing all event data recorded by RR web. The agent API then sends this data to a RabbitMQ message queue. RabbitMQ supports a high throughput of event data and integrates directly with ClickHouse, an analytical column-oriented database. ClickHouse stores event data from RR web, conversion event data, and metadata for finalized sessions. In addition to ClickHouse, we have a Postgres database that stores metadata for active user sessions and the data defining a Bard user's conversion funnels. This data is stored separately in Postgres because it is treated as mutable, while the data in ClickHouse is treated as immutable. The session ender, a cron job, scans the active user sessions in the Postgres database and finalizes any sessions based on the time since the last recorded activity. When an expired session is detected, its data is moved from Postgres to ClickHouse.

The last group of components is the analyze and replay group, consisting of the replayer API and the replayer user interface. The replayer API connects Bard's user interface to the ClickHouse and Postgres databases. It handles operations such as listing user sessions, retrieving session replay data, and all CRUD (create, read, update, delete) operations for conversion funnels. The replayer user interface, built with React, allows Bard users to filter through sessions, replay them, define and view conversion funnels.

To summarize Bard's architecture, we have three main groups of responsibility: collection, data processing and storage, and analyze and replay. The collection group includes the agent, which collects session data and sends it to the agent API. The data processing and storage group consists of the agent API, RabbitMQ, ClickHouse, Postgres, and the session ender. The analyze and replay group includes the replayer API and the replayer user interface. These components work together to provide comprehensive data collection, processing, storage, analysis, and replay functionalities for Bard.

Now, let's discuss the design decisions we made while building Bard. Data management was the key focus, as we needed to handle three distinct types of data, each with its own characteristics and challenges. The three data types are session data, funnel data, and event data.

Session data is metadata attached to each user session, providing information such as session length, the app it came from, and any errors. The challenge with session metadata is that it can be mutable or immutable, depending on whether the session is active or ended. We needed to be able to update active session data but keep the ended session data immutable. Additionally, session data has a low volume.

Funnel data corresponds to the funnels created by Bard users for conversion analysis. Funnel data needs to be mutable, as users should be able to create and edit their funnels. Funnel data also has a low volume.

Event data is generated by RR Web and contains information about user actions within the browser. It is used for conversion analysis and session replay. Event data is always immutable, and the challenge lies in its high volume. Up to 10,000 events per second can be recorded for just 200 users.

Considering these challenges, we started with event data as our starting point. We needed a database that could handle high write throughput and complex queries over large amounts of data. We initially explored PostgreSQL, a typical relational database, but it couldn't handle the required write throughput for 10,000 events per second. Next, we looked at NoSQL databases, specifically document databases like MongoDB. While MongoDB offered higher write throughput, its data structure didn't fit well for conversion analysis. We also considered time series databases, which had high write throughput but had limitations in terms of querying older data. Finally, we turned to column-oriented databases, which proved to be the solution we needed.

We evaluated two column-oriented databases, Cassandra and ClickHouse. While they both met the column-oriented requirements, we discovered that Cassandra was a transactional database, optimized for simultaneous operations but not complex queries. ClickHouse, on the other hand, was an analytical database, optimized for complex queries but not designed for simultaneous operations. However, we found that by integrating ClickHouse with RabbitMQ, which handles the high volume of event data, we could solve the challenges we faced. RabbitMQ would handle the write throughput, while ClickHouse's native functionality supported complex queries over large data sets.

For session and funnel data, which have lower volumes and require mutability, we chose to use PostgreSQL. Its relational model and lower write throughput needs made it suitable for these data types. Separating this mutable data from the immutable event data in ClickHouse allowed for efficient data management in Bard.

In conclusion, Bard's design decisions were guided by the need to effectively manage session, funnel, and event data. We chose a combination of column-oriented databases, integrating ClickHouse with RabbitMQ for event data and using PostgreSQL for session and funnel data. This design achieved high write throughput, supported complex queries, and enabled efficient data management for Bard. Cassandra and ClickHouse are both column-oriented databases, but it became clear that they were not directly comparable. Cassandra is a transactional database, designed to support multiple simultaneous operations, while ClickHouse is an analytical database optimized for complex queries over large data sets. ClickHouse, however, only supports a limited number of simultaneous queries. Sending all our event data directly to ClickHouse would overwhelm it. To overcome this, we integrated ClickHouse with RabbitMQ, a message queue that can handle high volumes of data. RabbitMQ acted as a buffer, allowing the data to flow smoothly into ClickHouse. This integration solved our problem by combining RabbitMQ's high write throughput with ClickHouse's ability to handle complex queries on large data sets.

While ClickHouse was suitable for event data, it was not well-suited for storing session and funnel data. These data types required frequent updates, which ClickHouse is not optimized for. We decided to use PostgreSQL to handle session and funnel data, as it is a relational database that can handle updates efficiently. Funnel data was stored in PostgreSQL, while session metadata lived there until a session expired. At that point, the metadata was moved into ClickHouse. PostgreSQL was able to handle the lower volume of session and funnel data effectively.

Implementing key features in Bard came with its own set of challenges. One major challenge was organizing the data into sessions. We used a unique identifier for each session and tagged each piece of data with the appropriate session ID. Persisting the session ID across page reloads and navigation presented a challenge, but we were able to solve this by utilizing the session storage browser API. This API provided a key-value store that persisted while the user kept the browser tab open. When the user navigated away or closed the tab, the session ended. On the server-side, we used a separate component called the session enter to mark the end of sessions.

Conversion analysis posed another challenge. We decided to use funnels to perform this analysis. Each funnel consisted of a name, session filters, and an event sequence. For example, we could create a funnel to analyze the conversion rate for the online store Better Brew. The session filters would define the subset of sessions to analyze, and the event sequence would define the conversion path. Bard executed a sequence of queries for each event in the event sequence, using the results of the previous query as the base. This allowed us to execute any funnel easily.

To ensure security, we implemented authentication for requests sent to the agent API. When an agent instance started, it obtained a JSON web token from the tokens endpoint. This token was then included in the headers of all subsequent requests made to the events endpoint. The agent API authenticated all requests before taking further action. This authentication measure protected the application from processing illegitimate requests.

If you would like to try Bard, you can clone the deploy repository and choose between two options. Running Docker Compose up will create a local containerized version of Bard's components, while running a script will do the same on Amazon Web Services. After setting up Bard, you can instrument your application by inserting Bard's agent into your front-end code. Just install the Bard-Rr npm package, import the agent class, create an instance, and invoke its start method with the necessary parameters.

In conclusion, our journey with Bard involved tackling various challenges, from selecting the right databases to implementing key features such as session organization and conversion analysis. By integrating ClickHouse with RabbitMQ, we overcame limitations and optimized the handling of high-volume event data. PostgreSQL proved to be the best choice for session and funnel data storage, efficiently handling the required updates. Bard's implementation challenges were addressed through creative solutions, such as utilizing the session storage browser API and executing funnels with dynamically generated queries. We also ensured security by implementing request authentication. With the availability of Bard's source code on GitHub, you can explore the project further and try it out for yourself. Thank you for attending our presentation and we hope you find Bard as exciting and useful as we do. The organization's code for each component is now available on their GitHub repository. A question arises in the chat, asking how they came up with the idea for the project. One team member explains that they were inspired by another Capstone project called "Retrospect" which focused on a similar issue, but not as deeply as they intended to explore it. They were particularly inspired by the concept of session replay, as it is interesting to see a replay of a session after it has been completed. They wanted to take a deeper dive into conversion analysis, which led them to their current project.

Another question is posed in the Q&A section, asking if the analysis is only performed on predefined funnel sequences or if there is an exploratory feature that searches all possible permutations of files. They clarify that the analysis is only performed on predefined funnel sequences. However, all events are stored, so if a funnel needs to be created after the fact, all previous session recording data will be available for analysis.

A question is then directed to the team, asking for more information on how they came across this problem domain and if there was team interest in conversion data. They respond by stating that it is similar to a previous question and do not have any further details to add.

Another question asks about the most challenging problem they faced during the project, wondering if each team member had a different perspective. One team member shares that for them, the most challenging part was the process of juggling databases and designing the system until they found a solution that would work. This involved learning how to use different tools and databases, which presented a unique set of challenges. Another team member mentions the difficulty of dynamically creating funnels for SQL queries on ClickHouse, which took them some time to overcome. Additionally, one member found it challenging to find a database that was supported and behaved the way they intended, requiring them to explore various options.

The Q&A session continues with a question about how the team implemented the front-end. They explain that they used JavaScript with the React framework to build the front-end. They also utilized the Material UI library, which integrates well with React and provides pre-built components with built-in features. They specifically mention that the table component from Material UI was a significant time-saver as it included pagination and the ability to sort by columns.

Joey asks if there were any features of session replay tools that they would have loved to implement if they had more time. One team member responds that a "click rage" feature, which detects when users rapidly click multiple times, would have been a valuable addition. They also mention the desire for more flexibility when creating funnels, allowing for more complex logic between events.

When asked if there is a learning curve or overlap between session replay tools, they acknowledge that some tools can be overwhelming due to the numerous features they offer. However, they note that once a tool is selected, using it becomes less of a challenge. However, transferring data from one provider to another can be tricky, as providers may not make it easy to move the data.

The team is asked about the process of converting raw session data into a replayable video. They explain that when a web application records event data, it starts with an initial snapshot of the entire structure of the web page called the document object model (DOM). Then, events such as DOM mutations, browser events, and JavaScript code initiated by users are recorded with timestamps. The replay player emulates these events on a separate DOM structure inside the player, creating the illusion of a video replay. They mention that this separate DOM structure is contained within an iframe element in the replay.

The final question asks if there are any browser APIs they wish they had to make building the project easier. One team member expresses the desire for a reliable event that detects when a tab is closed, as it would have been useful for signaling the end of a session to the backend. However, they ultimately found an alternative way to end sessions and did not encounter any major issues. They speculate that such an event could be handy in other situations as well.

In conclusion, the team thanks everyone for attending the presentation and expressing interest in their project, Barb. They hope that the attendees enjoyed learning about the project and appreciated the insights they provided during the Q&A session.