Hello everyone, thank you for joining us today. My name is Lisa and, along with my colleagues Emily, Kathy, and Kyle, I have developed an observability tool for GraphQL APIs called Q Mentis. In this presentation, we will discuss the challenges faced by a hypothetical company called Novels and Barnes with their mobile web application. We will then delve into the benefits of developing a GraphQL API and explain what observability is. After that, we will cover existing GraphQL observability solutions, demonstrate Han Tests, provide a technical deep dive of the Q Mentis architecture, discuss implementation challenges, and finally, demonstrate the installation process. But before we dive into the details, let me briefly explain what Hanitas is. Hanitas is an open-source observability solution for GraphQL APIs. It simplifies the collection, processing, and visualization of metrics and traces data, making it easy to track errors and analyze API performance at the resolver level.

Now, let's talk about Novels and Barnes. They are an independent bookstore with brick and mortar locations as well as an online store. With a small engineering team of just two full-stack engineers, they are responsible for maintaining the monolithic single server app that supports their business. Over the past year, Novels and Barnes have experienced a significant increase in sales, particularly through their mobile web app. However, along with the increase in sales, there has been a rise in customer complaints, specifically about slow performance. This is problematic as high latency impacts customer satisfaction and ultimately affects sales. To address this issue, Novels and Barnes decided to implement a GraphQL API for their mobile web app.

The decision to develop a GraphQL API stemmed from the limitations of their previous approach, where the frontend communicated with the backend via a REST API. With this approach, the server would send a large amount of information about books, authors, and genres to the client, leaving it to sort through the data and select relevant information. While this worked well for desktop browsers and low levels of traffic, it became a performance bottleneck as mobile traffic increased. To load a page, the client had to make multiple requests to different endpoints, resulting in high network traffic and slower page load times. By implementing a GraphQL API, Novels and Barnes were able to address these issues. With GraphQL, the client only needs to make one request and can customize the query to fetch exactly the data needed. This reduces network traffic, improves performance, and provides a better user experience.

One common issue with REST APIs is data over-fetching, where the client receives more information than needed for a specific request. GraphQL avoids this problem by allowing queries to fetch only the data required, minimizing bandwidth usage. While implementing a GraphQL API required additional work on the backend, Novels and Barnes believed that the benefits outweighed the costs, considering their small engineering team that handles both frontend and backend tasks. However, after deploying the GraphQL API, the team recognized the need for observability to monitor the health and performance of their application.

Observability, in the context of software development, refers to the ability to measure and analyze a system's current state based on the data it generates. It helps developers understand what is happening within the system, facilitating effective troubleshooting and debugging. There are three pillars of observability: metrics, traces, and logs. In this presentation, we will focus on metrics and traces, as these are the data types collected by Q Mentis. Metrics provide developers with a high-level overview of the system's health by aggregating numeric measurements over time. They help answer questions such as performance degradation, increased latency, and error rates. Traces, on the other hand, provide detailed information about the journey of a request, enabling developers to identify failures and performance bottlenecks.

For GraphQL APIs, observability needs to be approached differently compared to REST APIs. One key difference is that GraphQL APIs typically have only one endpoint, unlike REST APIs that have multiple endpoints. Metrics alone do not provide enough context to identify the root cause of issues with GraphQL APIs. For example, high latency could be due to the complexity of a GraphQL operation or a performance bottleneck, and metrics alone cannot pinpoint the exact cause. Traces are essential for GraphQL observability, even with a monolithic architecture, as they provide detailed information about requests, including the operations performed and any errors encountered.

Existing GraphQL observability solutions can be categorized into fully managed services or do-it-yourself (DIY) approaches using open-source tools. Fully managed services such as Apollo Studio and Hasura Cloud offer comprehensive observability and monitoring features specifically for GraphQL APIs. These services simplify the process of collecting and analyzing metrics and traces and provide easy-to-use UIs. For example, Apollo Studio's monitoring dashboard visualizes metrics like request rate, latency, and error rates, offering meaningful insights to developers. DIY approaches rely on open-source tools and libraries to implement observability. These solutions provide flexibility and can be tailored to specific requirements.

In conclusion, Novels and Barnes recognized the need for observability after implementing a GraphQL API to improve the performance of their mobile web app. They understood that metrics alone were not enough and that traces were necessary to identify and solve any issues. Existing GraphQL observability solutions, both fully managed services and DIY approaches, can address these needs by collecting and analyzing metrics and traces data. Hanitas, our open-source observability solution, aims to simplify the process for developers by abstracting away the complexity of collecting, processing, and visualizing metrics and traces data for GraphQL APIs. In the next parts of this presentation, Emily will discuss the differences between observability for GraphQL APIs and REST APIs, Cal will demonstrate Han Tests, Kathy will provide a technical deep dive of Q Mentis architecture, and Cal will discuss implementation challenges and future work. Rest API developers typically track errors using status codes. If a response has a status code of 400 or 500, it is counted as an error. However, with GraphQL, most status codes will be 200, even if there is an error. Therefore, relying solely on status codes to count errors will underestimate the actual error rate.

In the diagram, we can see the difference between the real error rate and the error rate calculated using status codes of 400 or 500. This is because GraphQL handles errors differently. In GraphQL, all errors, regardless of status code, are handled as part of the response body under a special "errors" object. To have a clear picture of the GraphQL API's health, developers need to track this "errors" object instead of relying solely on status codes.

Adequate GraphQL observability services require developers to track both metrics and traces. Metrics give a broad overview of the system's overall health and help identify potential problems. Metrics are like the tip of the iceberg. Traces, on the other hand, are essential for finding out the specific problem and its location. Without metrics, it's hard to spot problems because there will be too many traces. Metrics provide an easy and quick way to spot a problem, while traces provide the necessary information to understand what is happening and how to solve it.

Let's take a look at an example of a GraphQL-specific trace. The trace includes the operation name, trace ID, total duration of the request, and the root span. The root span encapsulates the latency of the entire request. Every GraphQL request goes through parsing, validation, and execution phases. Within the execution phase, there are separate spans for each phase. These spans include the operation type, names of parent and child resolvers, and associated child spans. These GraphQL-specific parts of a trace help developers gain a better understanding of the journey of a GraphQL request and identify any bottlenecks or errors that may occur.

Now, let's discuss existing GraphQL observability solutions that Novels and Barnes could consider. There are a few options to explore, including fully managed services like Apollo Studio and Hasura Cloud, as well as a DIY approach using open-source tools.

Apollo Studio and Hasura Cloud are two popular fully managed observability and monitoring cloud services for GraphQL. They offer many features and have a relatively simple-to-use UI. Apollo Studio is a cloud platform that helps with all phases of GraphQL development, including monitoring metrics and traces. Hasura Cloud also manages the infrastructure of GraphQL applications, offering real-time monitoring and tracing. Both solutions provide meaningful information, such as the operation name and type.

Here is a view of the monitoring dashboard in Apollo Studio. Users can easily visualize metrics information, such as request rate, latency, and error rates. They can also see which operations were most requested, took the longest, and had the most errors. The graph at the bottom shows the request rate over time, making it easy to identify traffic spikes.

Here is another view of the Apollo dashboard. It shows the request latency over time. This dashboard helps show when slow requests occurred. The visualization of request latency distribution makes it easy to spot outliers and slow requests.

Hasura Cloud's dashboard is similar to Apollo's. It shows the same three metrics: request rate, error rate, and latency. It also provides information on which operations were most requested, had the most errors, and had the highest latency.

Novels and Barnes could choose to use Apollo Studio or Hasura Cloud as their observability tool. However, Apollo Studio requires payment to access traces, and the free version of Hasura Cloud has limitations on the number of requests per minute. Novels and Barnes, experiencing increased traffic with new customers, would prefer to avoid such limitations. Additionally, both Apollo and Hasura would own the collected data, and Novels and Barnes would not be able to access data collected beyond a certain number of days. As a small company aiming to minimize costs and retain data ownership, neither Apollo nor Hasura is the best fit for Novels and Barnes.

In addition to fully managed services, Novels and Barnes could consider a DIY approach. This would give them full control over the features and functionality of their observability tool. However, the DIY approach requires extensive research, as it involves exploring and integrating different components. It is resource-intensive and time-consuming. With a team of only two people, Novels and Barnes would prefer to focus their time and effort on the business logic of the application, rather than investing in a DIY observability solution.

There is a third solution that Novels and Barnes could consider: Keymantis. Keymantis is an open-source observability tool specifically designed for GraphQL APIs. With Keymantis, Novels and Barnes can maintain control over their data without relying on a third party. Keymantis is well-documented and designed for easy setup, minimizing time and cost. It allows users to see both metrics and traces in one dashboard, providing comprehensive observability. Although Keymantis may have fewer features compared to managed cloud solutions, it is free and does not have any limitations on time or storage. This allows Novels and Barnes to invest their energy back into their business needs.

After discussing the pros and cons of various GraphQL observability solutions, Novels and Barnes have found Keymantis to be a great fit for their business. Now, let's dive into how Novels and Barnes can use Keymantis in more detail.

If Novels and Barnes choose to use Keymantis, their small development team can benefit from free real-time metrics and traces specifically designed for GraphQL APIs. They don't need to learn or implement any new observability technologies. By monitoring the real-time request rate, error rate, and overall latency, Novels and Barnes can assess their application's usage. They can also analyze and distinguish every request trace made to the GraphQL endpoint.

The Keymantis dashboard provides a comprehensive view of metrics and traces side by side. This allows users like Novels and Barnes to gain valuable insights into the performance of their GraphQL API. For example, they can observe how the request rate and error rate move together in the metrics section, and identify potential issues. By examining traces alongside metrics, they can easily pinpoint outliers and problems. This is crucial for investigating and addressing bottlenecks, ensuring high-quality performance and customer satisfaction.

Traces in Keymantis provide detailed information about each request made to the GraphQL endpoint. They allow Novels and Barnes to understand the execution flow and identify any inefficiencies in their resolvers. By investigating slow requests and analyzing the associated spans, Novels and Barnes can make improvements to their resolvers and optimize response times.

In this demonstration, we showed an example of an inefficient resolver in a trace. With proper observability, Novels and Barnes can easily spot and rectify such issues. This is vital for maintaining the efficiency and performance of their GraphQL API. By using Keymantis, Novels and Barnes can track down issues from the dashboard all the way to resolvers, maximizing their ability to respond to and resolve problems.

Now, let's delve into the architecture of Keymantis. The architecture consists of two main components: Keymantis Express and Keymantis Compose. Keymantis Express is an npm package that provides a pre-configured Express GraphQL server. It generates the required metrics and traces using OpenTelemetry SDKs. On the other hand, Keymantis Compose allows users to deploy the entire Keymantis architecture on their own server using Docker. It handles the processing, exporting, storing, and visualization of incoming metrics and traces.

The Keymantis architecture can be divided into four major phases. In phase one, metrics and traces are generated using the Keymantis Express GraphQL server and OpenTelemetry SDKs. This ensures that the data generated is specific to GraphQL and includes all the necessary details for accurate observability.

Phase two involves exporting the generated metrics and traces for processing and storage. This allows Novels and Barnes to efficiently manage and retain their observability data.

In phase three, the data is stored using scalable databases like Prometheus and TimescaleDB. This ensures reliable and efficient storage of metrics and traces.

Finally, in phase four, the stored data is visualized and analyzed using tools like Grafana and Jaeger. Novels and Barnes can gain comprehensive insights into the performance and health of their GraphQL API through customizable dashboards and detailed analysis.

By utilizing the Keymantis architecture, Novels and Barnes can effortlessly set up a powerful observability solution for their GraphQL API. They can gain real-time metrics and traces specific to GraphQL, allowing them to quickly identify and resolve any issues that may arise. With Keymantis, Novels and Barnes can focus their resources on their core business needs while ensuring the optimal performance and functionality of their GraphQL API. The video demonstrates how Hantis can be used as an observability tool to track down issues from the dashboard to a resolver. Now, let's discuss the architecture of Hantis.

Hantis has two main components: Hantis Express and Hantis Compose. 

Hantis Express is an npm package that includes a configured Express GraphQL server responsible for generating the metrics and traces. 

On the other hand, Hantis Compose allows users to deploy the Hantis architecture on their own server using Docker. It handles processing, exporting, storing, and visualizing incoming metrics and traces.

Let's break down the architecture into four key phases:

Phase 1: Generating traces and metrics with the Hantis Express GraphQL server and OpenTelemetry SDKs. This phase ensures that the data generated by the server is specific to GraphQL. For example, Hantis Express updates the error rate counter if the response object contains an errors property. Additionally, custom error tags are added to easily filter and visualize traces with errors. The middleware used in this phase also modifies the trace names to help distinguish between different traces.

Phase 2: Exporting data for processing and storage. Traces are exported to the OpenTelemetry Collector, which handles batching and processing. Metrics are exported to Prometheus, an open-source monitoring service that stores metrics as time series data.

Phase 3: Storing data with Promscale and Timescale DB. Timescale DB, an open-source time series database powered by SQL, is used to store the telemetry data. It supports high insertion rates and low modifications and deletions, making it suitable for Hantis. Promscale, a backend extension, connects the telemetry data to Timescale DB.

Phase 4: Visualizing and analyzing data with Grafana and Jaeger. Grafana, an open-source tool for observability dashboards, connects to Promscale and Timescale DB to obtain metrics data. Jaeger, another open-source tool, is used for end-to-end distributed tracing.

Now, let's move on to the implementation challenges and how we overcame them.

One challenge was getting meaningful data from a GraphQL server. We considered building a custom server from scratch, but this would have required developers to change their code to work with Hantis. Another option was to use Apollo Server, but it was difficult to extract trace information. Ultimately, we chose Express GraphQL, which allowed us to collect the necessary data from requests and response objects.

Another challenge was connecting metrics to traces. While we initially wanted to connect them to make it easier to analyze the data, we found that the only way to do this in Grafana was to use its solution for traces, which would have added complexity to the architecture. To overcome this, we created separate trace panels for latency and errors, allowing users to filter and analyze the data effectively.

To set up and install Hantis, start by installing the Hantis Express npm package. If you don't have Express GraphQL installed, install it as well. Next, clone the Hantis Compose repository to your local machine. Import the Hantis variable into your main file before the Express GraphQL variable. Set up the route handlers for your GraphQL endpoint, making sure to pass the Hantis register latency function to the response time function. Finally, the main Hantis function needs to take the response object as an argument.

In conclusion, Hantis is an observability tool with a well-defined architecture that consists of Hantis Express and Hantis Compose. It is designed to generate metrics and traces specific to GraphQL, export and store the data, and provide visualization and analysis using Grafana and Jaeger. We faced implementation challenges but found solutions to generate meaningful data and connect metrics and traces efficiently. To install and set up Hantis, follow the provided instructions. Our team encountered some challenges during the project, but ultimately, we found better solutions using an existing npm package to obtain latency data and passing trace data to a custom function to accurately count errors. Initially, we wanted to connect metrics and traces in order to make it easier for developers to identify potential problems and get detailed trace information. This would involve clicking on an outlier metric data point, such as an increase in error rate, and accessing a list of traces that occurred within that time frame.

After conducting extensive research, we discovered that the only way to incorporate this feature in Grafana was to use Grafana's solution for traces, Griffon and Tempo. However, this would have required us to use a different database to store traces, as Grafana Tempo isn't compatible with Timescale and would have added complexity to the existing infrastructure. Another option was to build a custom UI, but that was not ideal. To overcome this obstacle, we created two trace panels: one that shows traces by latency, making it easy to spot outliers, and another that only shows error traces. Both metrics and traces have timestamps, allowing users to filter the traces panel to find information they need.

It is worth noting that the leading paid observability solutions for GraphQL currently do not support linking metrics and traces together. Now, let's move on to a quick demonstration of how to install Qmanus and set it up to work with an application. First, you need to install the Hanist Express npm package and, if necessary, the Express GraphQL package for your project. Next, clone the Hanist Compose repository to your machine. It can be cloned anywhere and will run properly. Once the npm package is installed, import the Qmanus variable into your main file, which is responsible for importing the schema and starting up the Express GraphQL server for your API. It is important to note that all the Hanist variables must be imported before the Express GraphQL variable to avoid any potential issues with collecting traces.

After importing the necessary variables, you need to set up the route handlers for your GraphQL endpoint. This is similar to setting up route handlers for any API, but with a difference: you need to pass the Qmanus register latency function to the response time function as an argument, and the main Hanist function needs to take the GraphQL schema as an argument and be passed through the Express GraphQL server. This completes the setup of the Hanist Express package to generate traces and metrics when your server is deployed.

The last step is to initialize the Hanist Docker container to collect, export, store, and visualize the data. To do this, navigate to the Qmanus Compose repository in your terminal and run Docker Compose up. This command will start the Docker images, and if you have Docker Desktop, you can view the Hanist Compose container with all the running images.

Now that everything is set up and running, you need some data to visualize. If you have a production-level server using Hanist, you can deploy it and wait for requests to come in. If you're in a development environment, you can use GraphiQL, which is already set up on localhost:4000, to send requests. Once requests start coming in, navigate to localhost:3000 to view the pre-built Hanist dashboard in Grafana. This is where you can visualize all the metrics and trace data for your GraphQL endpoint, making it simple to monitor the overall health of your app and identify any inefficiencies.

Looking forward, our team has several plans for future improvements. First, we aim to add functionality that makes Qmanus compatible with multiple GraphQL server types, such as Apollo. Additionally, we want to expand metrics, specifically by adding the ability to see the frequency of specific operations and their average response time. We have also discussed connecting metrics and traces, which is something that could be implemented in the future. Lastly, incorporating alerts is on our radar—this feature would enable observability platforms to send alerts via text, Slack, or email when a serious issue arises, making Hanist even more valuable.

Thank you for attending our presentation. If you have any questions, we would be happy to answer them at this time. During our project, there weren't many things we would have done differently. Now that we know which approaches worked and which didn't, we would prioritize the ones that proved successful. However, it's impossible to completely avoid trying different methods until we find the one that best fits our needs and requirements. Looking back, one aspect that we might have approached differently is building our own user interface instead of using Grafana. A customized UI, simplified version of Grafana, would have been preferable, as Grafana can be overwhelming due to its multitude of features.

When it came to dividing the work, the project naturally lent itself to division based on metric and trace collection and exports. Two team members focused predominantly on traces while the other two focused on metrics at the beginning. In the end, however, we all came together to ensure that the key aspects of the project were covered. We made it a point that everyone had a hand in all the phases that were discussed.

In terms of organization, we had daily meetings to discuss and adjust if needed. Our team was flexible and open to reorganizing tasks or trying out new approaches. This adaptability proved to be beneficial to the project as it allowed us to respond quickly to any unforeseen challenges.

In response to Julio's question about creating an npm library for extending Express GraphQL with instrumentation to emit metrics and traces, extending Express GraphQL involves adding custom extensions. These extensions allow for the customization of metrics and traces. We utilized middleware to calculate important metrics such as latency and track different error types. As for the information added to traces, we included a custom operation name and operation type to differentiate them. Without these additions, the traces would only show the generic GraphQL endpoint, making it difficult to distinguish between different queries. We also introduced a specific GraphQL error type in the traces, allowing for easier visualization in Grafana. This was necessary because our filter only displayed traces with errors, but we couldn't filter them by status code, requiring the addition of custom information to these traces.

As for the implementation of instrumentation, the instrumentation code resides in our npm package. We execute certain functions within the Express GraphQL server to extract the required data. Although we have no control over the implementation details of the server, these functions allow us to obtain the necessary metrics and trace information.

With no further questions, we would like to express our gratitude to everyone who attended the presentation. Thank you for taking the time to join us and showing interest in our work. We appreciate your support and feedback throughout our project.