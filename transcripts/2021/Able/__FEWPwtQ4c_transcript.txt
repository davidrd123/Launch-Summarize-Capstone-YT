welcome everybody thanks for joining us my name is jordan whistler i'm here with janae janssen eugene matras and michael rego today we're going to be exploring why and how our team built able this presentation will last approximately 50 minutes with time for questions and ask answers afterwards please post any questions as they come to mind in the chat box and we'll post them at the end of the presentation you can also ask them in the question and answer dialog box at the bottom of the zoom preferably the question and answer is the way to go there able is a framework that enables a user to quickly and easily deploy a b tests also called split tests for jam stack applications it allows the user to set up and deploy an a b test to cloudflare in addition to standing up a dashboard powered by umami open source analytics software using aws infrastructure we'll begin the presentation by talking about what a b tests are why they're important and how they're traditionally conducted then we'll talk about jam stack architecture what it is and what advantages it offers over a traditional client server model next we'll talk about the specific problems presented by the a b testing of jam stack applications some of the options available to overcome those problems then we'll present able explain its features and the challenges we encountered in developing it finally we'll talk about some of the features we didn't add to able but could be added in the future imagine your business has a website and it's generating traffic you're keeping track of the way visitors engage with your site because you want to maximize the return on your investment in this essential technology at some point you may begin to wonder if you could increase visitor engagement by making certain changes to your website what if i used a different color scheme you may wonder suppose this button said check us out instead of find out more it might be nice if you could do some kind of experiment to answer these questions with actual data instead of your own gut feelings or personal preferences excuse me experiments like these are known as a b tests in practice when an a b test is conducted the current version of the site is designated as the control version with one or more test versions deployed alongside it when people visit the site they are randomly assigned to groups each group will be served a different version of the site and each visitor should see the same version every time they visit the site critically the activity on each site must be tracked this requires a tool to record and organize the data in a way that makes it easy to interpret and analyze to determine if one version outperformed the other when the test is finished the data may reveal that one version of the site performs better than the rest if so that version can be deployed as the official version of the site the benefits of a b testing are well established and widely cited there are various reasons a company or application designer may decide to run an a b test bounce rate is a metric that measures the percentage of visitors who visit a page and then leave rather than continue to other parts of the site reducing this metric implies more interaction with the site a b tests may also be employed to improve return on investment from existing traffic through increased cart retention sales conversion and user experience a b tests may also help developers identify where user experiences are falling short for example if users aren't clicking a button as much as expected maybe it's because it's too small difficult to find or because its function isn't obvious finally with a b testing you can roll out new low risk features for just a small portion of your users to see how well they work before introducing them to your entire target audience let's look at a real world example ben is a dutch telecom company that was looking to improve conversion rates through its e-commerce platform one of the changes that chose to test was moving the color palette selection to a more prominent location the picture on the left is the control the picture on the right is the test variant which ran for two weeks through this test the company was able to achieve 17.7 increase in conversion rate as well as a reduction in customer service calls requesting a color change now that we understand how useful a b testing is let's take a look at how a b testing actually works in a traditional client server architecture a user makes a request for a web page by typing a url in their browser they are then randomly assigned to either the control group or to the test group and they are served the appropriate version of the page one useful way to categorize the currently available a b testing tools is by where the logic resides that divides the traffic among the website's variants for most available solutions this logic is executed on either the client side or the server side both of these solutions have their pros and cons there is also a third category solutions that makes use of a technology called edge computing where the logic resides in the various nodes of a global content delivery network or cdn i will talk more about what this means in a moment but for now just understand that edge computing opens up an avenue for a b testing that parallels client-side and server-side and has its own group of pros and cons it's important to consider the advantages and disadvantages of each type of solution client-side tools are the easiest to understand and implement on the other hand server-side tools allow you to test the back-end functionality as well as the front-end design also they don't require the browser to participate in the logical routines required to run the tests and as we will see a little bit later this can have an impact on the page's performance yet for these advantages server-side tools do require that you run an application server as part of your infrastructure soon we'll talk a lot about why that might be a problem and go into more detail about that third category the edge side solutions because experimentation is an important part of optimizing your website there is a huge range of optimization software available providing a variety of services from simple to complex in general they facilitate creating variants deploying them splitting the traffic and some of them also include built-in tracking and analytics tools to help you determine which variant provides the most optimal user experience [Music] so far i've mentioned three ways to implement the logic for a b testing client side server side and edge side next i will briefly discuss traditional client server architecture including some of its drawbacks and introduce the jam stack why it was created and how it approaches these limitations before turning it over to michael to discuss how we can implement a b testing logic within a jam stack architecture traditionally a single location houses a web server an application server and a database dynamic web content is usually handled by the application server which generates a just-in-time response to each http request in the context of a web application dynamic content is content that must be freshly generated every time a con client makes a request for the resource such as a page requiring a user to log in or a sports site that frequently changes or site that requires database access like a bank account the server is responsible for querying the database and using the results to create an html response which it then delivers to the client as for the website's static content such as images or html css files that don't change very often it may be stored on a cdn we talked a little about cdns before but it's worth going into the topic a little deeper right now to really understand the role these networks play in both the traditional and jam stack architectures cdn or content delivery network is a global network of caches whose purpose is to host the static content of your website because this content does not have to be freshly generated every time someone requests it it can be stored in the nodes of a cdn and delivered from locations closer to the clients who are requesting them this means that when you navigate to a web page the dynamic content of that page may be delivered from a server very far away from you well the page is static content may be delivered from somewhere very near to you so it takes less time to look to deliver that static content however in the case of dynamic content it still has to be generated by the application server which means some of those long round trips are still necessary now as traffic increases an application server may be slower to respond there is also additional time involved in generating the html response required on each request for some use cases such as blogs or sites that are infrequently updated the jam stack is one solution to rendering time and signal latency problems associated with client server architecture by using cdns to house the entire application as opposed to pieces of it low latency and high performance is achieved in gm stack applications while the use of api calls in place of application servers and databases eliminates the need for server-side rendering as this piece of architecture is completely eliminated this means the developer can concentrate on producing efficient applications in a smooth development workflow as the complexities of the underlying architecture have been abstracted away so to summarize the use of cdns allows for performant websites and the decoupling of the application through the use of api calls allows the developer to push the entire application to the edge and not only pieces of it the j is for javascript the programming language responsible for all the dynamic behavior of the application the a is for apis or application programming interfaces apis are services that can be called programmatically with javascript that allow your application to integrate with third-party products and services and finally the m stands for markup which means the raw html javascript code and css that your browser needs to display the content of a website there are many benefits to using jam stack architecture jam stack applications are incredibly fast because they serve content from close physical proximity to the user they reduce the http signal latency resulting in noticeably faster load times they are quick and convenient to develop with git based workflows and automated build into pulley processes and finally with jam stack developers don't have to manage servers sometimes jam stack is referred to as serverless architecture because it makes heavy use of apis to abstract away the need to provision and manage servers this is a little misleading because servers are still involved within the apis however these are usually managed by third parties in a thriving api marketplace which means developers can focus on building the application itself rather than using time and resources to manage infrastructure however this leads us to a problem when we wish to conduct an a b test while working with jam stack applications if our application has no application server into serving pre-rendered content how can we direct a portion of our traffic to an alternate version while maintaining the benefits of using a cdn i will now hand it over to michael to continue the discussion as jordan said i'll be talking about some options for conducting a b tests specifically in the context of jam stack applications some of the unique challenges that presents and how we approach those challenges we mentioned before that in an a b test the logic that splits users into groups and decides which website variant to serve maybe on the client side or on the server side however as jordan also said in a jam stack application there is no dedicated application server so solutions that rely on server side logic are out of the running this suggests that we should explore options that rely on client-side logic of which there are many as we've alluded to when the logic is on the client side it's quick and easy to set up a b tests however this ease of use has a major downside when a client makes a request all the variants will be served in the response this increases the volume of the data being sent which can add to the page's load time then when all the variants have loaded into the browser a javascript routine must be called which hides every variant except the one the user is supposed to see this can cause the incorrect variant to flash onto the screen before being replaced by the correct one as shown in the middle picture that's called the flicker effect and it can make for an unpleasant experience for the user this effect can be corrected with a script that blocks all the variants from being shown in the browser until it knows which one to render as shown in the picture on the right but this means the user may be looking at a blank screen for a couple of seconds before the chosen variant finally shows up in all of these cases the increased amount of data to transfer and the expensive logic of switching between variants could cancel out some of the load time reduction we're hoping to see from using the jam stack architecture and a couple of extra seconds of waiting for a page to load might not sound like a big deal but it is according to google the chance of a bounce increased by 32 when a page load time went from one to three seconds and by ninety percent when the page load time went from one to five seconds so faced with all the disadvantages of client-side a b testing for jam stack applications we must keep looking to see if there's a better way to do it when jordan was talking about jam stack architecture before he mentioned that all of a website's assets are hosted on a cdn and this is what makes jam stacks so fast when all of the assets are hosted on servers all over the world all the content can be delivered from locations closer to the users which results in faster performance and as it turns out most cdns also offer another feature which opens up a whole new category of solutions to the problem using a capability known as edge computing we can actually write a program that executes every time our user's http request hits the cdn's local server and determines the response they will receive this is that third category of solutions we were talking about in the other section on how to separate our clients and serve them different versions of the website we can use edge computing to serve different versions of our content on a per request basis which is exactly what we need to do for a b testing so with that in mind let's look at some ways to take advantage of edge computing to build an a b testing solution there are a few companies offering edge side solutions to a b testing right now although not nearly as many as those offering client-side or server-side solutions but we've identified two broad categories of edge side solutions based on how the variants are created and served they are the html rewrite solutions and the branch-based solution the first option the html rewrite solutions involve intercepting the payload of the client's response and altering the body directly before forwarding it on to the client in theory this could be used for a b testing by keeping one version of the website in the cdn and selectively rewriting variations into it as it's being served to individual users we did some research on vendors offering solutions like this such as outsmartly to use them for a b testing you don't have to maintain multiple versions of your website but developing this way presents other difficulties you have to build your website from react components which you then register with the service to render differently for different variants of the site we felt this might be practical for testing small changes but not for testing out entirely different versions of the same website it's also not simple for developers to add this technology to their website especially if they weren't already developing it with this process in mind it's a complex and involved process and in the end we put this type of solution aside to see if there is a better way for our use case so if we're not rewriting html that means we'll have to find a way to keep multiple versions of our static markup files in the cdn's cache and choose which version to serve on a per request basis many cdn providers offers branch-based deployment for jam stack applications and it can be used for a b testing it works something like this you keep the code for your app in a git repository hosted on a platform like github or bitbucket when you're ready to deploy the cdn's jam stack hosting platform retrieves your code from the repository and runs a build process which generates the static assets of your app if your repository has multiple branches it will generate a bundle of static assets for each branch once the assets are built the cdn replicates them in all the nodes of its global network and exposes a url for each bundle of assets finally now that the assets are built every time someone navigates to your domain you can use the cdn's edge compute platform to choose a variant and serve it back to the client this is called branch-based a b testing and it looks like a promising avenue for exploration into jam stack testing solutions in addition jam stack developers are generally already accustomed to deploying with a git flow so branch-based a b testing can be seen as an extension of how they are already working let's look at a few of the options for branch-based ad a b testing that are currently available in the marketplace netlify is a cdn that offers an out of the box split testing feature at the edge if you host your jam stack application on netlify you can take advantage of this feature to split traffic among apps built on multiple branches of your git repository this feature is quick and easy to set up however it doesn't offer control over how your traffic is segmented only how much of your traffic is segmented in other words you can direct 10 20 or 30 of your traffic to the test version of your site but you can't decide to test for example only mobile device users or only users who are using a particular browser which is something you may want to do also netplify doesn't offer a built-in analytics solution layer 0 is another cdn boasting branch-based a b testing at the edge and they also have a split test feature it's similar to netlify's but it allows you to split traffic based on cookie header browser or device however like netlify it also doesn't offer the built-in analytics solution so to recap the out of the box a b testing solutions offered by cdns are easy to use but they may or may not offer the kind of control you want over your tests and they don't offer adequate analytics solutions as an alternative to these options it might be worth it to consider a do-it-yourself solution you'd need to host your jam stack application on a cdn that offers both branch-based deployment and a robust edge compute platform with complete control over the http request response cycle at the network edge such as cloudflare or aws this would give you as much control as you could ever want over the a b testing process however you'd still have to come up with your own analytic solution let's talk about what's involved in setting up a diy solution for a b testing your jam stack application first of all you have to create your variants manually on different git branches then you'll deploy them to your cloud provider of choice and this will give you a distinct url for each version of your application when a client sends an http request to the url that identifies your web page you'll have to provision a serverless function to intercept that request and inspect whether or not the user should be included in the test if they should the serverless function will need to assign users randomly to groups this means that the first time a person visits a web page undergoing a test a routine should be called that picks from among the available variants and the client should be served that variant you might think that would be as simple as having the serverless compute function send a redirect response instructing the browser to request the chosen variant from a different url however this would result in that different url being displayed in the browser's address bar this is not good because it's not the address that they navigated to and we want the test to be invisible to the user this means that they should not see a different url in the address bar than they expect to see and that means that the serverless function can't simply send a redirect response it must be written to fetch and deliver the correct response using only the information contained in the http request and it must accomplish this in one request response cycle the test should also generally be sticky this means that once the user has navigated to the site they should be served the same variant of the site on all subsequent visits and to do this you have to set a cookie to track which group the very which group the users belong to in addition to all that you'll have to monitor user behavior and track metrics for each of your variants side by side there are many analytics tools available but choosing the best one to use and setting up the tracking process could also be rather challenging in order to monitor user behavior most analytics tools provide a tracking script that needs to be inserted into every page that needs to be tracked this may require editing every page of html that you're planning to serve perhaps the most important thing to track is which metrics belong to which variant this may mean setting up two or more separate tracking scripts that need to send their data to the same place also if you'd like to respect user privacy by maintaining full ownership and control over the data you're collecting you may opt to host your own analytics using an open source tool this would require you to provision and manage additional infrastructure finally once you've identified the variant that meets your performance goals you'll have to roll back the test deploy your winner and invalidate all the caches containing your test variants while this process is doable it requires a lot of steps and a solid understanding of how to use serverless compute options and because it's so highly involved it also makes it difficult to update tests once they're in process and if you want to iteratively test to find the most optimal version of your application you'll have to walk through the process over and over again now we're about to introduce able which we believe occupies a middle ground between the very difficult but powerful diy solution and the very easy but more limited out of the box solutions provided by cdn companies like netlify and layer zero able automates the process of setting up branch-based a b tests on cloudflare it does a lot of the things you'd have to figure out for yourself if you were trying to do a diy solution it offers fine grain control over the a b testing process and it automates provisioning infrastructure for your own instance of umami which is a powerful open source analytics tool what it doesn't have right now is a slick configuration dashboard so it takes a little bit more effort to set up you have to manually edit a json file to supply able with the configuration data but developers may be willing to make that trade-off in exchange for the other benefits that it offers so now i'm going to turn it over to janae who will talk about able in some more detail now that we've seen where able fits into the picture of existing solutions we'll take a closer look at what able does and how our team built it first we'll start off by demonstrating able by walking through a possible use case then we'll take a look at abel's architecture and examine how it works under the hood coffeebean.com is a fictional online retail store that specializes in selling well coffee beans of course they have a small dev team and a jam stack app already deployed in production on cloudflare pages and they decide to run some av tests to optimize their site they start off by brainstorming ways to optimize their site and create a couple of git branches to mock up potential new front ends for their web page since they're using cloudflare pages their new branches will automatically be built and deployed as a preview complete with a url now they want to put these alternate pages into action and see how users respond this is where able comes in the team manager installs able and uses able's cli to set up all the necessary information about their cloudflare account all of the details for configuring the a b test live an adjacent file that able auto generates each variant needs name and a url there should be at least two variants but it's possible to add more by adding them to the variance array each variant can also take a script for tracking metrics remember earlier michael mentioned that tracking scripts have to be written into each page's html in order to track user behavior when a variant is requested able will inject the script into the head of the page's html at the edge before serving it if the coffee bean dev team doesn't already have a analytics tool of choice they can choose to use umami analytics umami is an open source privacy-centric self-hosted analytics tool able abstracts away the difficulties of self-hosting analytics by provisioning all the underlying architecture needed to run umami on aws after setting up umami and adding the script tags to the able config file there are a few other configuration options the coffee bean team might be interested in for instance they can choose to roll out their test variants to smaller percentage of users to start off with until they're confident that the users like their new app or they can selectively segment traffic based on device browser headers or cookies this may be useful for instance if they only want to a b test their desktop site while all mobile users continue to receive their legacy site with all of the configuration details in place running able deploy will launch the split test the test will be up and running within seconds and traffic will be split to your site immediately as users interact with coffeebean.com information about users behavior will be channeled to umami where the team can view it in real time as the test progresses the coffee bean team might make want to make some adjustments maybe one of their variants is performing especially well so they want to increment the percentage of traffic directed to that version of the site or maybe the metrics have indicated one variant is the winner and they want to fine-tune it by testing a different feature change they can simply edit the config file at any time and run able update to modify the test in progress then when the test is done able destroy test will roll back the test and able destroy umami will tear down all of the aws infrastructure the coffee beam team can now release their fully optimized site at this point let's zoom out a bit and look at how our team built able able's architecture can be broken into two main parts the cloudflare component responsible for controlling the a b tests and the umami and aws infrastructure used for tracking the metrics we'll walk through both halves of able in depth in just a few moments but first we'll explain how everything fits together on a high level the cloudflare component runs the a b test this is where the variants are hosted and all of the logic from the a b test runs in a serverless function in cloudflare's cdn called a cloudflare worker the configuration data for the a b test is stored in a cloudflare kv we'll explore how these two pieces work together shortly the other half of abel's architecture is responsible for processing and storing all of the analytics data during the test we wanted to provide an option to easily self-host analytics so we decided to use an open source analytics tool called umami however to actually run umami we needed two things a server for the analytics engine to run on and a database to store the data we opted to spin up this infrastructure on aws with umami analytics up and running when a user visits the site information about their actions will be sent to aws where it will be processed by the umami application running in an ecs container and stored in an rds database all of this data will be displayed in the able umami dashboard at this point we're going to zoom in on abel's architecture a bit first the cloudflare portion and then the aws umami portion the cloudflare architecture consists of two main parts a cloudflare worker and a cloudflare worker kv the cloudflare worker is a serverless function you can think of a serverless function as a function that can be executed at the edge of a network this function runs every time a user visits the page and controls which version of the app a user is served when we deployed our first cloudflare worker to perform an a b test between two branches all information regarding the a b test was hard coded in the cloudflare worker this meant whenever we wanted to make a change to our test we would have to redeploy our cloudflare worker every time we decided to place the configuration of the a b test in a worker kv a kv is a type of data store that only stores key value pairs the cloudflare worker kb is really interesting because it's distributed across cloudflare's global edge by storing the configuration data in the worker kv we can make changes to our a b test without having to redeploy workers and since the worker qv is globally distributed and available throughout cloudflare cdn the additional latency to fetch the configuration data is minimal so let's take a look at this in action when a user types your domain name into their browser a request will be sent to a dns server which will in turn be routed to the cloudflare cdn closest to the user at the cdn the request will be intercepted by the cloudflare worker the worker will first get the configuration data for the test from the worker kv where it's stored this includes information about split ratio traffic segmentation etc the worker will then check to see if the request includes an able cookie the cookie determines if a user is part of the control group or the test group if the user hasn't visited the site before they won't have a cookie the worker will check to see if they should be included in the test and if they should we'll roll the dice and set the cookie based on the outcome it will then retrieve the appropriate variant and serve it to the user if the user refreshes the page or returns another day they'll see the same version of your site and won't realize they're part of an experiment that leads us to the second half of abel's architecture the umami architecture running on aws umami also consists of two parts a database to store all of the data umami collects in an application to process this data and display it in the dashboard the application component of umami runs in a docker container managed by amazon elastic container service or ecs using a docker image means we don't have to manually install and run umami on an ec2 or elastic compute cloud instance and can instead use ecs ecs is a container orchestration service that makes it easy to run stop and manage docker containers we configured it to scale up if our umami application gets a spike in traffic and needs more compute power to store umami's data able uses amazon's relational database service or rds rds is a managed sql database service that abstracts away the complexities associated with running and maintaining a database amazon has other options for persistent storage but we chose rds because we wanted our users to focus on the data collected by our application instead of worrying about the configuration management and maintenance of a database the final part of abel's aws architecture is an application load balancer the application load balancer sits in between the client and the container service umami is running in remember if umami starts receiving a lot of data and needs more compute power to keep up ecs will automatically spin up more containers to keep up the application load balancer will make sure the traffic is evenly distributed to the containers we automated the creation of this infrastructure using aws's cloud development kit or cdk now that we know the components that comprise umami's infrastructure let's briefly walk through the flow of how the analytics portion of able works when a user requests the page the corresponding tracking script is injected into the html by the cloudflare worker as they interact with the page data about their interactions is sent to the umami infrastructure running on aws a load balancer intercepts the data and directs it to a container where umami is running umami will process this data and display it on a dashboard the data will be stored in an rds database let's do a quick recap of abel's architecture that we just covered a client makes a request to visit your site the request is then handled at the edge by a cloudflare worker the cloudflare worker fetches the configuration of the a b test from the cloudflare worker kv and determines whether the request will participate in the av test if so the worker will decide what variant an analytic script tag to send back as well as a cookie to ensure the client will always see the same version of your site then the client will send data to umami analytics where you will be able to see how well each variant performed in real time on your umami dashboard now that we know what able is and how it works i'll turn the presentation over to you john who will take us through a few of the challenges we overcame during the process of building able we will now talk about a couple challenges we encountered when we created able one challenge was adding separate analytic script tags to each variant of your site when they have already been deployed to the cdn most client-side analytic tools including umami track user behavior with a javascript script tag this script tag is essentially a callback function that is executed when a user visits the page which sends information about the user session back to the analytics software this is a common way for how analytic tools work so how would a developer differentiate the data from one variant of their site to another during an a b test well the answer is pretty simple you have to make sure each variant of their site has their own separate script tag written into the html this way you can keep track of which variant is performing the best a developer could manually insert the analytic script tags in the html for each variant of their site themselves this becomes a tedious task where some a b testing tools such as the a b testing tool provided by netlify offer a solution to insert the analytics script tags for you with able we wanted to provide a similar service of adding the analytic script tags for you remember with jam stack applications the html is pre-built and cached at the cdn most a b testing tools for jam stack applications insert the analytic script tags while the static files are being built before they are cached at the cdn the problem in our case is that we have access to the html that is already built and cached at the cdn now the question is how can we insert separate analytic script tags to each variant of a site after the html is built and cached at the at the cdn the solution is to insert the analytics script tag at the edge with cloudflare's html rewriter cloudflare's html rewriter is a javascript api that is accessible by cloudflare workers allowing us to parse and modify the html so when our worker fetch the cached html from the cdn we use cloudflare's html rewriter to insert the correct analytics script tag at the cdn edge before it is sent to the client another challenge was automating the process of enabling https for our umami application initially umami was using the http protocol this meant the traffic served over the internet to umami was not secure not only was this a security issue but umami analytic script tags would be blocked by most browsers to use https we need a transport layer security certificate also known as a tls certificate which can be provided by aws certificate manager aws certificate manager is a service that can manage and issue tls certificates that can be that can be used with aws services we can use aws certificate manager to issue a tls certificate and attach it to our load balancer however the aws certificate manager cannot issue a certificate to the domain name provided by aws this means we need to provide a custom domain this was troublesome because up until now we were using the domain name assigned to the application load balancer provided by aws to access umami we ended up issuing a certificate to the same domain name used for the a b test on cloudflare with a subdomain of umami for instance if a user wanted to set up an a b test with able using the domain coffeebean.com then a digital certificate would be issued for ableumi.coffeebean.com although issuing the certificate to a subdomain of abel umami and assigning the certificate to the load balancer it seems straightforward the challenge was automating the process let's look at the necessary steps to enable https step 1 issue a certificate with amazon certificate manager to a subdomain of able umami step 2 validate the certificate by creating a dns record in cloudflare's name servers with the information provided by amazon certificate manager step 3 wait until the certificate is validated which can take a few minutes step 4 once the certificate is validated assign the certificate to the application load balancer step 5 create another dns record in cloudflare's name servers for the subdomain able umami which will point to the application load balancer before we talk about how to automate the process of creating a certificate let's see how the rest of our aws infrastructure is built currently our aws infrastructure is built with cloud formation templates created with amazon cdk cloud formation templates is a file written in json or yaml which can automate the process of creating and provisioning your architecture the cdk allows us to use javascript to create these cloud formation templates otherwise we would have to write hundreds of lines of code the problem with using cloudformation templates to issue a certificate with aws certificate manager is that once a certificate created aws will pause the deployment process until the certificate is validated however in order to validate the certificate we need to create a dns record in cloudflare's name servers which never happened we went from step 1 issuing a certificate to step 3 waiting for the certificate to be successfully validated skipping the step needed to validate the certificate the solution is to create the certificate using amazon software development kit before we create and provision the rest of our aws infrastructure with a cloud formation template amazon software development kit is another tool to build aws infrastructure through the use of api endpoints instead of a cloud formation template let's see how able handles automating the certificate process first we will use amazon software development kit to issue a certificate for a subdomain able umami a response is immediately sent back which was not possible when we use the cloudformation template second we make a request to cloudflare's api to create a dns record with the information provided by the previous response when we issued a certificate third we wait until the certificate is successfully validated through the process of polling polling means able will repeatedly ask amazon if the certificate has been validated fourth once the certificate has successfully been validated we will attach the certificate to the application load balancer through the cloud formation template this will also create and provision the rest of our aws infrastructure fifth and final step we make another request to cloudflare's api to create another to create a dns record for the sub domain able umami which will point to the application load balancer now that we have talked about a couple challenges we faced when we created able let's go over some future work where able can improve we would like our users to be able to deploy multiple a b tests currently we only allow one a b test up and running we would also like to provide a gui for configuring tests instead of having users to fill out our json template this will not only enhance the user experience but make able less prone to human errors finally we would like to support other jam stack jam stack hosting platforms such as aws amplify this concludes our presentation about able thank you for being here with us today we will hang around for a few minutes to answer any questions you may have all right i think we have our first question um will wants to know what were the trade-off reasons for using cloudflare services instead of keeping everything on aws well that's a great question well it was sort of vice versa wasn't it because we started developing our a b testing solution on cloudflare because you know they offered the very convenient branch-based deployment with preview branches and production branches and then when it came time to implement the analytics solution uh the cloudflare wasn't really suited to that because it couldn't host the kind of databases we were needing to have so it was actually vice versa wasn't it i would also mention um aws amplify is a service that is geared towards um deployment of jam stack in it's kind of tied towards git based deployment but they're in some ways they're kind of playing catch up to for sale and network and they're not as widely used so cloudflare is kind of more of a leader in the um in the in that space and of course putting the the dashboard on aws makes more sense because cloudflare is just a cdn and this is a full application with a database so you can't do that on the cdm all right uh the next question is from wesley uh the following are all related to the choice of rds what were some of the reasons behind choosing rds over dynamodb does umami not work well with nosql does able effectively make rds serverless or do users of able still need to manage rds instances i think i'll pass this one on to you john yeah so um this is a good question because it was just recently asked to me earlier umami only works with a sql database um you can either use mysql or postgres so uh that pretty much cancels out the dynamodb and for choosing rds we we chose rds because the we look at some other options and one was attaching a elastic elastic block store to an ec2 instance and that requires you to actually manage and provision the database but we chose rds because that aws will handle that for you um in terms of like scaling right now able doesn't able doesn't scale up you can only scale up you can't scale horizontally with a database with rds at least all right uh lena says amazing work able team what did the evolution of the architecture look like until you landed on abel's current setup well that's a long story you john you want to go over this with me how do you want to uh it started ah geez i mean yeah i can talk about it yeah we go you go you go ahead you're the best at this one but it kind of went all over the place it's it's kind of funny because we cut out a a large check section about the evolution of the architecture just to make time so i sort of know what to say anyway so we started with um i don't know if anyone remembers but we started with a single cloudflare worker and which will just intercept the request and uh and fetch the correct site however after that we realized that all the information was hard-coded and as janae mentioned earlier we added a we added a um cloudflare worker kv in order to fetch and manually change the configuration dynamically so that the cloudflare architecture is actually really small the hard part was the aws we started with the ec2 instance and we had both the database and the umami application running from there and then we we sort of just went through the process of just how how would we be able to scale this horizontally and the first step is usually you separate the database uh which we move to an rds and then we do scale the application server we had to change that to a docker container and then which will be managed by elastic container services and then in order for if you're if you have multiple containers running then you need an application load balancer to direct and manage the traffic so that they're distributed evenly and that's sort of like how that how that evolution of the architecture came to be all right thank you you john rodney says this is very relevant to things my company does uh he works at gatsby which is a jamstack company and i'm curious what was the most interesting part of the project for each of you individually uh michael do you want to maybe start yeah believe it or not it wasn't anything uh technical i think it was the experience of collaborating uh on a team like this and you know the the uh the challenges of learning how to do that uh i've never done anything like that before and i think that was uh it was it was really instructive and educational to me to you know just to learn how a team's dynamic naturally evolves you know how the people end up in different roles that it's just it's psychologically interesting even more than any of the technical parts of the the challenges we tackled yeah i would say that i also kind of agreed that the process of learning how to collaborate and make decisions i feel like you know initially maybe our team was a little bit timid and no one wanted to step on anyone else's toes and so learning how to uh develop opinions on things and make them happen um that was a really interesting part of the process but then also just learning more about jam stack and playing around with cloudflare was really fun um yeah overall it was just a really interesting couple of months anyone else want to answer yeah i'll go um first of all yeah like you guys said i really enjoy working with this group of people it's been a great experience and thank you and um as for the material um i've been really fascinated learning about the evolution of applications as it's um to me been almost and this is going to be kind of abstract but it's it's almost been a metaphor for the universe in a way as they've been shattered apart and and evolved from a singular entity with a server database web server and a singular unit and been gradually broken apart and pushed further outwards to the edge so and just learning about how the original you know static assets and pictures were pushed to the edge and now compute is getting pushed to the edge then storage is going to get pushed to the edge and learning about how um that applies not only to web pages and websites but other things like iot in manufacturing and drones and cars and just all the different things that that are interconnected in the world this project has really kind of um brought that kind of shine that light on into my eyes a little bit and i learned a lot about that that transition of technology that was that was what i found most interesting and um for myself i found what the most interesting part was uh learning about edge computing specifically with cloudflare i thought i was like they provide a really good um they provide good blogs just on learning how these worker or these workers work you can say and yeah just playing around with those and after after that i mean now i start getting ads from cloudflare about all the new things they're doing so i'm like it's just me yeah it's just making me more interested in the space of technology all right well i think that's all the questions we have and that's about all the time we have so thanks again for everyone attending and also thanks to our mentor daniel and uh all the additional help we had from chris and the tas this has been a lot of fun 