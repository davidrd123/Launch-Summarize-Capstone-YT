hello everyone thanks for coming to our presentation and i'm juan one of the creators of horse so this presentation is going to be divided in six sections first i will introduce the problem at home source by using a real-world scenario then my colleague rich will give context into the engineering area that is needed to solve the problem observability and telemetry after that kali will list a couple of existing solutions and explain why they are not perfect for our use case she will also show a demo of horrors being used next jose will describe the architecture of horus and demonstrate how to easily deploy it with docker and npm then i will explain some implementation challenges that appear when developing the project and finally i will also explain some future work that could be done in horse first of all what is searched so horus is an open source severality solutions for microservices users can generate store and visualize correlated telemetric data metrics and traces allowing them to see the real-time hull of your application this allows for easier finding of bugs and reverse portable if you haven't understood most of this don't worry because we'll cover each part in the following sections but before we do that let's introduce evil deserts it's an e-commerce site that has recently skyrocketed in popularity what started as a one-person site hustle has known outgrown a monolithic architecture this means it's time to move to a microservice architecture for better organization oliver has led a team of engineers who built evil teachers for years and he continues to oversee each sub-team in their now aside microserves one day who wakes up and finds that the site has been inundated by a stream of attributes overnight what happened customers are complaining about not being able to buy products and many of them sign off swearing they will never try the site again while oliver is confused the ceo wants answers different people different teams go on to buy some districts as if they were real customers the problem is that some of them can complete the purchase without errors whereas others do experience errors it's hard to recreate the problem as there are inconsistencies when looking for it if they can find who the program is they can start looking for assaults oliver's last resort is to look at the logs of its microservice hoping they will contain useful information about the eligibles unfortunately the logs look like what you see on the screen the problem is that logs provide too much information in a constructor way a oliver scrolls through them his frustration grows the laws are endless and difficult for him to parse he says something about the mirrors here and there but it's unclear what is happening or why oliver needs an observability tool to know what's going on so before we continue with oliver and evil t-shirts my colleague rich will give some context into observability telemetry traces and metrics brilliant thanks one so observability is the technical domain the horse exists in so it's important we take a moment here to explore what observability means and begin to get to grips with how observability could solve all this problem so firstly it's defined as the ability to measure the internal state of the system only by its outputs so what this means is in order for us to detect the status or health of a system we need to turn to these outputs to get a better idea of how an application or system is operating by referencing this data that the developer can easily navigate from effect to cores in a production system so what's the difference between observability and monitoring well observability is designed to allow the developer to ask theoretical questions about their infrastructure and they have the tools to be able to actively investigate and resolve an issue rather than just consume information passively observability allows you to ask questions like what is most likely contributing to latency right now where and when are my users encountering errors and what's the health of my application currently so what exactly are these generated outputs that i keep referring to well in the world of observability this data is referred to as telemetry telemetry is typically defined as the collection and transmission of data to receiving equipment for monitoring in essence it's a historical byproduct of assistance operations in the form of useful data there are three different types of telemetry data which are known as the three pillars of observability they are metrics logs and traces we'll be getting to know these three data types and greater depth later on in the presentation ultimately these data types are the building blocks of observability by building relationships between them we're able to gain insights into the history trends and interactions that are taking place in our infrastructure in the publication software telemetry jamie wiedersehl describes observing the systems that bring you telemetry can display in a way that will help you make decisions which is our latest goes on to explain in his book that any telemetry system is essentially a data pipeline and this pipeline is composed of three major stages emission shipping and presentation so what it will do is it will ingest data process it store it and make it retrievable to the end user what we're going to do is take a look at each of these stages individually so we can see what happens at each stage and how they interact with one another so the emitting stage is the first stage in a telemetry pipeline it's responsible for generating telemetry data in a production application the types of telemetry that can be generated are typically from three different sources you have production code hardware that's running that code or external software that's being used as an additional service the emitting stage is typically achieved by injecting an sdk into the production code which will instrument and aggregate the telemetry data you can also add context related details at this point as well and to the standards that you're generating to make it easier and understand to interpret when it arrives on the other side some real world examples of this include jaeger for trading prometheus for metrics and open telemetry which is fast becoming the gold standard in telemetry generation and processing the shipping stage is responsible for receiving the raw telemetry data from the emitter its priorities are to process it into an accessible data format enrich the data if needed and save the data and storage mechanism to be used by the presentation layer later an important design factor the shipping stage is to consider how to organize and store the raw telemetry data that is generated by your emitter telemetry data by nature is generated continuously and at a very high frequency so your database of choice needs to be able to handle this high rise intensity while also being able to query the data when required if the frequency of the incoming data is beyond the processing power of a database it's wise decision to consider the implementation of either a queue or an event bus to manage that data influx finally we've got the presentation stage and it's the last phase in the installation pipeline and crucially the only one which most stakeholders will interact with to make important design and business decisions the presentation stage's purpose is to transform telemetry data into useful measurable and human friendly visuals regarding how an aggregation is performing interestingly the presentation stage is often a separate architectural component to the emission and shipping stages and is regarded as the user intake uh interface of telemetry architecture it's also from what large sas uses their primary selling point it's their dashboard as their ui in essence telemetry presentation is always a key component of telemetry architecture even though it does not directly impact the generation of telemetry data if the architecture doesn't implement the stage itself the user will just do it themselves either by creating their own graphs for outsourcing to a separate ui component by your profiler ready so we've explored the full extent of this finished pipeline let's turn on our attention back to the technology data metrics traces and logs and they're differentiating quantities so mometrix it's defined as a volume that expresses some data about the system these metrics are usually counts or measures and are often aggregated or calculated over a period of time so for example this can be an aggregated measurement of how many requests took place in the last 10 seconds metrics can answer questions like is the application performing slower than it should be a user's encountering errors while using the application and at what time of day are we receiving the most amount of requests why an application is behaving in a particular way may still be unclear what metrics give us is the broader picture of an application's overall state and performance a request can pass through a host of different services making them harder to pin down and understand what really happened a trace provides a view of this request throughout its lifetime in a system where it starts where it goes to next and where it finally terminates throughout the distributed infrastructure traces also capture each step of the way and how long each step took this is commonly referred to as a span which is shorthand for a span of time traces are the newest telemetry data type and are less common than metrics and logs what they are great at and what's really their superpower is providing context for their other telemetry counterparts which generally tend to operate this higher level of abstraction in essence traces give us this low-level perspective of an application's history and has to see the greater details of what's taking place under an application's own finally we've got logs and logs are structured or unstructured lines of text that are emitted by an application in response to some events in the code logs are the most detailed data type so it's easy to assume they're immediately helpful and they can be but all the details can make them hard to pass and understand and install logs are great when diving into the details and seeing a step-by-step explanation of what a system did or attempted to do so which of our three telemetry data types should we use to solve for this problem greater than macro level they aggregate all monitoring measurements and explore them at specified time intervals and what's great about them is this exporting cost does not increase with higher application traffic this is a great place to start but there are some limitations in taking a metric only approach if an application were to start detecting errors or there was a sharp increase in overall latency you wouldn't be able to identify where across your infrastructure the complications were materializing traces of the natural counterpart they provided contextual information around the journey of a request and how it unfolded as it moved to a system this can help pinpoint the source of an issue in a distributed system quickly and accurately binaries by establishing the relationship between the macro nature of metrics and the detailed nuances of choices the user can theoretically jump between a high level and a low level perspective by switching between these two different temperature data types so now we have a greater understanding of how observability can be achieved through telemetry i'm going to pass you to cali who's going to remind us of the problems that oliver is facing and what solutions exist that could help him thanks rich so when we left oliver and his team they were facing a few different issues but mostly they came down to they were getting customer complaints that evo t-shirts wasn't working some people were more descriptive saying things like my cart isn't accurate or i can't complete the checkout transaction others were just saying things like your upside doesn't work i hate it so some people on his team were able to recreate some of the problems like oh yeah my cart isn't accurate but then other people were able to have an accurate cart so they weren't able to consistently recreate the problem in order to pinpoint what was happening so even if they have a suspicion of where the problem is they can't necessarily fix it because if they quote unquote fix it is it really fixed or were they just not able to regenerate the problem at all so because they don't know what the problem is they can't fix it and they're stuck with a lot of grumpy customers and this is where observability could really help out oliver and his team if they were to run an observability system alongside their application the observability system would be generating that telemetry data that rich was just telling us about specifically if they had metrics and traces that were correlated they'd be able to use that to find where the issue was happening so if their metrics were generating things like requests per second and errors per second they would be able to see the errors happening they wouldn't have to wait for a customer to to say hey your store isn't working they'd be able to see it within seconds of it actually happening but they wouldn't have to stop there they wouldn't have to stop with saying oh there's errors in our application i really wish i knew where they were instead they could look at the correlated traces and see the literal user path that they went down to generate that error so the focus wouldn't have to be let me recreate it immediately they'd be able to see what actually caused the error it might be a 500 there might be a 404 there might be some weird payload and a post request whatever it may be the trace would allow the developers to see that information then they could see where the problem is and go about fixing it so because observability can really help all verner's team it's a great thing for them to do the next natural question then is how should they have an observability system so oliver and his team are software engineers they can figure out observability and telemetry and they can maybe put something together themselves but that's not what they're interested in right now they're not interested in mastering observability they're interested in using it so the best thing for them to go to is an all-in-one service something they can get up and running provides everything they need and it just works so the best place for them to start would be with a sas solution two of the biggest in this domain are new relic and datadog and they have some great pros right off the bat first they have this out of the box full observability platform you don't have to patch something in it just it's all there all you really have to do is copy some instrumentation a few lines of code into some files in your code and it works you don't even have to necessarily really understand how it works because it just works a lot of the complexities abstracted away things like what database are they using or how do they query the database you don't have to know that because they take care of it for you and the way you interact with your data as a developer is with a very polished ui that has more features than you could possibly use and so all of those are really great things for them however there are some immediate drawbacks for all of ernest's team the first is the high cost new relic and datadog will cost two to eleven thousand dollars a month for a small engineering team which isn't which is totally understandable for a much larger corporation or company but it's really out of out of bounds for where evo t-shirts can afford right now they would if they would go down the free route with either one of these they'd have to give up ownership of their data meaning if they left new relic they'd have to leave their data behind also if they wanted to do some analysis that goes back further maybe like two weeks they wouldn't be able to do that either because the data is automatically deleted after eight days and although the ui is very feature rich and very very polished and nice it would require some more devoted time to really understand all the features they have very good documentation but again it would take time to really master this and figure out to find what they need and that's just time they don't really want to spend right now so because sas doesn't work out for oliver and his team they might try to go another direction which is a diy approach on the screen are just a few of the different technologies and open source projects that are used in the sphere of observability the punchline is this though in order to put something together they have to deeply understand it they have to understand what each of these technologies do and don't do for example not all of these work very well together so grafana can query time scale for metrics but it can't query it for traces grafana can query jaeger for traces but then jager needs elasticsearch or cassandra open telemetry can work with time scale with traces but then grafana can't get the traces from open telemetry through timescale you don't remember all those details the point is just it's confusing and the way that you figure this out is by spending lots of time mastering it and putting these things together and again oliver and his team could but they don't want to spend the engineering cost and the time in order to make it happen so for right now this is where all of ernest's team are they like some things with diy they like the idea of keeping their data they like that it's not super expensive but the draw of sas and how easy it is to set up is also really nice but they don't have the cash to be able to afford that so what oliver and his team what they actually need and what solves these problems for them is horus and so let's look at that now and why that can help them at a high level horus is an open source observability solution for microservices users can generate store and visualize correlated telemetry data allowing them to see the real-time health of their application and that's a lot of words so let's break it down and extract some meaning from it piece by piece first is that horus is an open source observability solution it's open source so the code is free yes you have to pay to store your uh your data from your telemetry data but you'd have to do that no matter where you go it's open source also in that the code is unlocked as it were if people on oliver's team want to look closer at how things are really working under the hood they can go about doing that maybe down the line there's another feature they want to add that horus is almost there but they just find a need later that just goes right beyond it they're welcome to develop that further and make it really fit their use case even better but horse is also a complete project so they don't have to understand it they don't have to go about going into the code and doing all that and this allows them to understand it as little or as much as they'd like the next thing horus does is it generates and stores telemetry data specifically it uses open telemetry to generate and it uses time scale to store in the next section jose will talk a little bit about open telemetry and time scale and why we're using them the last part of horus and rich mentioned in the presentation stage this is the main place people interact with and open or an observability uh product and that's the same for horus this is where you can visualize correlated telemetry data and see the real-time health of your application here's a little gif of the ui but let's actually take a closer look at the ui so this is the first page of the horus ui where you can see your metrics you have total request protect for 10 seconds errors per 10 seconds as well as the latency health and on the top right you can choose different time frames relative to where you are you can also click the refresh button just to make sure you're really getting up to date the real 10 second data there when you hover over a data point it'll show you how many requests are in that time and if you click on a data point it will take you to the second page these are all the traces that happened in that 10 second interval you can filter them you can sort them and this kind of gives you a high level view with some of the details that each of these traces have but if you want to understand the full journey of an individual trace you can click on any one of these it'll take you to the final page and this has a breakdown of all the spans it defaults to http spans in the top right there but you can change that to non-http spans and of course you can look at all the spans as well and if you want even more detail you can click on any of these spans and it will show you the attributes of what happened in that span what was the action what was the status code or the method what really made up the details of that and anytime you can you can hide that and see the waterfall chart again now if you want to look at a different trace you can click back to where you just were and of course you can go back to the main page and start the journey all over in summary horus is really good for oliver and his team and it's because horus is open source it's an all-in-one service they has the the flexibility and the low cost of diy but doesn't have the high engineering cost it's already all there put together for you it's easy to deploy it has a simple ui that includes everything that they need right now but nothing to distract or overwhelm them and it has that clear connection and correlation between metrics and traces now horus isn't all things to all people and it does give up certain things like hosted storage or all the other features that things like new relic and datadog provide but that's okay for oliver and his team and it fits what they need right now just fine in the next section we're gonna i'm gonna hand you over to jose and he's gonna talk a bit more about the horus architecture and why it is how it is thanks kelly so you've already spoken to us about why there's need for something like horse and how horse behaves i'm now going to answer a different question which is how horse is built and how horse is deployed so let's first start with how horses builds let's look at this uh high level overview of horus so on the left hand side you have a general microservice application that has a root service so it's that box with those three services to the left and those services post telemetry data to the horse infrastructure that's on the right so horus runs on a single vps that has a docker network and within that network has four docker containers with each component communicating between themselves but there's a lot of information so let's break this down piece by piece and understand how this works and this first starts with going back to evil t-shirts so this is the just an example of how their microservice application or at least a part of it could work the customer hits the root service with an http request which then uses other services in order to fulfill the the operations the customer is expecting now the problem with this for oliver and his team is that in general http request cycle doesn't generate that telemetry data that we've spoken about it doesn't generate those metrics and traces we need to work with so that's where horse agent comes in so horse agent is an mpm package that we've developed using open telemetry tools we chose to work with opencelebrity because it's the rising gold standard for generating and working with telemetry data it's backed by most industry players and crucially it allows you to with a single technology as in open telemetry generates uh different types of telemetry like metrics and traces and logs so that was those were key considerations for why we chose to work with open telemetry so when you install our mpn package for horse agents what it does is it helps you instrument and install the the exporters and the instrumentation to generate that data in this case this is how the code looks like when you do it it takes about five minutes up to five minutes for service between installing the npm package and placing this code it's about like you see less than 10 lines of code and this is just for the root service when you go to the dependent services that aren't the root service it's even less code it's just two lines of code to generate those traces so this is how evil teachers application or now look like by placing that horse agent that is in purple what the application now is doing is those http request cycles are now generating that cylinder data and that can be used in horse well it's breaking down this down a little bit more by looking at the distinction between the metrics and the tracing agents that are provided here so this first part is the metrics agents this is installed with ultra instrumentation from open telemetry again using the npm package that i showed before and explained and what it does is it generates metrics every interval and specifically we've created our npm to generate three types of metrics that you saw with cal explained it the request for seconds the errors per second and the latency per request and besides the instrumentation that generates those metrics what it also has is a connect an exporter that exports those metrics and sends it as a post request to the horse connector which i'll talk about briefly now if you go to the next slide there are few differences here with the tracing agent now the commonality is that it also uses auto instrumentation and it also uses the uh the open symmetry exporter to post that data but let's start looking at differences here so straight off the bat you can notice from the diagram that the dependent surfaces also have tracing agents whereas in the other one we saw that the mattress agent was only in the root service this is because since cars has made for micro service applications with the root service you only install it in the service because since every request goes through it that's where you collect that data that's aggregates and averages out what's happening in the system the difference with traces is that since traces are made up of spans like rich explains spans happen in other services as well because they represent operations in a service so if you were only to have traces in the service you wouldn't be able to see all of the spans which is why that would be to install the tracing agent in every service and that's why every service exports the spans are generated in them to the 2d connector a second key difference is that you don't just generate those traces and spans you generate and cue them and it's because unlike a metric which generates every every interval say every 10 seconds with traces you generate them every time an http request comes in so that means that if you didn't trace this you would be hitting the database every time a request hits your your microservice which would have a taxing effect would be resource intensive on the connector on the database so we've implemented open telemetry using opencelebrity tools to queue and then send as a batch multiple traces and spans so that allows us to take in more requests per second and have our infrastructure still work perfectly well so now that we've seen horse agents let's start start looking at the horse architecture at the vps so that first part was horse agent the only part of horse that sits outside of our vps this next one is the infrastructure that lives in the vps and there are four parts to it the first part is the connector it's just an express server that receives post requests to two different endpoints one for metrics and one for traces what this connector does is parse and validates data for the schema so it parses that data coming in and validates it and on top of that when it comes to the dates it enforces utc on the timestamps and the purpose of this is to make sure that the times are always on the same time zone which will then allow us to associate metrics with traces the second component is the database that the condense that connector inserts data into now we chose to work with time scale for three key reasons the first is that it's a time series database and this was something very important to us because telemetry data is time series data it's the the key characteristic is that you can sort it and organize it and work with it based on time the second is that unlike some other time series database time skill works with sql time skill is specifically built on top of postgresql which we all work with and this is especially important because if oliver and his team at some point need to understand the code or need to extend the code to suit their needs working with a sql compliant database is going to be easier not only because it works with sql but because if they have to change the schema i need to find relations that's something that works out of the box with um time scale since it's built on top of postwar sql and finally because timescale has some optimizations built in specifically for time series data the script great performance scale that you get with timescale that you don't get with postgresql for example now the final part the final piece is the ui which at a high level you can think about it as single architectural components but here we're displaying it as two parts these are running in two different docker containers one is the ui server that is express app that makes requests to the database it queries the database and the other is the ui client which is which is an xjs app that has react components and that is what allows the end user oliver or one of his colleagues to interact and interface with the data in the database so some key decisions here was decoupling that ui client and ui server which makes it easier to work with and develop and this is particularly important if course oliver and team want to extend the products later a second key thing that we saw with kali is build that association of metrics with traces through time sounds and the way this happens is that when you click on metric points on the front end we get the delta between the current timestamp and the next timestamp and that allows us to by using those two different time stamps to query the traces in that time frame and finally the ui clients have several custom react components for database administration that works out so great uh great as kai show so let now let's go back now that we've looked at the architecture and broken down my pieces to what rich was talking about these telemetry pipeline stages so this first part is the mission stage this happens when a customer makes a request and asks the request travels between the root service and the other services so this is where the telemetry data is generated by the horse agent using cylinder tools those tracing and metrics agents the second part is the shipping stage and this also includes these services because these services not only have the instrumentation that generates the data but they also have the open championship exporters that export that data so since the shipping stage is about exporting data processing data and storing data that exporting starts at those services because independent services exports the traces directly to the connector and the root service exports the metrics and traces also directly to the connector all of them for post requests it also includes naturally the connector that processes the data and then the database that stores the data and then finally we have the presentation stage which is the ui so it is the ui server and the ui client which together allow all of our teammates or whichever developer that uses horus to interface with that data now the great thing about working with horus is that since we've built it on docker like i showed before with a docker network and several docker containers working within it you can just set it up and run it with dock and post up we have a docker and push yama file that instructs docker how to spin up these containers and have them work together so it's very simple to use so now that i've shown how horse works and how to deploy it i'll let quantity go over finish with the challenges that we face in the development process thanks jose to develop a framework like horus we had to solve a couple of engineering challenges and trade-offs the first one was connecting metrics and traces together but as i will explain later this created another time zone differences finally we also had to decide between various visualization trainings active feature of horus is a clear link between metrics and traces but generating related metrics and traces is all at the beginning you have to store and query them while maintaining their relationship how do you show the right traces several observability tools rely on an assigned id to maintain this connection when the metrics and traces are generated before they are stored in the database the trace is given a metric id and the metric is given a tree saving however this creates two sub-problems the first one is that if metrics are generated let's say every 10 seconds many traces have been created in that period to hold information about all of these traces a big array must be great the flow of horus is from metric to traces so the metrics need to hold information to point to the related traces an array of hundreds of ids didn't seem like a waste approach especially when that would need to be potentially stored across errors per second and left the second problem is about what happens if a metric is related to multiple traces or if a trace is related to multiple metrics it's a many many many-to-many relationship which is complex to store and query some platforms solve this issue by only storing one important trace per metric data point if the trace passes objects for example it has a status quo of 500 or 400 perform it is chosen as the most important race and store all the traces that the metric databall references are discarded from a storage standpoint this trade will make sense however this advantage is clear lost information what if the user wants all the traces what if there are multiple relevant traces in a single metric to solve this we settle on an organic connection time since metrics cover an interval of time we only have to query traces that fall within that interval of time in order to supply the right traces it's also the problem was that this connection with time raise another is different time zones this caused issues when we're correlating metrics addresses when testing if the database was stored traces and metrics correctly we realized that sometimes the metrics would not be well correlated with choices for example we would create a database in a particular time interval and see that there were 12 requests made but then in that same time interval there would be no traces this resulted in the user experience that you see on the screen the user clicks on a metric data point and is taken to traces page but there are no traces in this page this doesn't make sense if during 10 second time frame there are for example 12 requests this would be 12 traces during that time frame after a bit more begin we realized that traces existed but they were off by a couple hours either forwards or backwards what was going on we found out that there was an inconsistency with time zones to store traces in the database we would use the timestamp already provided by open telemetry in the emitting stage which defaults to utc however matrix arrived at the connector without a timestamp to create it we invoke the javascript date constructor however as you can see in the slide this call returns a different timestamp depending on the time zone of the machine that is making the call we have to make sure to generate a timestamp in the connector for the metrics that always have utc time zone no matter which machine was executing the code after doing this fix everything worked as expected the last uh challenge we had to solve were some visualization traders when jose was explaining the architecture you may remember that part of it was our own user interface however this was not the original idea initially our plan was to use graphana an open source dashboard monitoring solution in essence rafana provided the perfect solution to integrate the presentation stage into our application it could visualize and graph both metrics and traces and have the ability to query our database of choice timescale the problem was that when we started implementing it we realized that it was not as easy as profana made it sound for metrics graffana worked as expected retrieving data directly from timescale and displaying it appropriately in charge however the only option to visualize traces was to use other tracing solutions different from the open telemetry standard like jager or sikki when we discovered this we decided to go with jager but there were two problems with it the first one is that it uses its own instrumentation to meet tracing data this means that we'll need to instrument the microservices with both open telemetry and jager the other drawback is that jager can only store tracing data in either cassandra or elasticsearch this meant we would need to have another database in the project resulting in the architecture you see on the top diagram in the screen this architecture works slightly different to the one jose presented before you need the trace data in jager format is sent to elasticsearch to be stored the metrics generated by open telemetry are sent to the connect which stores them in time scale to display the metrics data or funnel queries time scale directly but for the trace's data it uses as a data source which queries elastic search for retrieved data this architecture also requires two virtual virtual private servers to work this is because elasticsearch takes a lot of resources and needs its own vps this had another layer of complexity since we will need docker swarm to implement and connect the two docker networks after something green we were able to make this architecture work however not all of our problems were solved first of all the architecture was very resource intensive the elasticsearch server had problems with it and it crashed several times when it was running it's true that we're not using a very powerful server but thinking about our use case we thought it was best to not need powerful hardware to make horsework also having two databases could introduce time synchronicity issues which would have been fatal for the connection of metrics and traces finally we just didn't like the idea of having such a complex architecture because it meant more potential points of failure after coming together to discuss our options we decided that the optimal solution would be to develop our own user interface this way we will not have the problems mentioned before plus we would have an extra advantage the total customization of the user experience when working with rafana you have to conform to the options it offers for the supply of information however with our own ui we could choose exactly what the users see from the colors to the data to the different pages this allowed horus to be a better fit for the potential users of our application the program again was that to develop the ui we had to resolve some drawbacks that had to be considered the first one is the design decisions we had to take when developing it because the options were infinite we had to be very deliberate to choose the functionality and scope we wanted to have we also had to wrap up on a couple of libraries and frameworks that we had no previous experience with which meant an extra engineering effort we use tailwind library to avoid writing a lot of css nevo for my metric charts chart.js for the waterfall charts and next js which is similar to react as a frontend framework after seeing the results of making the ui we are glad we decided to abandon rafana and going with it it made horus more elegant and easy to use plus it increases the possibilities for future development talking about that although it fulfills all of oliver's need an open source project is never fully finished these are some of the features that we like to pursue in a few in future iterations uh the first one is developing more pages in the ui for example a page where the user can choose a custom time frame and view all the choices that happen in a time frame instead of having to go through matrix words support more language is different from j from javascript when generating open to limited data and finally we would like to test the project further to investigate the hardware requirements for hosting horos and larger systems in the screen you can see the theme that built horus and our locations and if you have any questions we'll be happy to answer them uh you can i think you can write them in the in the in a box and i will see them brilliant thanks uh guys um so i've got one question here um from will which i think is a brilliant question um says uh it seems like it would have been difficult to build and test this without a non-trivial app so how did you test out of course um and i think that's a great question um there were several ways that we did test it and what's great about building an observability solution is that you can you can actually get that real-time feedback about how your application is is working you know you're able to make them you're able to make a request on your on your dummy application and then you can see is it is it translating to you to your own service to horus and so we must get that real-time feedback from our own application but we also one of the major things for us that was really really important to get it right was to um was to make sure that it was our responsibility as a team and as developers to make sure that that telemetry data was never lost or that it was it was always accurate to the events that were taking place in the application um so one of the major testing that we did was was load testing using artillery i o and to make sure that when this application was receiving a high number of requests and those requests again were accelerated and raised over a period of time and the um horus wasn't dropping any of that data and so it was always getting um the the real time um data accurately and interpreting it appropriately um on on our ui and so yeah we used our telegram um with with uh with our application and uh that was a success and so we're really happy with that and then with the front end elements as well we use jest and to make sure the data that we were um presenting was was accurate to the data that we expected as well um so those were our two primary forms of uh testing um i'll reach out to the guys in case there's anything that ever missed yeah i think i just add to that um the another small part that we did too well not small another thing that we did was so we did use kind of a a trivial app i guess i'd call it when we started um developing everything just like make sure that works first but we did also go to testing it with a microservice that was distributed across different digital ocean droplets so it had a had a root service on a root droplet and there was other droplets and other services they all communicated and they all gave their their data their telemetry data to horus so we didn't test it with a non-trivial app the whole way through probably i think it's because it would be complicated but we we used a non-trivial app at the end um kind of after we were more confident like okay this is working let's test it in a more difficult sphere so that's just another stage of our testing as well thanks kelly yeah follow-up question here again an excellent question so um the difficulty of learning a new tech standpoint um how big of a percentage was building out uh the front um and i think um i think i'll pass this to to to kellyanne um rather regarding the front end um from my standpoint it was it was a really it was a really um big moment for us because like we said our original prototype was to use the grafana and outsource that responsibility to them and but actually it was a really big big turning point for us and we had to spend a lot of time making that decision and weighing out the pros and cons of doing it and i think we made the right decision um but um i'll pass out to juan to talk us through some of the some of the design decisions and why we decided to do it and uh thanks rich so yeah we were a bit hesitant on doing the ui moviefair uh so i would estimate it was maybe 30 percent of the total time uh geographically yeah i'd say i'd say 30 to 50 it feels like um yeah i feel like we we kind of got the rest of it done about halfway through i think we we're about halfway through our time when we're like man we need to make our own ui and that was a big that was one of the reasons why it was so hard because we're like if we make a ui it has to be nice and to make a nice ui that's going to take forever so um but we iterated through other stuff so yeah i'd say i'd say 30 to 40 i'd agree with that brilliant excellent thank you so we got another uh question here from katarina um why did you decide to work uh work on observability and observability solution and what other ideas did you have um i'm gonna pass this to jose so why do we work on an observability solution sure thanks um so we um we were doing some general research on different areas um just things like canadian deployments suitability among others we thought that observability had a lot of potential since like rich spoke about you can describe a telemetry pipeline like a data pipeline so that was a type of problem we were quite interested in and then within the space of ability we did juggle a few ideas of the type of problems we wanted to to to address and we end up going down this full stack apm type solution um yes among several things like my client said bobby wanted to build your own ui want to work with both back ends the front ends but there are other ideas around there and initially actually we we didn't we thought more about plugging things together and having ease of use case whereas you might have noticed um this turned out to be without that for example again we develop our own ui rather than just plugging in something like grafana excellent uh somebody else want to add anything to that as well i think other ideas something that i i still wish would have worked but it just doesn't exist and maybe some other capstone team could do this is when we first started looking observability we were trying to see if there's a way to connect observability with security um so like figuring out there were security breaches through metrics or traces in some kind of way which we weren't able to find something that really supported that um but yeah i think a lot of what i remember is we had a bunch of different ideas but they're escaping me now but i remember we went down observability because we knew that observability is so like the use for it i feel like it's so clear but that it's also so difficult to use to use so like jose said our first goal was just to make it easier to work with and not even make a lot of custom stuff but that's kind of how it came about brilliant excellent so we've got a couple of questions here about nexjs and why we decided to use that yeah i think um we used it plain and simple because somebody suggested it um and we just we looked at it and we we all have experience with react and so that was that was the most comfortable place for us to go but the person who recommended neck said it's like react but a little bit easier to work with and so that always sounds nice um and we tried it out and we just we really enjoyed it um it was for me at least it felt familiar enough to react that i didn't feel disoriented or confused i think you know i ramped up on it meaning i could just start using it and actually building our ui with other teammates in like two hours so it wasn't it wasn't i guess scary to use or confusing um but all it really did was oh you know i should do this these four steps and react yeah you don't have to do any of them and next they just happen and so it was just it was really nice to take take away some of the the steps you have to do to make a ui and yeah we were already hesitant about making the ui so anything making it simpler and easier we were on board with yeah it did feel like a real natural evolution building on from our skills it was it was it was really yeah it felt really great kind of working with that technology um and uh yeah being able to use our pre-existing skills in react um and just again just making that more streamlined um user experience for us as developers um okay uh so another question here um i'm gonna pass this one over to jose um so a great question as well uh multiple different movie parts um and did we have any specific issues when managing connections between containers and other services sure um we actually did so we were initially developing uh the the different applications different parts of horus as in the connector the database the ui server and ui client locally and then we were having issues with how we migrated that code into docker so we were able to set up the docker containers and the overarching docker network with the compose um somewhat easily the challenge then became how do we make what was working locally in our local computers work in docker because in docker you have different door containers which are sort of isolated and they communicate via http um so they they're in different uh even though they're in the same ip address as in the same vps they need to they just don't know about each other unlike locally where you can use localhost to communicate in different for applications different hosts so that was something that we it took us quite a bit of time um getting that right um which specific one helps a lot with and um to address um and it was just there were just many things about getting variables rights um accessing data um but what type of variables use for example environmental variables or other types of variables as in for example in docker which again just was was a challenge but we eventually okay yeah and and the thing just to add to that i think it was really worth the the the engineering effort we put into it to use that to use docker because you know we could run it locally on our own machines we could run it in a digital ocean droplet you can run it on aws it just it gives it so much more accessibility uh to be used as a product okay great excellent another question here what challenges did you face working on this project the distributed team um and how did you overcome those challenges from carl so great question thank you carl um uh yeah uh does anyone jump into this one um i'd say you know that was a concern of mine coming into this team because yeah we're all over the place right we have the farthest difference that i think at one time was seven hours difference between us and i i gotta say um so jose right now is on my time zone he's um in peru right now but rich and juan were so nice in how they accommodated to the eastern time zone um and stayed up late and still were able to brilliantly code at like two o'clock in the morning and so that was really helpful i think something else that helped was we just we met often uh we checked in often and even though we're far i personally never felt like and what's going on or what are people working on it just i felt very connected and like we're on the same page even we're doing different things um yeah and i think i think the accommodation of us all meeting together often and doing that was really good yeah i mean for me it's been just such a joy to work in this throughout this whole experience um with these guys um even though we've got the time zone difference you you learn very quickly to adapt to like okay so what we're gonna set aside for today what are we gonna put aside tomorrow you know we solve in our own time independently um so you know this this uh this project has been really rewarding in that sense that we've been able to adapt to those different time zones adapt that remote working environment and being able to work um really effectively as a team um under those circumstances um but yeah i think it's it's it's been been really great i've really enjoyed it um some of the problems challenges though um i think uh [Applause] one i suppose one of the challenges is is um is is making sure that everybody's um okay working across those other time zones as cali mentioned like me and vine were kind of in that like later in the evening and i'm just kind of making sure that you know everybody's feeling good everybody's you know um everybody is is feeling okay at the desk and making sure that they uh you know that it's um and having that awareness as well right um i think there's a lot of things when you're not in the same space as somebody it can be hard to pick up on those things so again just having that general um awareness but uh yeah i think you know uh again to terms of challenges um no real great challenges but but certainly uh a really good experience um jose would you like to jump into that yeah i mean i think maybe something i would add i think probably helped a lot was um i think we were very concerned about making it work and we are very conscious that working remotely can be a challenge because like rich said you aren't in the same place so it's hard to pick up on on what other people are thinking and feeling and doing and so forth so i think we are very deliberate in trying to um create a good dynamic and make it work um i think overall we did quite well and probably in large part because we were trying to be very deliberate about it from the start i remember that um we spoke about it a lot especially towards the start of working together about how we wanted to work together but besides like planning it we also made decisions as we went along to accommodate to what worked best for everyone excellent i'm uh oh we've got another question we've got another question um so are there any trade-off decisions that in hindsight uh seem like not an ideal solution so anything that um we went through that might not seem like the best uh idea now uh i think also didn't mention before but uh talking about docker uh one of the very painful thing was dockerizing next js uh for a couple reasons at first it took like forever like it's uh every time you wanted to generate a new image it was like 15 minute wait and yeah it was a blocking thing so you had to be there waiting uh yeah sitting at the sitting on the computer waiting for it to finish uh so that really slow slow us down a little bit towards the end um and also again working with environment variables and next js and docker again it was not easy at all uh but uh yeah like we didn't really check that before uh committing to next year so we we tried to dockerize everything at the end so it was like part of optional so after we had developed everything we went to dockerize and then we're like we realized oh uh dockerizing nexus is not fun but uh yeah so yeah we would probably uh look for a different front-end framework that is yeah easy to price quite excellent um so i hope it's answer all your questions i know that sometimes you can get rid of time if you you have a question it sort of comes to you later on so and we're all on slack so do feel feel free to reach out to us if you go any further questions and we'll be happy to answer them and thanks again for joining us today and we hope you enjoyed our presentation and thank you very much yes thanks everyone you 