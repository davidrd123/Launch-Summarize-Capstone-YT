Welcome everyone! Thank you for joining us today. I am Lena and I will be leading the first part of this presentation. With remote collaboration from Austin, Sophie, and Vaheed, we have developed Fjord, an open-source framework called Fjord. Fjord is designed to provide a real-time API proxy for Kafka. It enables data streaming to web-facing clients, while also allowing developers to deploy a scalable infrastructure on Amazon Web Services for handling real-time streaming.

Let's break down the definition of Fjord and focus on its main components. We have real-time API proxy and Kafka. To fully appreciate what Fjord does, it is important to understand real-time data and Kafka, and subsequently, why an API proxy is needed and what solution Fjord offers.

Real-time data is something we encounter in our daily lives, as seen in the example of a food delivery app called SuperEats. This app constantly updates customers on the status of their meal orders and their delivery drivers' locations. In this context, real-time means being able to react to events as they occur and before they lose their importance.

Kafka, on the other hand, is an event streaming platform widely used across various industries. It efficiently handles large volumes of records as records stored in a log. Kafka's binary transport protocol allows for the quick transmission of these records between machines. It is a secure platform, trusted by many Fortune 100 companies like LinkedIn and Netflix.

To bridge the gap between Kafka and real-time web applications, an API proxy is needed. An API proxy acts as a server intermediary, translating traffic between Kafka's binary protocol and the HTTP protocol used by client devices. This enables real-time data streaming from Kafka to web-facing clients.

Implementing an API proxy offers numerous benefits. It allows the efficient handling of high volumes and velocities of Kafka messages, while also providing scalability to manage external user traffic. Additionally, an API proxy acts as a gateway for added security and customization by grouping Kafka topics into different configurations of API endpoints. By offloading resource-intensive tasks to the API proxy, businesses can focus on core activities.

While there are existing enterprise solutions like Ably and PubNub that offer reliable real-time API proxy solutions for Kafka, they come at a high cost and lock users into their ecosystems. Alternatively, organizations can build their own solution, combining components like a Kafka sync connector, an API proxy server, a pub/sub mechanism, and a load balancer. Open-source solutions for these components include Red Hat Stream C, Pushpin, and Centrifugal, but building a DIY solution requires significant resources and expertise.

In summary, Fjord is an open-source framework that provides a real-time API proxy for Kafka. By bridging the gap between Kafka and web-facing clients, Fjord enables efficient data streaming and scalability while ensuring the security and customization needs of businesses. Organizations can choose to use existing enterprise solutions or build their own solution using open-source components, depending on their specific requirements and resources. An API proxy is a valuable tool for exposing internal Kafka data to a large number of users over the internet. It offers several key features that make it a reliable system for handling the volume and velocity of Kafka messages. With an API proxy, thousands of end users can receive Kafka streams over HTTP. Using a separate proxy also allows for dynamic scaling of the server in response to external user traffic. Moreover, a proxy acts as a gatekeeper, providing an additional security layer in front of the Kafka cluster. Additionally, an API proxy allows for customization and grouping of Kafka topics into different configurations of API endpoints. By offloading the resource-intensive tasks of real-time streaming and infrastructure management to an API proxy, businesses can focus on core value-creating activities. 

Let's now explore some existing API proxy solutions in the market. There are three primary enterprise solutions that implement a real-time API proxy for Kafka. The first one is Ably, a leader in real-time streaming. Customers who already use Ably's real-time API can integrate its Kafka connector, enabling end users to stream from their Kafka cluster. PubNub, another well-established company in real-time services, offers a bridge for Kafka, although it is still in beta testing. Finally, Migratory Data provides a specialized product that natively integrates with Kafka, with expertise in scaling WebSocket connections. These solutions offer feature-rich and highly scalable options. However, one downside is the high cost and the lock-in to a particular ecosystem.

If you decide to roll your own solution, you will need to implement multiple architectural components. The basic components include a Kafka sync connector and an API proxy server. To handle incoming traffic, you will also need a pub-sub mechanism for sending messages to all server instances and a load balancer for routing traffic. Open source solutions are available for each of these architectural components. For instance, you can use Red Hat Stream C or build your own sync connector using the Kafka Connect API. However, this approach is complex and requires expertise in the Java ecosystem. Open source solutions for a proxy server include Pushpin and Centrifugal. Implementing your DIY solution is not easy, as it requires significant time, resources, and expertise, not to mention the associated costs.

This is where Fjord comes in. Fjord provides an alternative that sits between the DIY approach and paid services. It is an open-source, scalable, and easy-to-deploy platform. With Fjord, users have full ownership of the data coming in and out, and they can easily add any additional features they need. Fjord incorporates all the necessary infrastructure pieces out of the box, making it the only open-source platform that facilitates the deployment of an API proxy for Kafka. 

Now, let's take a closer look at Fjord itself and its architectural components. Fjord was designed with five main goals in mind. First, it handles the real-time infrastructure for streaming records from Kafka topics to internet-facing clients, reducing the load on existing infrastructure. Second, Fjord is scalable and can automatically scale up and down based on the current load, ensuring cost-effectiveness. Third, Fjord provides secure access control through JSON Web Tokens (JWTs), allowing businesses to control who has access to their data stream. Fourth, Fjord is fully open source and customizable, giving developers the flexibility to modify and extend its features. Finally, Fjord is easy to deploy, with a CLI that simplifies the deployment process on AWS to around 15 to 20 minutes.

Fjord is suitable for various use cases. For instance, let's consider a scenario where customers can order meals from their favorite restaurants via Supereats. Drivers need to be notified in real time whenever a customer places an order. In this case, customers, drivers, and restaurants would all connect to Supereats' servers via HTTP or HTTPS. The servers deliver either through a mobile app or a browser, initiating a Server-Sent Events (SSE) connection with Fjord. The Fjord proxy pulls records from the Kafka cluster, and the clients receive push updates via SSE, without being aware of the Fjord connection. This approach allows for customized content delivery without adding streaming load to the servers.

To understand Fjord's architecture better, let's explore its components and workflow in more detail. Clients connect to Fjord via a load balancer that distributes traffic evenly and enables auto scaling of servers based on demand. The Fjord server pushes new records to subscribed clients using SSE. On the backend, Kafka consumer groups pull information from the Kafka cluster, with the option to customize the number of members for parallel consumption of records. A NAT gateway allows Kafka traffic to reach the consumer groups. An important middleware component is a Redis server that decouples the interaction between consumer groups and servers, enabling scalability. This publish-subscribe mechanism allows the servers to scale up and down efficiently while receiving streaming records from all consumer groups.

Now, let's discuss some interesting technical challenges we faced while building Fjord. The first challenge was choosing between server-sent events (SSE) and websockets for real-time streaming. Long polling was ruled out due to its inefficiency. After considering the options, we settled on SSE as it worked on most browsers, with minimal issues on Internet Explorer. SSE proved to be a viable choice for our use case.

Another technical decision was containerization using Docker. By dockerizing the conser application and the server application, we could easily scale the number of instances for each component. Docker containers are lightweight, portable, and enable easy management of multiple instances. They also work well with orchestration tools like Kubernetes or Docker Swarm. To simplify container management, we chose AWS Elastic Container Service (ECS) and Fargate. Using ECS and Fargate, the containers and underlying servers are managed by AWS, freeing users from provisioning and managing servers.

The flow of data through Fjord presented another challenge. We needed an efficient mechanism to synchronize the flow from Kafka to connected clients. The Fjord conser acts as an abstraction for one or more Kafka consumer groups, with each group running as an ECS service. The conser pulls data from the Kafka cluster and publishes it to a Redis channel. The Fjord server, which is scalable, subscribes to the Redis channel and delivers new records to connected clients. This approach ensures efficient data flow and allows for seamless scaling.

Deploying Fjord on AWS involves four steps. First, users need to install the Fjord CLI globally. Then, they navigate to a new directory to generate a JSON file that customizes the Fjord deployment. This file includes necessary information such as Kafka broker IP address and security details. After customizing the settings, users run the Fjord deployment command, and AWS provisions and deploys all required resources. The process typically takes around 15 to 20 minutes. It's worth noting that users may need to whitelist NAT gateway IP addresses to enable access to their Kafka cluster if it's protected by a firewall.

In summary, Fjord is an innovative solution that addresses the challenges of real-time streaming from Kafka topics. It offers a reliable, scalable, and secure API proxy for delivering Kafka streams to Internet-facing clients. Fjord's architecture incorporates all the necessary components and can be easily deployed on AWS using the provided CLI. By providing an open-source platform, Fjord empowers users to have full control and ownership of their data stream while enabling customization and extension of features. The implementation of Fjord involved overcoming technical challenges such as choosing the right streaming technology, containerization, data synchronization, and streamlining the deployment process. Overall, Fjord provides a flexible and cost-effective solution for businesses seeking a real-time API proxy for Kafka. To deploy your AWS deployment, first, gather all the necessary information. Then, use the 'keyword setup' command to generate a JSON file that will be used to customize the deployment. This command also generates a private key for Jot authentication. Next, customize the generated JSON file by adding your Kafka broker's IP address, security information for your Kafka cluster, and the desired API topics for exposure. Once you have made the necessary customizations, run the 'fjord deploy' command and wait for AWS to provision and deploy all the required resources. This process usually takes around 15 to 20 minutes. And that's it!

When you run the 'fjord deploy' command, the CLI will output the public IP addresses of both your load balancer and NAT gateways. If your Kafka cluster is protected by a firewall, you will need to whitelist the NAT gateway IP addresses to allow access to the Fjord conser. Deploying with Fjord is as simple as running a few commands.

In the CLI output, you can see the two NAT gateway IP addresses and the URL of the load balancer. Fjord also offers an easy-to-use client-side JavaScript that can be included on any user interface to establish a connection stream. Thanks to the EventSource Web API, establishing a connection only requires a few lines of code. The load balancer's endpoint, as shown in the output, is used to establish a new SSE (Server-Sent Events) connection. Developers can add their own logic to handle each incoming Kafka record.

Now, let's discuss some of the interesting technical challenges we faced while building Fjord. The first challenge was choosing between server-sent events (SSE) and WebSockets for real-time streaming. SSE and WebSockets are both viable options, but SSE was chosen due to its simplicity, efficiency, and unidirectional communication. SSE works well for our use case since we only need clients to receive real-time data from Kafka. SSE also provides continuous automatic reconnection attempts, which is beneficial for mobile devices that may switch cell phone towers.

After deciding on SSE, the next challenge was decoupling the conser and the server. Initially, the conser published each record directly to the server via an HTTP POST request, which worked with a single server. However, we wanted to scale the server instances to accommodate multiple clients, and this setup didn't allow new servers to receive records from the conser. To solve this, we introduced a middleware, specifically Redis, between the conser and the server. Redis acts as a publish-subscribe mechanism to propagate messages from the conser to all online servers, enabling dynamic scaling without impacting the conser with additional requests.

The deployment on AWS presented another challenge regarding cross-origin requests (CORS). To enable the client-side JavaScript to access resources from a different origin, we needed to enable CORS using special request headers. While CORS worked locally, we encountered issues when deploying to AWS. After a period of inactivity, clients were getting shut out of servers, resulting in CORS errors. We discovered that the load balancer was timing out HTTP responses and forgetting about the headers that enabled CORS. To tackle this issue, we implemented a heartbeat or pulse for SSE. This involved sending a blank message to all clients at regular intervals to keep the connection alive, preventing the load balancer from timing out and causing CORS errors.

For load testing, we initially struggled to find an open-source library that supported SSE. Eventually, we found Gatling, which provided good documentation for testing SSE. By pushing the server to its limits, we discovered the maximum capacity per server and set up auto-scaling alarms to launch new servers as necessary. This allowed us to handle a large number of concurrent connections and serve any required number of clients efficiently.

In conclusion, we have presented the deployment process of Fjord on AWS, the use of SSE for real-time streaming, the decoupling of the conser and server using Redis, the resolution of CORS issues with a heartbeat mechanism, and the load testing challenges. We have highlighted the key technical decisions made along the way and the solutions that were implemented. If you have any further questions or comments, feel free to ask in the Zoom chat. The AWS console on the fjord server task, shown in the highlighted red box at the bottom, reveals that the maximum capacity we achieved on one server was approximately 8,500 client connections per server. This was achieved by using the lowest CPU and RAM settings possible for an AWS server instance. Thanks to fjord's ability to scale up new servers as needed to handle increased traffic, we were able to use the server with minimal power consumption. This allowed us to be cost-efficient while still being able to serve any number of clients required. With this, our presentation concludes. Thank you for your attention and for being here today. Now, I would like to open the floor for questions and comments. Please send them through the Zoom chat.

Q: How would this work in a mobile app?

A: Great question, Julio. In a mobile app, you would use Java or Kotlin for Android or Swift for iOS. There are libraries available for server-sent events (SSE) that can be used. Similarly, there are libraries available for websockets on browsers, and mobile apps can make use of them as well.

Q: What was the most challenging part of the project?

A: Thank you for the question. Starting from the initial experimental phase on the AWS console, transitioning to using the AWS CDK wasn't straightforward due to unclear documentation. This was the most challenging part for me. 

In addition, handling the influx of information in the AWS world and learning about Kafka and its configuration details and setup presented significant challenges.

Deploying the code on AWS posed the biggest challenge for me. Since we were accustomed to running things locally, transitioning to production-level code on AWS proved to be a whole different ballgame. The example I shared about the course issue, where everything seemed fine locally but presented problems in production, was an unexpected challenge.

Q: What was the most interesting part of this project for you?

A: For me, it was fascinating to explore and connect all the different components. Additionally, I particularly enjoyed learning and implementing server-sent events. Initially, we also built a prototype server using websockets, which made the project even more interesting. Furthermore, learning about Kafka and conducting load testing with Gatling was an exhilarating experience.

Q: After all the research and learning, did your initial vision of the project change?

A: Our initial vision of Fjord aligns quite closely with the final product. However, there were a few additional elements necessary to make it a scalable system. For example, we initially considered different messaging middlewares before selecting Elastic Cache and Redis. During this coding Capstone project, I had the opportunity to explore Kafka, Docker, AWS, and the world of infrastructure. It was an exciting process to move away from just coding and delve into these larger systems. I want to extend my congratulations to all the other teams who have done fantastic work on their capstone projects. Your efforts have been truly impressive. 

I would also like to express my gratitude to the logical community and everyone I've connected with during this journey. Your presence has made the experience much more enjoyable. Special thanks to Chris Sturgeon, Nick, our mentor, and of course, Austin, Vahe, and Sophie. It has been an awesome experience collaborating with you all.

I echo the sentiment expressed by my peers. This has truly been an amazing experience. Trusting in the process is crucial. There will be times when you doubt yourself, especially for those considering doing a capstone project. However, I can assure you that Chris and John are phenomenal mentors. Trust in your team, trust in yourself, and put in the hard work. The outcome will be a tremendous growth experience, as it has been for me and everyone else in the cohort.

Once again, I want to extend my heartfelt gratitude to all those who played a critical role at different stages of this process and experience. It may seem like I'm repeating myself, but I cannot emphasize enough how incredible this journey has been. I have learned so much, and it has been an absolute pleasure to be part of this team. I am truly proud of this cohort and want to thank everyone in the Launch School community, including our instructors and mentors, for their support and guidance. Finally, congratulations to everyone who has come this far.