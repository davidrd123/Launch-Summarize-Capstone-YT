so hi my name is rodney mutambo and joining me are christian larwood owen lentz and ezra elliott together we created jolt now jolt is a lightweight open source framework that builds and deploys jam stack applications with serverless functions as we discuss jolt we'll walk through five different sections so we'll start with what is a jam stack for serverless architecture then we'll look at how can you use existing solutions to deploy a jam stackless serverless application then we'll look at how would you deploy applications with jolt and then we'll see some challenges that came along the way as we developed jolt and finally we'll look at the final architecture of jolt and any future work that we have in mind so let's get started perhaps this jam stackless serverless architecture may not be very familiar to some people but this combination is actually gaining a lot of popularity in fact this is what a vp of engineering at a multi-million dollar cloud architecture deployment company is saying serverless plus jam stack is where web app architectures are going now this was written after seeing how their platform was more and more commonly being used for deploying jam stack plus serverless combinations in order to understand these two terms we need to actually understand what exactly is a web app architecture so we can define a web application architecture broadly as the way the pieces of our infrastructure interact now these interactions include middleware systems and databases to ensure multiple applications can work together and so let's make that a little bit more concrete so with any web application you have two sides you have the client side and the server side in essence these two sides interact through http requests and much of deciding a web app architecture depends on what you would like to happen on the client side and what you would like to happen on the server side now typically a developer may adopt what we call a three-tier architecture to build web apps and here you can see a picture of what a typical three-tier architecture may look like a client sends a request and most of the activity occurs on the server side this first server called the web server handles routing and hosting of static assets and if all the client needs are static assets the request ends at the web server and a static asset gets sent gets served back as a response now this middle server is called the application server and it handles general compute and that means any business logic is generally handled there finally we have the database server and that deals with the storage of persistent data so this architecture is very common and you can see that a lot of activity occurs on the server side in the traditional three-tier architecture both static and dynamic content is dealt with from the server side and generally each of these servers are actually privately owned as a front-end developer this would mean that i would need to spend a lot of time learning how to deal with server-side logic and perhaps i would just rather focus on my application code without having to worry about what goes into managing each of these specific servers as a result of this new architectures have actually started emerging that push more activity to the client side or limit the need of owning and managing each of these types of servers one type of architecture that does this is the jam stack architecture let's take a look at what the jam stack architecture is the person who coined the term jam stack was matthias billman and he's the ceo and founder of netlify and he says that the jam stack is a modern web development architecture based on client-side javascript reusable apis and pre-built markup let's try to break that down just a little bit so the jam in jam stack stands for javascript apis and markup this client side javascript is responsible for the dynamic workflow during the request response cycle apis provide added functionality such as content management search authorization payments and and beyond now markup refers to a collection of pre-rendered html files let's look a little deeper using an actual architecture diagram so a typical jam stack architecture can look like this static content is retrieved via the cdn and dynamic content is retrieved using javascript to make api calls to third-party apis now if we hone in a little bit we'll see that we've added a new piece of infrastructure the cdn a cdn or content distribution network is essentially a distributed platform of servers that serve content based on location in other words there's a network of servers around the world and for example if sally lives in africa she will receive content from the server nearest to her country in africa and likewise other locations will have servers closest to them that will serve these pre-rendered static assets to them this will result in faster performance now let's look closer at how the content actually gets to the cdn the general model of how content gets there is that some site generator can be used to assemble content the content that is needed to build static sites and and then a build server will build as many permutations of static pages as possible now we can push this content to a cdn and when a browser requests a page the browser will receive one of these pre-built pages from the closest server and this is how static content is handled now that we know how static content is handled we can look at serving more dynamic content we push all dynamic activity to the client side client-side javascript can be used to perform dom manipulations on the client's browser instead of completely re-rendering the whole page and these third-party apis will offer services that you do not actually have to manage typically this would be orchestrated using a client-side library like react or any of the ones seen on the top picture and additional content will be retrieved from a third-party api like google forms or fauna db for example and there are many others we can see that most of the activity has been pushed to the client side let's see what it looks like when we put it all together you now have an architecture that is able to both serve static and dynamic content with faster performance without the need for server management however the jam stack architecture has its own limitations one of the main drawbacks is how long it takes to build each of these sites since the build time is longer if someone needs a breaking news or current affairs site that can't that's constantly rebuilt and these static assets need to be constantly redeployed then the jam stack architecture may not be for that use case the jamstack architecture actually works well with sites where the static assets don't need to be changed often a good example would be an e-commerce site that has the same static assets served consistently but the data behind the api could change if we compare the jam stack architecture side by side next to the three-tier architecture we see a pattern before the web server was serving static content now that's done by the cdn before we use the database server to get data and an application server to execute application logic now third-party apis abstract away the managing of a database and even handle our application logic now before we go any further there's an important thing to to note at this point you could argue that this new architecture is actually more complex because of all the different services that are used and that would be true each of these services will probably have very complex logic that relates to it but for a front-end developer that complexity is abstracted away since the developer just consumes these services as apis within their front-end code as a result development is easier and that is the point one key point of jam stack of the jam stack is to reduce the complexity of re development by removing the need to own and manage servers not to reduce the complexity of the architecture still all of this dynamic activity is managed by a third-party api and that may be fine for some use cases but there are there may be times when a developer needs the ability to have some custom back-end capabilities without a third-party intermediary maybe there are credentials that a developer doesn't wish to share with a third party servers or private keys that can't be stored on the browser now we could get this back by spinning up an app server but that's not something we want to do with a jam stack architecture we don't want to have to own and manage servers this is where our last architecture comes back into the picture the last architecture we'll talk about is the serverless architecture to be clear when people are talking about serverless most people think of serverless architecture to mean serverless functions and serverless functions essentially became more widely used after aws launched aws lambda in 2015. aws aws defines a serverless function as a compute service that lets your code run without provisioning or managing servers or managing runtimes let's look at what that looks like practically as you can see in these two pictures all the developer has to consider is the functionality they want to write and everything else from infrastructure to runtimes will be provided on demand by a cloud provider still it's important to note that when someone uses serverless functions there are some tradeoffs to consider for example the benefits of serverless functions are that serverless functions provide a highly scalable backend that users only have to pay for what they use without having to understand any server side logic however they also have some significant drawbacks if we take aws lambda as an example lambdas are generally designed to run for short durations so they shouldn't be for long-running applications a second limitation is the fact that these serverless functions are not built with jam stack in mind they're built to be used with different services and this this makes it sometimes cumbersome to actually integrate serverless functions with jam stack manually as a result of this many jam stack providers have actually started making this integration between jam stack and serverless better and easier to implement also many developers and many companies have adopted this jam stackless serverless approach to building web apps an example of how developers are using this was actually given at the jamstack conference in 2020 and let's go back to our diagram to see how it works suppose someone has an e-commerce site this person may want to use stripe in order to deal with payments looking at our architecture the stripe front-end client could be used to retrieve a lot of information such as inventory and user information through api calls the user could even set up the initial credit card information but as soon as the user tries to check out that usually involves the stripe backend client and that usually requires a secret which can't be placed in this front-end browser client for security reasons serverless functions can be used to deal with secrets in the same way that the app server did previously they can act as a backend that can hold the stripe secret as an environment variable variable this ensures that sensitive data never actually lives in the browser a final example i'll give will show how companies are using this combination in 2019 paypal decided to migrate their paypal me portal to the jam stack plus serverless architecture and reported improvements in performance they even came up with a term for these types of apps and they called them static apps these are just a few examples but we can safely see that ryan coleman was on to something when he said serverless plus jam stack is where web app architectures are going now at this point you should be aware of what these terms mean and you may want your next application to be a serverless plus jam stack application you may even want to know what goes into building one of these applications but not know where to start i'm going to pass it off to my co-creator christian to tell us what would actually go into building a serverless plus jam stack application manually and what are some companies that are trying to make this process easier next up we'll dive into how you can deploy a jam sac plus servos application then we'll explore what existing solutions are out there and finally i'll unveil jolt so suppose you have a simple jamstack plus serverless notes application in order to successfully deploy and maintain this app you need to consider four core pieces of infrastructure first how to store your static assets then how to run your functions next how to manage your apis and finally how to distribute and serve those static assets to users let's take a quick look at each piece of infrastructure for a jam sack plus serverless application you're going to need to think about where to store all of your project static assets such as html and javascript you'll also need to store files such as your functions and their dependencies from there these files would need to be easily accessed by the other pieces of infrastructure that need them next you need to consider how you're going to run your functions so within jam sac plus service application you would need a way to add serverless compute functionality the use cases can be for a variety of reasons for example our notes application needs to query a third-party database such as fontadb for a list of all of our current notes or like rodney's earlier example to make a stripe api call third you would need to consider how you're going to manage your apis so within a jam stack plus service application you might have multiple functions and need a way for an http request from the client to be routed to the appropriate serverless function an api gateway takes all of the api calls from a client and routes them to the appropriate service on the back end using our notes app let's say a client makes a request to the route and even get notes the api gateway takes that request and routes it to the correct function which is then invoked lastly you need to consider how you're going to distribute and serve your applications static assets to users anywhere in the world in a jam zac post service application a global network of cdns ensures that whenever a user navigates to a site they'll receive the static assets from cdn closest them resulting in low latency and an optimal user experience no matter what service you ultimately choose to use the four pieces of infrastructure that we just saw are absolutely necessary if you decide to use aws you'll additionally have to provision and work with aws am which allows you to manage access to other aws services we decided to try out what it was like to manually deploy our jam tackle serverless notes application via the aws web console we quickly discovered that this process would require no fewer than 50 individual steps everything from manually creating each lambda and uploading any required environment variables or dependencies to creating the api gateway its routes and linking each of those routes to a lambda to setting up a cloudfront distribution and the dozens of other steps in between you can see that this is a tedious and error-prone endeavor and if you're fast enough and know exactly what to do you'll spend at least 15 minutes to provision these five separate aws resources not including the time it takes to wait for the distribution of your static assets across all aws cloudfront cdns so imagine having to do this entire process for each new jam stack plus serverless application or at least parts of the process every time you want to update a pc or infrastructure such as a lambda or api gateway route fortunately there are solutions out there that abstract away the complexity and time commitment of manually provisioning aws infrastructure like you just saw today there are a number of tools that allow developers to deploy jams acquis applications onto the cloud each one with its own set of trade-offs some of these tools such as netlify and burcell are built to make deploying an application as easy as possible their focus is on providing robust jam stack centric features that enables developers to easily build their project static assets and package up additional codes such as functions to provision the necessary infrastructure including any serverless functions and to deploy these assets to your cdn using either of them is an easy enough process but there are some large trade-offs to be considered both netlify and purcell rely on aws behind the scenes and they completely manage your infrastructure for you this means that you never have access to the underlying infrastructure of any of your applications additionally you also sacrifice configuration and netlify and versailles enforce limits on such things as lambda memory size the timeout limit for how long a lambda can run and even the total number of lambda indications you can make each month what's interesting is that these restrictions are actually far more limiting than the free tier for aws lambda next there are other diy options such as serverless framework and aws specific options such as amplify iac which encompasses cloud formation cdk and sam and web console these services tend to sacrifice ease of use and overall jam-sac centric features form more robust infrastructure capabilities simply put these solutions are as close as you can get to the infrastructure with the added benefit of being able to leverage any of the over 140 services within the aws ecosystem the drawback here is that none of these diy solutions are purely focused on helping you launch a jam stack plus serverless application this results in a subpar experience due to the broad use cases for any of the diy solutions and also due to their lack of features tailored to jam sac apps so is there a happy middle ground between these solutions a framework where it's easy to use and where the developer can own the underlying infrastructure introducing joel at its core jolt takes a project builds static assets provisions the necessary cloud infrastructure for both the application and your serverless functions and deploys that app to a cdn which then propagates around the world all from a single command and all in as little as a few minutes this one command jolt deploy removes the need for all of those manual and error prone steps we saw earlier when deploying to aws through the web console compared to netlifying versailles your application sits on your own aws infrastructure it's yours from the start and jolt is 100 open source so you can fork the repo and tailor it to your team's needs since jolt is a lightweight jam stack plus serverless framework it won't have as many jam stack-centric features as netlifier versel but enough to allow developer to easily deploy an app with serverless functions compared to aws jolts is easier to deploy and this is a big one seamlessly update your infrastructure and functionality as you continue to build out your jam stack plus serverless application most importantly jolt provides a happy middle ground where it's extremely simple to set up on your local machine provision and configure the necessary cloud infrastructure and serverless functions and deploy a functional application in minutes so at this point we've taken a look at the necessary infrastructure in order to deploy and maintain a jam stack for servo's application we've also touched on how to manually deploy a simple notes app via the aws web console and reviewed popular jam sac serverless options lastly from a high level we introduced jolt and several of the benefits the jolt framework provides so i'm going to pass things off to my co-creator owen who will discuss the core architecture of jolt and how deploying jam stack plus servo's application with joel works so we've looked at how jolt fits in alongside some other methods for deploying a jam stack plus serverless application and now why don't we take a walk through the specific pieces of infrastructure that jolt uses to deploy applications so you might remember this diagram that rodney introduced earlier these are the core components of a jam stack plus serverless application so with this setup static assets are requested from a cdn and the computational tasks that would have been performed by a server are now handled by third-party apis finally any custom compute that you might need to perform outside of a client's browser for instance using a secret key to communicate with a third-party payment service can be performed with serverless functions so using this diagram as a jumping off point let's walk through the core architecture of jolt first up we need some kind of cdn service that can cache and serve static assets with minimal latency so since we're working with aws their cdn service cloudfront will fulfill this role next we need somewhere to store the static html css and javascript that make up our application so we chose s3 for this since cloudfront our cdn is built specifically for caching and storing files on s3 so now when an application is deployed with jolt cloudfront will retrieve those static files from s3 and cache them so they can be served to clients immediately when they're requested one other interaction between s3 and cloudfront that's worth mentioning here is that every 24 hours the cash expires and when this happens the next client requests will result in a cache miss this just means that the cache didn't contain any data that the client requested so on a cache miss cloudfront will go and retrieve the latest version of the requested files from s3 repopulate the cash and then send the requested assets back to the client so this is great now we have a way of serving static assets to users and we can use third-party apis to handle many of the computational tasks that would have been handled by a back-end server in our three-tier architecture but what if we need to perform some computation that can't be handled by a third party well as christian mentioned earlier we use aws serverless functions known as lambdas for this job while lambdas don't take the place of those third-party apis we saw earlier they do allow you to create your own custom services that can meet your application's needs when no such third-party solution exists so right now the current diagram doesn't actually provide a way for clients to send requests to our lambdas so as christian introduced earlier we need some way of linking clients and lambdas this would be done with some kind of reverse proxy sort of like a traffic cop that can sit in the middle and make sure that each request reaches the appropriate lambda so jolt uses aws api gateway for this job to provide a unique endpoint for every lambda each one is integrated into the api gateway so that requests can be sent to them using the gateway url with the lambda name appended to it with the api gateway added to our architecture we now have a fully functioning jam stack application with a suite of serverless functions and requests for static content can be sent to cloudfront dynamic content can be provided by lambdas through the api gateway or by using those third-party apis so there are a few more pieces of infrastructure that jolt uses but for now i think we should take a well-earned break from infrastructure diagrams and look instead at how to actually use jolt so let's do this from the perspective of a hypothetical web developer we'll call him bob bob is building a new application for writing notes as a front-end developer bob is interested in finding a web app architecture that will give him some light back-end functionality for securely interfacing with a third-party database without needing to build and manage a complicated application server and he'd also like it to be highly scalable with little effort on his part so after some research bob decides that jam stack plus serverless fit his needs very nicely so the application is built using react and it has some basic crud functionality that will be provided by some lambdas that interface with a graphql database that's called faunadb this will aid in storing updating and retrieving notes to get started bob can just run jolt init from the root directory of his application and as you can see in the terminal here he's then prompted for answers to a few questions that will be stored locally in a configuration file jolt uses this file to keep track of all of the details needed to develop deploy and manage his notes app and if bob wanted to use jolt with other applications he could just run jolt in it again from the root directory of those projects to configure them in much the same way since bob needs a few lambdas in order to securely interface with the fauna dv database you can define each lambda as a separate file inside of a functions folder kind of like the one shown here and this will be located in the root of his application for this app bob needs a lambda for getting notes one for creating notes and one for updating notes but unless bob can write perfect bug-free code they'll probably want to test these out before he deploys them so this brings up one of the major pain points of building a jam stack plus serverless application this is the area of testing and debugging your lambdas if you don't have some sort of specialized tool there's really no way for you to run lambdas locally so for instance if bob had some bugs in the code for his create lambda create create note lambda he would need to deploy the lambda aws and then send a request to it consult the logs which are part of a different aws service then make a change to the lambda locally redeploy and on and on as you can imagine deploying and updating lambdas during development in this way is a time-consuming process it also involves a lot of context switching as you shift from your local development environment to the aws console in order to make changes to the code and read logs and on this results in a complex workflow and it's also a significant departure from the way that developers normally test and debug code so in order to provide a smoother debugging experience with lambdas jolt provides a local development server that lets you run your lambdas so here's a quick demo of how bob might use this lambda development server in order to test his lambdas locally before he deploys his application so we can see here bob is in the root of his application and from there in order to test his lambdas locally he can just run the command jolt dev this will spin up two different servers one running his notes app and the other running his lambdas locally and once both servers are running he can navigate to localhost at port 3000 in order to view his application and as well as to send requests to lambdas so changes to lambda code using this system take effect in real time and logs from lambda requests can be seen printed out in the terminal here this lambda server could also be spun up by itself and this could be used to maybe handle running unit tests on your lambdas for instance so now that bob's finished development and he's made sure that everything works he's ready to deploy his app so to start deployment bob just runs jolt deploy and when he does this first thing that happens is a build process is kicked off using whichever build command bob is specified this build process will automatically transform bob's front end application code into a collection of minified html css and javascript files and these will be transpiled so that they are compatible with older web browsers as well as new ones after building jolt can provision the infrastructure that we outlined earlier for bob's app and then the static assets in lambda code get sent to s3 now these static assets can be cached by cloudfront and lambdas can be created using the uploaded lambda code deploying to a cdn sometimes takes a little while but after a few minutes bob's app has propagated to cdn servers all over the world and bob notes is fully deployed and ready to take the world by storm so some time goes by bob notes is well on its way to becoming the next snapchat since he's using a jam stack plus serverless architecture bob's app can automatically scale up to handle the increased traffic in addition any number of lambda instances can be spun up on demand and the cdn can serve static assets to an unlimited number of clients all over the world without any kind of slowdown so if bob had gone with a traditional three-tier architecture he would probably now be spending most of his time struggling to keep up with the rapid growth by provisioning more servers and vertically or even horizontally scaling his database since he's not busy with back-end management bob has the time to develop some new features for bob notes first on the list is adding the ability for users to delete notes so after developing and testing this new functionality locally bob is ready to roll out version two of bob notes and he can do this using the jolt update command this will once again build the application code into a collection of static assets the static assets in the lambda code are used to update the existing infrastructure on aws and and in the case of lambdas being added or subtracted the appropriate lambda will be created or removed in bob's case a new lambda delete note gets created and after a few minutes the version 2 is live all over the world but wait something has gone horribly wrong here complaints are flooding in from millions of disgruntled bob notes users it looks like bob forgot to include any css in version 2 of bob notes fortunately for bob joel provides an easy fix in the event that the production version of an application breaks using the command jolt rollback bob can revert both his front end and his lambdas to the previous version rolling back both front end and lambdas together in this way ensures that the available lambdas will remain compatible with the front end of this application rolling back the front end and serverless functions was actually an especially difficult problem to solve but we're going to get into some more detail on how that was tackled later on uh for now bob has rolled out uh rolled his application back to version two things are looking nice and stylish again and now that he has a stable build redeployed bob has time to fix the broken code base and do a proper roll out of version 2 when he's ready so we've now explored the core pieces of infrastructure that make up an application deployed with jolt and we walk through the different commands used for deploying and managing an application now i'm going to turn things over to ezra who will take a closer look at a few of the commands we ran earlier as well as some of the challenges that we overcame while developing them hi i'm ezra elliott and in this part of the presentation we will discuss some technical challenges of developing jolt the development of jolt required some out of the box thinking and consideration of some technically difficult problems one of the first challenges we faced was making our api endpoints predictable traditional web applications can send requests to the backend via a simple and intuitive relative url an example is sending a get request to the endpoint slash get notes that seems simple enough but with api gateway being used to create apis users would have to use the url of the api gateway if they want to access their api this can be very confusing and time consuming so we need to a way to make these endpoints relative if the user were to do this themselves they would get a gateway link that they could use to access their functions but that is way too time consuming and requires hard-coding the url of the gateway into the code base we decided to use a feature of cloudfront called lambda at edge lambda edge allows us to run functions when certain urls get requests these edge lambdas are very much like traditional lambdas but they're executed on cdn servers much closer to their clients this results in a serverless computing environment with very low latency using lambda edge we can send all requests with a dot functions path prefix to the edge lambda the edge lambda responds with a 308 permanent redirect response which tells the client to repeat the request using a different link because the response denotes a permanent redirect the response will be cached on the client's browser this means that the browser will know where to send the request next time this function is called thanks to this our users will have lower latency as a browser will automatically send the request to the api gateway now that we have redirection from cloudfront to api gateway we can invoke our functions using a proxy function in cloudfront allows developers to use intuitive paths relative paths with no hassle let's discuss some more demanding challenges with managing our applications infrastructure another challenge we faced when developing jolt was dealing with a failure during a deployment or update these failures can cause many things to go wrong and because we are dealing with many pieces of infrastructure manually rectifying an error could cost a developer valuable time let's say a user is updating their application and the lambda update process fails the rest of the updates already in place which means a user could have an application that is stuck in between versions if they aren't careful extra infrastructure could lead to unexpected bills for unnecessary services how can we ensure that a failure to completely deploy or update a jolt app will not cause any lingering infrastructure to remain on the user's account first of all deployments and updates are treated as single units the entire process either succeeds or fails if the deployment or update succeeds the changes become available in the event of a failure our system takes measures to revert your application to the exact state before the process began the concept of treating many actions as a single indivisible unit is known as atomicity by implementing this feature we can be sure that your infrastructure will not change without a successful operation if the deployment or update is successful all of the information for this specific version will be recorded to a database called dynamodb we use dynamodb as a source of truth for all jolt applications this database contains a table for each application the table keeps track of files and infrastructure for each version this enables us to interact with different versions after they are created we can safely and deploy we can safely deploy and update our applications but we faced another challenge with managing a jolt application like we saw with bob if a jolt user updates their application just to find out that something is wrong they should be able to quickly change the version of their app to one that works this is simple enough for static assets but changing the version of an api is difficult the endpoints of a rollback versions api need to be exactly the same and the static assets need to be available again when rolling back the static assets of a jolt application we had to decide between two potential paths that had their own trade-offs the first would involve deleting all versions of a file that exceed the version used for the rollback now the rollback version will be treated as a laser latest version this would prevent a user from being able to roll back to a newer version of the application since we have deleted static assets of newer versions the second would involve re-uploading files from a specific version this would make cloudfront serve those assets as if they were the latest version without having to delete other static assets this approach would allow us to go back and forth between versions but it would use more storage on s3 jolt decided that the ability to roll back to any version was worth the extra storage using s3 so we choose to re-upload static assets the next step is to query the dynamo database for the proxy used in the selected version this will be used to give us access to the selected versions api gateway because on updating we completely rebuild the api saving it as a new version due to api gateway being connected to the proxy we can rely on the version proxies give access to specific versions of the api there is one final step to the rollback process and this involves updating cloudfront the first step in updating cloudfront is to invalidate the objects cached by cloudfront this will force cloudfront to retrieve the updated static assets from s3 we must also change the proxy version to the version that links our static assets to the proper api this process takes a couple of minutes due to the global nature of cloudfront once every step is completed the selected rollback version will be active for the entire world to see let's see how this process works in our cli jolt cli has a rollback command that will allow users to roll back a project to any version they select the first step is to select a project that you wish to change now you now you can select the version for the rollback once you select the version for the rollback you can conver confirm that you want to revert the specified version and the process will begin as you see here we've now rolled back to a previous version of bob notes now that you're familiar with jolt and some of its capabilities let's take a look at its final architecture jolt's final architecture has a few changes from the core architecture namely the ability to use relative paths for function calls update capabilities and rollback capabilities we can see a client interacting with cloudfront to retrieve static assets and access the lambdas of an application dynamo database stores information for every jolt application some future work we would like to add is a gui dashboard for managing projects github integration for continuous deployment support for additional lambda run times in application staging environments thanks so much for coming to our presentation we'll now begin answering questions please submit any questions in the q a box in the chat awesome we already have a question and that is what was the part building jolt that you enjoyed the most i guess i can go first on that one um i think personally um my favorite part was probably uh just the ability to implement rollbacks that that just a series of decisions we were making there made that a much easier process but just the ability to have api versioning was was very it was very interesting problem to tackle so i'll just mention that sure so mine's a little bit more broad because like we had always heard about aws and and as you go through core you start to like hear about aws and know all about it but it seems like this big big thing out there and after we all dove into the documentation uh it actually wasn't as unwieldy as it seems uh there are certain aspects of it that are very challenging and even reading the documentation is challenging but overall just like just being able to finally get a grasp on some of these aws services that we'll probably be using on the job is is really cool now that i know how to do it and a lot more comfortable in that yeah in a similar vein to what christian was saying um working with aws is kind of a power trip when you realize you know you have with just a few lines of code you can spin up these complex pieces of infrastructure all over the world it's kind of mind-blowing especially having come from a place a few months ago of not even knowing what most of these things were an api gateway dynamodb these services were completely foreign to me and now it's like all of that power is right at my fingertips very cool yeah i really enjoyed uh just learning and figuring out the whole rollback process and how we can take the infrastructure that we used to create our applications and change the versions in a matter of minutes it was very interesting and i enjoyed it okay awesome we have a comment from melissa she says great job explaining why someone would want to use jolt and how it works i especially appreciate the inclusion of the lambda dev sandbox and i learned something about the company i work for that paypal is using a gemstack plus serverless architecture for the dot me app my team there uses gatsby for our internal documentation and let's move on to the next question was this your first time working together as a team if so how was that process for you all was it hard sure so we were fortunate enough well rodney and myself have been we went through core pretty much together and so we basically would study together every almost every single day uh so we knew we worked with each other extensively for the eight months that it took us to get through core and throughout that time eventually we got to know ezra and owen and so we kind of formed this little team and to anybody who's listening who's going through core right now we uh we ended up just like forming this like little study group that kind of just followed along as we all were going through the same uh the same course at the same time and we ended up um yeah we ended up doing like a lot of like practice projects towards the end of our time in core together and we we all knew that we were going to be doing uh capstone and so we figured let's just keep the keep the team going keep the dream alive and so yeah so we had uh worked with each other through core that's in certain aspects and then into this as well and was it hard okay no it wasn't hard this challenge is for sure but um we've we haven't having known each other it doesn't help okay next question from lena uh great work control team your project will save time energy and money for gemstock devs uh in your experience so far what are costs a developer can expect when using jolt yeah i'll go ahead as well okay yeah so uh aws lambda you get about i think it's two million free invocations per year uh or per billing cycle for the edge lambda i don't uh there is no three t uh free tier and i believe the price for each uh invocation is around three times the price of a regular lambda but with that being said uh we've done testing for months now and the bills have been very light uh we can't give a definite answer as for how the uh cost would scale i would add to that one of the benefits of doing it this open source way versus using a platform like netlify ever sell is that you're paying the base aws rate whereas when you're going through a third party like network i ever sell they're attacking whatever extra fees they want to add on top of that so they can meet their bottom line yeah to tap off that to go off that as well like uh as i mentioned in my section that lavine purcell uh they they have they have serious limits um so like for example i think it's like as i mentioned you get about a million or two million lambda invocations every month uh with land with metal player for sale if you go through theirs they only allow you to have like 125 000 i think it was last time i checked each month uh and then if you want to go above that you have to start paying like 10 a month so while they while they make things easier for jam-psych developers um you miss out on a lot of this free tier stuff that aws gives you uh which is why we went down this route of having like merging the best of both worlds essentially awesome the next question would you recommend to all core graduates to learn more about aws and what other tool did you learn in capstone that you recommend to core graduates i just graded graduated core and i'm deciding what to prioritize to learn next i i can chime in here [Music] the present capstone cohort will probably tell you that i'm a proponent for learning aws um i think i think you like the aws courses that they have tend to be very markety but the uh they're like it does help you really understand uh a lot of what's going on in the industry because aws they're they have so many different services that almost any part of the industry will be touched there so just understanding how they work there will really help you get closer at least to the job market and even prep you to to think beyond applications and think in systems and that's that's really one of the key things you want to pick up after core i would add to that uh i definitely agree that learning it is great i think it's just one of the hallmarks of life and software development you know you always want to be learning new things and there's never really a downside to that but um i would also say if you know time is a concern it is probably smart to prioritize learning the things that are going to be useful for whatever job you're interested in so generally aws skills are going to be more useful for like web engineering-centric roles um if you're just interested in like a front end dev roll or something it probably won't come up too much but um definitely if you have the time and the curiosity it's well worth playing around with because it's pretty fun okay so next question is there a way to roll forward to a more recent version after rolling back yes so our rollback functionality allows you to do uh to change the version to any version of the application that you've previously deployed or updated to so say you you do a rollback to version one of the application just for historical purposes you could you can do another rollback go straight to the latest version again and uh there's no problem with that yes okay how did you split responsibilities for the project during the development process i can chime in here um so we we had different uh phases but generally we came together as a team to figure out what it is that we wanted to implement and then we were able to split off into pairs or if it was something that one individual could implement they would they would pioneer it and then other another person could help but again it's it's uh it's a more difficult question to answer because different stages we use different approaches and we just kind of had this fluid process of we have a core idea of what we want to do and we can implement it in different ways [Music] okay from austin awesome presentation thinking back to starting this process you mentioned manually issuing dozens of commands to get your gemstack setup running how did you move from a manual process of issuing commands to your eventual solution did you try out any strategies between your manual start and where you ended up sure so i can jump on this one first so yeah so we wanted to put ourselves uh we wanted to understand like what how painful is the process if we if we only used the aws web console and we wrote that huge guide that you might have really quickly seen go through in that gif that shows uh the 50 plus commands or the 50 plus steps and so in when it came to issuing the actual commands to get our infrastructure up and running uh we explored a couple different options we explored the aw aws cdk and ultimately we arrived on the aws sdk uh software development kit which gave us a little bit more flexibility as to what to run and ultimately it just came down to um issuing commands for those core pieces of key pieces of infrastructure and there's some functions within there that are needed in order to for example what uh for example we need to like so for an example yeah to create a lambda uh manually or sorry to create a lambda in our code we have to create an item role and then attach that um in order in order to invoke that i am role or in order to invoke that lambda and so there's sub commands within there but ultimately it all boils up to what is it like four primary commands to to provision all of this infrastructure okay and a final comment from he says you may already do this but if not the recommendation would be to add a way to check on your available or remaining aws bandwidth from within the jolt cli terminal especially for the free tire so are you doing this no we aren't yet although actually that is a really cool idea um now that i see you say that i'm going to have to go and look up if there's an api for for metering those things if there is it would probably be a pretty easy thing to implement and definitely a handy feature to have so good call there yeah and again everything is on your aws account so you can always go to the aws web console and just take a look at your uh your billing for the current billing cycle and you'll see uh how much how much resource resources you've been using and how much you have available and the expenses okay so that was the last question any final words uh yeah uh thank you guys for coming to the presentation we appreciate it uh i think you had some good suggestions so you need to just come join our team uh but this has been a fun process and i hope it's been a good learning experience for those in core and well-represented our team 