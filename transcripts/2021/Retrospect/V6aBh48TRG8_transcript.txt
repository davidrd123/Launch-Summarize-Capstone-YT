hi i'm holden one member of team textrix and we built retrospect as our capstone project the agenda for today first i'll introduce retrospect why we built it how you can use it and what's the ideal use case next or we'll talk about existing solutions in this space and then how retrospect works in more detail after that nicole will talk about the design challenges associated with retrospect and how we handled them after that i'll walk through two more demos showcasing retrospect in slightly different use cases and finally svetlana will talk about the installation and spin-up process for retrospect so as part of the introduction what is retrospect so retrospect is a full stack tracing tool for debugging small distributed or monolithic applications retrospect records browser events and back-end request data and puts them into a single user interface so that developers can debug their applications with service traces and session replay now what does it look like to debug with retrospect imagine that you have an application on ecommerce website in this case bob's shop you can see that there's a micro services architecture with an authenticate service inventory payment and shipping service notice also in the right that retrospect is connected both to the client and to the back end now sometimes your application breaks in this case the user attempted to check out but they were unable to and they file a complaint with the owner bob now before we go into the debugging step let's see what bob's shop looks like so this is a recording of the user interface we can see the user adding apples to the cart cherries to the cart and then checking out we can see them adding their information as well as the items that they added on the right notice or note the email ivan gmail.com that will be important when we walk through the debugging later in this presentation now the payment method information will not be recorded by retrospect bob is able to add some special class names to the html so that credit card number expiration and cvv are not recorded also they click the submit button multiple times without success so now what does it look like to debug here and bob has two pieces of information when he's debugging he knows the user's email ivan gmail.com and he knows that the checkout failed that's it so how does he start the first thing he'll do is search the backend data for the user's email he looks for ivan gmail.com and the retrospect user interface makes it really easy to search through this back-end request data he can then sort by the date of spam to get the most recent data because he knows the request failed recently and now we can look at the spam details card he just clicks on a row and you get this more detailed view now there's a couple of very interesting pieces of information here first the waterfall chart at the top looks wrong to bob you may not understand it but bob recognizes that this looks too short normally the checkout process has five bars this only has three which tells bob that the checkout process got interrupted somewhere on the back end second a little bit lower bob can see that the status code returned to the user with a 400 confirming that an error occurred and then finally in the in the request data portion he can see that the customer email was ivan gmail.com unfortunately this is not enough to tell him what exactly went wrong so he clicks on the chapter id we haven't explained chapters yet but think of them as a combination of the front-end browser events and the back-end data associated with a particular transaction and again bob remembers that the waterfall chart looked wrong it looked too short so he can click on that last bar in the chart to get more information about the back end our request in this case he opens up the span tags and he can see that there was the last request sent was to the inventory service to the inventory not available endpoint and that it returned a 200. now this tells bob a couple things one the checkout process ended after inventory but he's not sure why two it sent a 200. so it's not that the inventory service was broken it's that something else happened prior to that inventory service being hit that caused the checkout process to end prematurely now at this point bob is stuck nothing on his back end tells him what the answer uh is why this process stopped he needs more information about what the user did unfortunately when he reaches out to the user they're not responsive as you may know the user likely went to another website and has already purchased their products and is not interested in helping bob debug his own website if this were a normal tracing tool bob would be stuck but retrospect is not a normal tracing tool bob can click on the session id and they can see an exact reproduction of what happened in the browser prior to the error he can see that ivan added apples and cherries into the cart and then what the checkout process looked like this is extremely valuable for bob because he can confirm a couple things one that ivan was using correct credentials when he went to checkout and two he can confirm what the user did on the front end that may have triggered an error and so bob will then look more closely at that session replay when he's trying to debug so remember bob has two pieces of information when he's debugging one the inventory service was the last service that got hit on his back end two he knows that the user was trying to buy cherries and apples those are probably connected and so when he looks at that session replay more closely he can see that something impossible happened you may notice it they tried to add cherries which there are zero left in stock into the cart not only they tried they succeeded so no wonder that when they attempted to check out something broke they're not available and this tells bob that something has gone wrong in his front-end code and maybe his back-end code those products shouldn't even be visible on his website let alone be able to be added to the cart and so this doesn't tell bob exactly what line of code he needs to change but it does give bob a useful starting point when he begins to debug this combination of front-end and back-end behavior that produces an emergent bug would not be solved with normal tracing solutions so what would it look like if bob tried to debug without retrospects so you have the same application within microservices architecture you have that same error when the user tries to check out but now bob doesn't have retrospect he can't just easily search the backend request data to find a request with ivan gmail.com he can't look at the session replay so what does he do well first he has to check each of his services he might check the shipping service check the logs now these are not easy to read and their quality is entirely determined by the person who set them up so if bob can't find an answer he's not certain that there isn't an answer there he just doesn't know and so he checks the next service authenticate checks the logs still no answer the payment service no the inventory service maybe but there's no confirmation like we saw in a retrospect ui the inventory service didn't return a 400 or 500 response it returned to 200 because it was a legitimate request to the inventory not available endpoint so nothing in the inventory logs tells him what the error was we know that the error was a combination of front-end and back-end behavior but bob can't tell that instead bob has to reach out to the user and they don't respond because bob doesn't have session replay he relies on the user being willing to talk to him and what their memory was of the transaction do you think the user can remember that cherries were out of stock when they went to add them to the cart probably not and so why was retrospect able to help him here and that's because retrospect is an observability tool for front-end and back-end recordings we not only capture the back-end tracing data we also capture the browser activity this reduces the amount of time bob spent looking at logs because he doesn't have to check in each one of his services he can just query in the retrospect user interface it also makes bob less dependent on the customer because he doesn't need a back and forth with the user about what they did he can just use the session replay now we said retrospect is an observability tool but what is observability you're probably familiar with two of the three pillars metrics are numeric values over time things like status code frequency average time to response these could tell you if you have a problem by illustrating some irregular patterns in the data also logs these are information with a timestamp usually some contextual data these can tell you what the problem is which line of code through an exception but you have to find it first so why did we focus on tracing and that's because metrics and logs are insufficient in modern distributed application you need tracing to tell you where to look before you can use something like logging now to make this more clear we can use the analogy of the game telephone you may have played it before debugging telephone and debugging distributed backend architectures are very similar because they're both black boxes when you put a request into a micro service architecture or you start a game of telephone you're sending a request or a phrase through a series of people a series of microservices and then you get the output which often has distortions introduced but you're not sure where or why now in the real world when you're debugging telephone you can ask each person in line what did you say at this time what did you say here what did you say here but when you're debugging microservices it's not as easy the customer often doesn't remember exactly what they said and they don't know exactly what they received and your micro services are very forgetful they can't remember all of their responses to particular uh initial requests and so that's where retrospect comes in retrospect is the equivalent of handling that first person a sheet of paper that says write down your name and write down what you said and then pass that paper on so by the time it reaches the end if a distortion has been introduced you can look at that sheet of paper check the list of services and what they said and find exactly where the transmission fails to extend this analogy logging would be the equivalent of giving each person their own separate sheet of paper and having them write down everything that they said now this doesn't solve the problem though because if a distortion gets introduced you don't know where it got introduced you still have to talk to every single person and read their entire paper because those papers don't get passed on like they would in tracing and so what kind of questions can our retrospect application answer it could tell you which service was down during the checkout process or in this case it could tell you at which point did the process stop like it stopped in the inventory service for ivan it could also say which account was a customer logged into when some event occurred for example bob could confirm that ivan jones was using the correct credentials when they were checking out it could also tell you which service took the longest to respond we'll show you a demo later that illustrates this more clearly now questions we don't answer we can't tell you which line of code generated an exception inside of a service that would be something like logging we also can't tell you which services on average are the slowest that would be a question for metrics we can only tell you which services were slow for a specific series of requests now the telephone analogy makes it clear in the real world what tracing looks like but what does it look like with machines here's a service diagram for bob's application you can see the client connects the api service and that connects to authenticate inventory payment and shipping services the service trace is the waterfall chart that we looked at previously in the retrospect ui you can see that the first part is the api service then authenticate inventory payment and shipping services this reflects the order in which services need to be called first authenticate then inventory payment and shipping remember that the checkout process got stopped at inventory for ivan so we didn't see the payment and shipping services when we put these two together you can see the relationship between tracing and the diagram the service trace looks like the diagram spread across time now let's introduce some vocabulary that we'll be using a lot later so a span is a single operation within a trace in this case you can see the arrow is pointing at the authenticate span after which is the inventory span payment span shipping span this tells you where the request went what data it held and how long it took by the length of the span the root span is the first span it's the parent of all these child spans notice that the api span cannot finish until all of its child spans especially the shipping span have finished this is the first request to hit your architecture and then the trace this is the combination of a root span and all of its child spans it's the complete path of a single request this is the waterfall chart that we saw in the span details card now i'll turn it over to earl to talk about what observability tools bob should use thank you holden so how can bob achieve a sufficient level of observability for this use case using existing solutions let's have a look at some of his options now one of avenue for bob is to go with an enterprise solution sas vendors such as sentry datadog and you relic would provide a way to see back-end traces in the context of front-end events as demonstrated these enterprise solutions offer not only observability for traces but also logs and metrics making them feature rich however the ease of outsourcing observability to a sas vendor comes at the cost of lack of data ownership and recurring fees in the case of a small company like bob's where capital may be low it may be better to allocate the money for those fees to other expenses and instead use an open source solution that provides just essential features for debugging a small micro service based application another option for bob is to go with a diy solution bob can use open source solutions dedicated to recording front-end events and back-end traces the most prominent open-source solutions for recording these include open telemetry for the backend traces and rr web for the front and events however bob would have to spend time learning how to use these open source solutions properly moreover they do not integrate with each other out of the box so bob would have to find a way to customize rr web and open telemetry such that the front and the vents will be connected to the back end traces they correspond to the time and energy bob would expend to get a diy solution setup would be better spent on the core functionality of his application now what if there was a solution that offered the ease of deployment offered by enterprise while also providing the benefits of diy this is where retrospect fits retrospect connects the related events and traces to of the instrumented application out of the box thanks to its ready-made pipeline the user will retain data ownership as the database instance is deployed in the environment of their choosing and it comes with a simple yet powerful ui for debugging small microservice based applications while it may not be feature rich enough to give you real-time performance analytics or say the trend of your website's conversion rates it will provide you with the context necessary to figure out what services to investigate given an error now let's see how retrospec works in short retrospect is a full stack tracing tool for small micro service based applications it is comprised of six pieces that work together to collect connect and select back-end traces and front-end events let's take a closer look at the different architectural components first is the collect group the client and server agents are responsible for collecting the data from the instrumented application for the client agent we use the open source web session recording library rr web with modifications to attach metadata onto requests that connect the recorded events to the relevant backend traces for the server agent we use the open source observability framework open telemetry similar to the client agent we modified open telemetry to attach metadata that would allow us to connect these backend traces to the relevant frontend events now here is a closer look at the agents at work and bob's application when a user visits bob's app the retrospect client agent takes full dom snapshots and listens for dumb mutation events and mouse clicks it sends these dehydrated events to the retrospect api after attaching metadata required for connecting them to their respective backend traces recorded by the retrospect server agent when the user triggers an http request to bob's back end the retrospect server agent creates the span that will be passed along the microservices involved in the http request this span is the pencil and paper from the telephone analogy and our retrospect middleware attaches the metadata required for connecting each span to the user session that triggered their http request before they are sent to the retrospect api next is the connect group the three pieces for connect are the api server an instance of a cassandra database and a server containing scheduled data maintenance tasks the api server receives the data from the agents and transforms the contents for easier querying before sending it to cassandra it also serves data to the ui by making cql queries to cassandra cassandra is our data store of choice this design decision will be covered in greater detail later but in short we chose cassandra due to the high volume of events retrospect would consume from the instrumented application the scheduled task server contains crown jobs that maintain the database by purging data older than a set number of days configurable by bob it also solves the technical challenge we faced with using the current implementation of open telemetry as the metadata isn't propagated properly to database bands the api places these unidentified database bands in a buffer within cassandra where they'll stay until their requisite metadata is attached to them by the cron job the last piece of retrospect is our ui which allows for the selection of specific events and traces we designed the ui to have a good balance between simplicity and power while also thinking about the user experience our design decisions for our ui were driven by us ourselves developing bob's micro service based application instrumenting it with retrospect and inducing errors in bob's different microservices we also consulted working developers to make sure our ui had the features they thought were necessary for our use case the result was a ui that was quite fun to use internally now it may not have all the bells and whistles of the bigger enterprise solutions but we aren't aiming to be a complete three pillars observability solution like they are our focus is on the traces through your architecture to give your micro services the paper and pencil in their game of telephone now we'll hand it over to nicole for the design challenges okay thank you earl so next we're going to talk about how did we build retrospect starting from the the design choice and starting from the project choice and going through how did we come to the final project that is retrospect during all three steps of the way so first we have we are going to talk about connecting events with traces then we're going to talk about how we store data and finally we'll talk about some just some choices about the ui so first uh we talked about open telemetry in our web and how they do really well with the front front and the back end specifically they are highly customizable they're feature rich open telemetry focuses on the back end in our web on the front end but they don't actually talk to each other natively they focus on their own on their own domains but they don't have adapters to connect them to outside technologies so uh as we're going forward let's just remind so traces refer to the back end so traces refer to back in conversations between services and architectures and events are fired by the user so with open telemetry our web we're able to record traces and events and first thing we're going to do is we're just going to store that somewhere so let's take a look at that next yeah here so we have traces on one side we have events on the other and these are clustered into two different tables great this is a this is a great first step but we don't have any way to connect them so first thing we did we decided to borrow an idea from browser browser cookies where we wanted to create and pass along a session id now there's not any way to do that out of the box opentel and our web are not designed for this they're not designed to take extra baggage as we started calling it in the form of additional headers and content so we had to build a custom span processor that that handles this so on the front end this plays out with we built a wrapper that intercepts and pins our own metadata onto events that are being sent out on the back end through experimentation we figured out how to forward this metadata along with all of the traces or with all of the spans within it so the first thing we did once we had this technology was we added session ids we generate a uuid on the client and that gets sent on to all of the uh it gets sent on with all of the events and with all of the traces so let's take a look at what that shows huzzah we have addresses and events and they're in a box now we have a session and next we'll even show how this is useful because we have multiple sessions my session is different from your session if i go there if i go to the bob site three times i will have three different sessions this is great uh however this isn't um even though this is still very useful to bob and while bob would be able to find what he's looking for it's not useful enough in fact as we start looking at what the data looks like next here we see sessions are good for the big picture but they're too broad for debugging um here we have four traces in a six second session but this isn't immediately useful and if we were to impose all of the events on onto this graph like so this is a waterfall chart it shows the different traces it doesn't show all of the user events if we were to impose all of the user events on here we would maybe be able to guess which events led to which but that would require some special inference on on the user side and that's not immediately useful so how can we organize them so we came up with chapters chapters are similar to many sessions uh it connects one single trace and all all of the spans that are composed within that race one single trace with all of the events that lead up to it so a session is large and will have one or more chapters but a chapter is a specific set of events that lead up to a single trace so whenever the client sends a new request to the server that would start a trace it creates a new chapter id and with that we're able to now have two forms of of identification and so next we're going to show what that looks like now we have the data is organized so these events lead to this trace these events lead to that trace these are organized into chapters so it's all neat and orderly and next when we focus on a single chapter we're able to see what does that look like so here we have a chapter in all of the spans that are within that we have the waterfall chart it has the durations and the nice graph format we have the we have the spans on one side that were related to it as well as all of the events that are specific to what led up to that chapter so uh next we have figured out how we're going to or how we're going to organize and collect the data now we have to talk about how we're going to store it so what are our data requirements so the first so the big problem here is we have a lot of data high right volume our users are going to be creating well that the customers that above app are going to be creating a lot of user events this is a ton of writing hopefully it's not going to be so much reading so we need a database with a high emphasis on write speed but not as much on read speed however read speed however reading will still be kind of involved so we can't just not have that we can't just dump it all we also have structured data our data fits a relationship like schema it's not a key value store and while we did use mongodb early on for just storing data document stores aren't going to work with it aren't going to work nicely with the kinds of queries that we're going to be running and then lastly it needs to scale really well um every single user is generating a lot of traffic as bob's app grows as he adds more web servers he's going to also need to add more database clusters to handle this load so there needs to be something that can scale really really well with that so we had a few different approaches that we investigated in our solution next is to use cassandra cassandra offers us several benefits it offers us the the write speeds that are afforded by a nosql database there's no crosstable operations however that even though there are no cross table operations it's not a document store it stores the data in a tabulated format it stores data in a row column format that is very similar to postgres or other sql environments in fact it's a sql like nosql database solution uh it also scales linearly bob can add new nodes to the cluster very easily uh he can just if he needs two times the amount of traffic he can just add twice the amount of nodes or even just it just doubles the amount of nodes and he has doubled the amount of performance it is actually that easy whereas with traditional relational database schemas that's difficult that's when you get into database sharding that's when you get into into into partition schemes a lot of that is handled for you with cassandra when you set up the schema you set partition keys and it's home it's its own thing but then day to day performance bob doesn't have to worry about that bob just adds new nodes onto the cluster so then lastly we are going to talk about the ui optimization uh we want our application to be very useful to bob uh so next we'll talk about this is we want this to be very useful to bob we don't want it cluttered with unnecessary features we want it easy to search we want simple succinct and useful uh this means that everything has a purpose everything has a place bob needs to be able to search we're not just exposing a database console we are we're giving bob the tools he needs to search through the data this is really important all of the traces all of the spans sections chapters these are all identified by very long incomprehensible strings even though he's looking for for ivan gmail.com that data is stored nested within a data structure that is stored within several layers of identifying strings and those aren't easy to write queries for manually we don't want bob to have to deal with that we don't want him to have to learn a new query language uh he needs to be able to search very easily and so we offer that and here we just have an example so when bob is looking at the spans we have filtering options we have that exporting options if he clicks on a span it shows the span details over on the side and that offers uh that offers top-down view it offers details and if that's not enough he can click on the chapter id or the session id depending on whether he's looking big picture or smaller picture and this lets him navigate to the problem he's looking for very very quickly now we're actually going to talk about this a little bit more um in order to do that we're going to have hold and give us a demo thanks nicole yeah um as i mentioned previously there is two more demonstrations of how you would use retrospec or slightly different use cases the first one a service is down the initial demo was a front end error possibly a back end there this one one of the services is unavailable so we can see the customer going to check out again note the email shipley gmail.com we are going to reference that later and as uh earl mentioned we're not recording with a video we use dehydrated dom snapshots you can see the checkout fail so now what does bob do bob goes to span search and instead of searching by request data bob can also search by the date of the span he knows that the checkout failed recently so he could check for i want the most recent spans that are after uh three o'clock on july 30th when he received the complaint you can sort by the date of span and because retrospect also shows you the status codes he can then look for a 400 or 500 level status code which he expects will be the cause of the failed checkout and again we can confirm we're looking at the right email with shipley gmail.com so next bob clicks the chapter id and we can see that same waterfall chart we can also see the list of spans associated with that chapter and open the one that has that 503. now bob knows it's probably the last span so he clicks on that last one and we can look at it more closely we can see that it returned a 503 the service was unavailable and we can confirm it by looking at the span tags this lets bob know why did that checkout process fail it's because one of his services was unavailable this would be extremely hard to debug without something like retrospect because if the service comes back up in between the time of the complaint and when bob starts to debug there would be no record of the service having gone down you wouldn't see that failed request the next situation the payment service is delayed uh we mentioned this earlier that waterfall chart can tell you how long did a service take to complete in this case someone named dale gmail.com is trying to check out note that we've sped up the gif so it'll only seem to be a two second delay but really it's a five second delay this could also be 10 seconds 30 seconds etc now what does bob do he can search the request data for that email in this case all he needs is dale and you can see immediately on the chart that something looks wrong it looks a little bit too long and so bob goes into the chapter id view which we see here and it should be immediately obvious which service is causing the problem it's that payment service so when we restart the gif you'll be able to see bob sees the waterfall chart clicks the extra long span and when you look at it you can see the time duration was five seconds exactly as we said and if you go into the span tags you can see more information like which service it was sent to giving bob a good place to start debugging now next i'll turn it over to stellana to talk about installation awesome thank you all right let's start with the client side first so what bob has to do to instrument the front end is to install our client agent with npm and he only has to do that on the client the second step is to update the uh the config file here he will have to update the endpoint to point to the api that earl was uh talking about um this this will send the front end uh data to the uh to the api uh step three is to update the index.js file here uh bob will have to import the recorder uh from the client agent package and start it uh to um add the client agent to the serv to the server side bob will have to do four steps step one is to install the server agent on on the back end to capture traces step two is to update the uh the con the config file here too here he will have to update the um service name then he will have to update the db options to a true if he's going to use a specific uh database option and then step three is to update the um the end point to allow spans to be sent to our api um that he he did for the for the client agent as well uh step three is to update the index.js file here bob will have to import the server agent into his startup file and use it as middleware and then step four uh bob will have to update the start script of his server to start the tracing file before starting his server startup files so this would be his index dot js file um the last thing bob has to do to d to deploy our tool is he would have to use docker uh to to do that there are two easy steps first you will have to download the uh docker compose um file and just run docker compose up and then he will be able to see our ui on port 32 100. and that's pretty pretty much it this takes us to the end of our uh section and we will take your uh questions down okay we already have one question so i'm going to read it so capturing every dom change for each of your users sounds like a very high volume data transmission exercise and you explain the storage benefits of cassandra in dealing with high volumes data quite well how does retrospect think about minimizing the amount of data sent over the wire as well as keeping request response cycles as short as possible yeah i can take that um if no one else wants to we approach it from a couple levels the first is that just just to be clear i think you understand this but we don't do a full dom snapshot every time there's a change to the dom there are full dom snapshots at increments but in between then it only registers individual changes like small changes to the dom so that when we build the session replay it has those snapshots and then it applies the changes in sequence before you get to the next snapshot that helps significantly reduce the size of the data that we send second you can can configure the recording settings so that you don't record the most uh active type of events for example you might have noticed in the session replay we don't record all the mouse movement those are especially egregious in terms of generating lots and lots of events so by default we configure our web to not record them and the third one is the size of the data and that's being sent is actually very small we have some statistics that we generated for testing this and in terms of consuming cpu time the self time of the longest session recording operation is about four milliseconds which is below the human noticeable range and our effect in the lighthouse score for bob's application was only a reduction of one point i hope that answers your question okay awesome so elizabeth said excellent job team retrospect and lena said amazing presentation if you had more time what kind of work would you like to implement oh yeah go forward for lana i was gonna mention one uh piece so um i believe we uh briefly mentioned it so we would like to give bob the option to show him the specific line of code that is throwing this kind of error so we do want to add logs uh in the um future okay nicholas says great answer thanks glad to see some benchmarking and then mark asks why cassandra over sure and so i'm happy to talk about that so offers great for document writing however we want to query data our data fits a very relationship like schema because every event is going to have a chat id and a session id every span is going to have a it's probably going to have a parent span id it's also going to have a chapter id and a session id we want to query based on those and with the amount of rows with the amount of data that we're going to be storing with a document store we would have to search through the kinds of queries we'd have to go through would not be desirable we want to be able to write a query like select from this where the id is equal to an id that we provide and it's having a relation having a relational like data structure helps us with that i hope that answers the question okay laura asks what was the most challenging part of the project oh man um as a one of the hardest things that wasn't coding related was deciding where to stop because it felt like there was always more and more interesting ways you could use session replay or more and more advanced ways to apply that back end tracing that auto instrumentation and being able to say like no we can't add any more features that was definitely difficult okay it looks like we don't have any more questions so anyone oh so yeah we do have actually so the first question is how did you do the screen recordings um yeah so we used a session recorder that uses the mutation observer api in the browser that records every change to the dom uh so it creates a basically a buffer of events um that have changed what the user sees in the browser and then it emits them periodically which we then export to our database and then later uh when we're trying to provide the session replay we collect those events that list of changes with those the snapshots of the dom and then we uh send them into a special replayer object we didn't we didn't build every player object just to be clear um that takes those and recreates what the dom looks like the way it's phrased is dehydrating the dom reducing it to text and then rehydrating it um basically reapplying the html or the css processing so it looks like the user interface okay so next question what process did you use as you build the project well i can talk about that um we took an agile approach we used a pivotal tracker that we stayed on track of this helped each of us because for most of the project we separated things into i'm going to work on this part you work on this part you work on this part and sometimes this would overlap greatly so keeping things as far as so this story blocks the story that was helpful um and it it also helped keep each of us have a list of what are some next things that we can do what are some next concrete goals that we can work on to help further the retrospect or retrospect project yeah i think the um that trello clone project was uh in incalculably beneficial in terms of teaching us how to create concrete stories that let us work more effectively okay so this is a question for each one of you so what was the most rewarding part of working on this project um i would say for me the best part was sharing it with different people and seeing how um you know how how they think of it and the and the kind of feedback that they share with us i definitely enjoyed working with all the data working with the api server i got to write a highly performant api server with golang and i found a lot of personal appreciation for that and i also got to work on putting the cassandra cluster together right that was just a lot of fun for me i really enjoyed this work for me i'd say my favorite part was working alongside working developers to try to get the correct features in and also um you know working with the ui you can see your um work immediately whereas uh for back end work it's not as apparent so uh yeah working with optimizing the ui's features was very rewarding yeah i um i definitely agree with with all of those my i think my favorite part is like getting to work with a small team on a hard problem uh it's i don't know i i played a lot of team sports and i was at a small startup before this so it feels really good to be like we have this maybe impossible problem we don't even know if we can do this but there's four people putting their heads together trying to figure it out and if you don't know how to do it you know there's someone else who is also really really good like trying to solve it at the same time and that's that's so satisfying to work through very nice so oven says really impressive work guys it's easy to see how useful the tool like retrospec would be especially for complex microservice apps microservice apps so a question client-side input can contain such sensitive data like passwords credit card info and so on are there any measures you build in retrospect to secure sensitive user data yeah i could take this one um so we used our r web um for recording the session data and our web offers a class you can add to inputs or elements in your html that would essentially block it from being recorded as you saw from the saturn recording of um ivan jones's session uh his credit card info the input boxes were grayed out so someone like bob can add those classes to his html elements to block him from being recorded okay awesome work once again yeah thank you so much everybody for coming thank you for coming you 