alrighty thank you guys for coming out tonight today we're going to talk about building echo and echo is a real-time message processing framework and don't worry we're going to jump into exactly what that means before we dig in though just a quick intro to our team uh we're an incredibly spread out team but this ended up being a pretty good opportunity for us we were able to learn how to effectively collaborate remotely and you'll be hearing from all of us throughout the different parts of this presentation a quick overview over what we'll be covering we'll start off by talking about real-time web applications and after that we'll spend some time explaining why real-time web applications often need dedicated real-time infrastructure next we'll go into why real-time web applications often also need real-time middleware and we'll explain what that is next we'll do a quick demo of echo so you can see what it actually looks like for a developer to interact with it and after that we'll spend some time digging into some of the more interesting engineering challenges we tackled finally we'll wrap up with some resources for anyone who wants to learn more about echo so first off let's talk about real-time web applications real-time web applications are everywhere they're all the live dashboards we see they're all of the apps that show you the driver location or the package location on a mac and they're all the chat apps that we use these are just a couple examples when it comes to actually defining what a real-time web application is everything centers on this idea of the user's perception and this quote sums it up pretty nicely it says a real-time interaction has a human angle because one of the collaborators in any real-time data exchange is always a human hence the human perception of a real-time event is very important and this feels like a bit of a loose definition but because web applications are primarily concerned with the user experience it's actually the only definition that's really relevant and it does lead us to some useful insights now the first insight is that we have to shift our idea of how data is transferred so if we go back to a traditional http request response cycle we have this idea of pulling data and with polling data we have data that accumulates somewhere usually in a database and it just sits there it doesn't go anywhere it doesn't really go anywhere until a client explicitly makes a request for the data and then the server responds with the data and that's why it's called pulling data because the client has to pull the data to them by making these explicit requests and this is distinct from a data push pattern and with the data push pattern the client often does start off with a similar request but the difference is that the client is requesting new data to be sent as soon as it is generated and then so now we have new data that's generated and it's immediately sent to the client it doesn't accumulate anywhere and when we think about real-time web applications pretty much everything follows this data push pattern and that's in line with the idea of things being perceived as instantaneous so going back to kind of a simple chat example it'd be weird if you had to click a button to see if there are new messages for you you expect them just to show up as soon as they're ready and another interesting insight with real-time web applications is that we actually move away from the server client model and so the server client model it's very focused on the actual devices being used but in real-time web applications it's much more useful to focus on the roles that these devices are being used for not the actual devices themselves and this leads us to the pub sub pattern and so here you'll notice that we're no longer talking about servers and clients we're talking about publishers and subscribers and so on the left we have a single publisher and they're sending messages to the subscriber on the right and that actually leads us to another interesting insight we're no longer calling data just data we're calling it messages when we talk about real-time web applications and messages really are just bits of data so it could be an actual text message but it could also be location data or any number of things and it's called messages because once again we're moving away from the implementation details and focusing instead on the actual roles being played and so expanding on this we also have this idea of one to many pub sub models and this is another fairly common pattern and so here we still have a single publisher on the left but now we have three subscribers on the right and as the publisher generates new messages it sends them to the subscribers and expanding on this a little bit further you can imagine that we can also have a many-to-many pub sub pattern and this is a possible pattern and there are specific protocols such as webrtc which are peer-to-peer protocols specifically for this type of setup but you can see things can get kind of complicated pretty quickly just because of how many connection connections there are and so for many to many pub sub it's actually much more common to have a central hub and with this pattern each of the publishers in each of the subscribers has a single real-time connection to the central hub and when a publisher sends a message it goes to the hub and then it gets emitted to all relevant subscribers and just for one final idea that comes up often in pub sub messaging we have this idea of bi-directional communication and up until now all of the devices we talked about were either a publisher or a subscriber but within real-time web applications it's actually very common for devices to be both publishers and subscribers and it kind of makes sense once again going back to the chat example whenever you send a message or a publisher and whenever you receive a message you're a subscriber and here we're showing various devices who are both publishers and subscribers and when one of them sends a message it goes to the central hub and gets submitted to all relevant subscribers so now let's imagine you actually want to implement a real-time feature in one of your applications now we'll start off with a fairly simple example we'll use the example of a customer service chat box and we'll start with a simple use case and kind of build up to the point where a lot of people do end up when you realize that managing real-time connections can be very difficult and often needs dedicated infrastructure and so when you actually start off a lot of times you might do some googling or searching around for real time and when you do that you'll often run into these different protocols and this isn't an all-encompassing list but these are definitely some of the more common ones that come up so there's quite a few http derivatives such as server sent events http long polling http streaming and then there's webrtc which is that peer-to-peer protocol we already talked about and then there's web transport and web sockets so now referring back to what we talked about previously we know that for a real-time feature you're going to need a data push pattern and all of these protocols do support that but since this is a customer service chat feature you know it's going to need to be bi-directional so you can both send and receive messages to customers and that rules out pretty much all of the http derivative and there definitely are some hacks and workarounds to get this to work for bidirectional communication but it's not the typical use case they're all primarily set up for one directional communication and next you realize you already have a central application server whatever is running the actual application you're adding the customer service chat to so it kind of makes sense to stick with that pattern instead of trying to implement a whole peer-to-peer network to work on top of and so using a central hub rules out webrtc which is a peer-to-peer protocol last but not least it's probably a good idea to use something that's been proven in production and that rules out web transport which is a super interesting technology but it still is an emerging technology that hasn't been fully fleshed out yet and so that leaves you with web sockets and that probably makes sense websocket is definitely the most common way to implement this type of feature into a web application so let's say that you're actually going to jump in and start building a proof of concept it's actually surprisingly simple to get up and running you can just open up your own application code and add a websocket library such as socket io and that's pretty much it it's fairly simple to get up and running now there are quite a few challenges that'll arise though if you either want to start adding more real-time features in or if you want to use this in production now the first thing you might run into is the problem of adding additional real-time features and this can be additional real-time features in the same application such as adding location data or live dashboards or translation or it can also be multiple real-time features that are the same just across different applications and in either case you'll find yourself spending less and less time on your actual application code and more and more time just figuring out the actual real-time infrastructure needed to support this and that's a negative pattern to fall into now another issue you might run into is the issue of scaling if any one of your applications becomes very popular and it grows to the point where it can't scale on just a single server and it needs to split out into a horizontally scaled architecture this makes things significantly more difficult because there's a few reasons one of them is that just the technology of websockets is more challenging to work with across different server instances and we'll dig into some of the details of that later but there's also the issue of the pub sub model and trying to manage and synchronize all the publisher data and subscriber data and message data across different server instances one final thing you might also notice is you might realize that your application needs scale at a different rate than your real-time needs and so all of these things kind of point to the same thing they point to the idea that managing real-time connections can be very challenging and that if you plan on actually using a lot of these in production it's often a good idea to have dedicated real-time infrastructure and that's exactly what these companies do these are some of the leading companies that provide real-time infrastructure as a service and so for people who don't want to do it all on their own and they don't want to build their own infrastructure you can just use one of these companies to handle all the real-time infrastructure and these companies all pretty much advocate the exact same thing they all advocate the idea of decoupling the real-time infrastructure from your application now if you actually continue down this path and start adding more and more real-time features into your applications you're going to run into another idea and that's the idea of real-time middleware and for an example if we take our customer service chat example once again realtime middleware could be something like translation so if you get to the point where you have a bunch of customers of different countries and you want to add support for these different languages real-time middleware could be something that actually intercepts the messages translates them into whatever language is relevant and then sends it back out to the customer and so that's the idea of real-time middleware something acting in the middle of the message sending process and some other examples are things like when you open up an uber app it doesn't show you every driver in the world it just shows you the ones that are nearby there's some filtering going on additionally for in-game chat there's often profanity filters and so once again the messages are going to and from individual users but somewhere in the middle they're being filtered out if there's anything offensive and then for things like chat bots this is a screenshot of amazon lex there's a lot of analysis happening on the actual messages so that the actual bot knows what to respond with and we dug into this a little deeper and we found that there's actually quite a few different categories of real-time middleware and they're also used all over the place and so some of the common ones are message transformation where the actual data and the message is being changed in some way and then there's message enrichment where based on the data and the message other things are added into it and then there's things like message filtering and chat bots which already talked about and then messages are often also used to feed into data analysis or to trigger alerts and notification and all of these are kind of the same idea somewhere in the middle there's some business logic being applied and this pattern was also recognized by pubnub enabling so pubnub has a great quote where they say you see everyone publishing down to their server doing a small bit of processing and then publishing the message right back out it doesn't make sense and abele has a similar quote where they say a common requirement in real-time messaging applications is to be able to insert some business logic into a message processing pipeline and so both of them recognize this anti-pattern in their customers where the customers were using their service so they had set up dedicated real-time infrastructure but then they needed to do some sort of business logic and all the messages so all of a sudden all the messages from this and real-time infrastructure hub were being sent down to their own application servers to do this little extra processing and then sent back out so even though they were physically decoupling their application servers from the real-time infrastructure they pretty much just recoupled them and they had to make their own infrastructure as scalable as the real-time needs and you just kind of get right back into that negative feedback loop where you have to support all the real-time scalability needs and so both pubnub and abele came up with solutions for this so pubnub came up with pubnub functions and these are proprietary serverless functions that you can write and deploy within your pubmed dashboard and ably took a little bit of a different approach they let you create serverless functions on one of many different function or serverless function providers and then they integrate those into your ably pipeline and so in both cases the end result is pretty much the same though it's removing the business logic from your application code and putting it somewhere else now we did think it was interesting that these are two of the major companies they both recognize the exact same problem but they solved it in very different ways with pubnub taking an internal solution and able using an external one and so this is kind of the landscape of options right now if you want to build real-time features and add them to your applications you can either use a third-party service you can use an open source solution or you can do it yourself and each definitely has different trade-offs and the right choice does depend very much on your specific use case so for example if your goal is just to have something that's easy to get up and running you probably should go with a third party service those are pretty easy to set up now there are definitely some open source solutions which are pretty simple but these definitely vary on a case-by-case basis now if your goal instead your main priority is to have complete control over your data and over the infrastructure then you're going to need to go with an open source solution or a do-it-yourself solution now if you want to use real-time middleware things get a little interesting as we showed not all the major providers actually offer real-time middleware out of the box and if you do use one that has that you still will have to give up some of your control and currently we did a bunch of searching and currently there are no open source solutions that have real-time middleware out of the box either and you can obviously build pretty much anything yourself but this is a particularly ambitious undertaking and because there was no clear-cut obvious choice for this specific set of criteria this is the area that we decided to dig into which led us to eventually build echo and with that i'll pass it off to drew thanks well so we saw a gap in the market and as a result we built echo echo is an open source framework that you can use to deploy your own real-time infrastructure with real-time middleware so there are four main parts to echo the first is the echo server and this manages the real-time messages for your applications the second is echo functions which provide that real-time middleware for in-transit message processing and then we have the echo cli which makes it easy to manage echo functions and spin up and tear down the echo infrastructure and the echo client enables you to build real-time applications on top of the echo server because echo is open source and self-deployed you have complete control over the infrastructure you can customize it to your needs and you don't have to rely on a third party to manage your real-time data so now that we know what echo is let's try it out first we'll spin up our own echo infrastructure with our cli tool so the echo cli tool provides us with several commands that we can use we can add a help command to the or help flag to the end of a command and it'll show us the documentation for that command here we'll run echoinnet and we'll input our aws credentials and this will spin up a new echo infrastructure for us using the aws cloud development kit so this process normally takes 10 to 15 minutes but we've sped it up here it will also create a new echo directory in our current working directory and it's worth noting that you can tear down your echo infrastructure just as easily with the echo teardown command so now that we've spun up our infrastructure let's take a look at it so here's our echo infrastructure we have our echo server on the top right there and this is a node application that's deployed in a container on aws elastic container service on the left side there's an application load balancer and this distributes websocket connections to our echo server on the bottom there's an s3 bucket and an elastic cache instance we'll learn a little more about the role that those play later but for now what's important to know is it's that this echo server is what manages the real-time messages for our applications so now let's set up a real-time application that uses the echo server to manage its real-time messages recall that when we ran echo init it created an echo directory in our current working directory and there we have echo functions and echo apps we'll look at echo functions later so within echo apps we have a few demo applications and these are designed to help a developer become familiar with building real-time applications using echo we'll be using the chat demo application here and it consists of a basic html file this html file runs a couple of scripts the first is our echo client which is stored on a cdn and the other is this script js and in this script we're creating a new echo client instance and this will allow us to connect our chat demo application to our echo server that we just deployed so the echo client instance takes a handful of parameters an app name a host a json web token and a uuid we've already set our app name to chat demo and we'll generate the host and json web token values with our cli tool the uuid is optional so we won't worry about it here so back in our cli tool let's generate the host and json web token values we'll do this by running the echo jwt command and pass in the name of our application as the argument so it outputs a few values the first being that echo server endpoint and this is the url of the echo server that we just deployed and again it will allow the echo client to connect to the echo server and send real-time messages to it the next value is this user json web token and this is the value used by the echo server to verify that our chat um our chat demo app is indeed a valid echo client and that last value that the cli output is a admin token this is for an application server it enables an app server to connect to a special admin channel and get status events but our simple chat demo here doesn't need an application server so we're not going to use this value so now that our chat demo app can use the echo client to communicate with the echo server let's go ahead and test it out to do this we'll open our html file in two different browsers to simulate two different echo clients both of these clients are subscribed to four different channels that we can think of as chat rooms boring angry backwards and robot when one client publishes a message it's sent out to our echo server that then emits that message back out to all subscribed clients which in this case is both of them so now let's take another look at our infrastructure and see what it looks like when we have these two clients connected to our echo server sending real-time messages to it you can see that we now have these two clients connected to our echo server when one client publishes a message on the borrowing channel it goes out to the echo server which then emits that message back out to the subscribed clients so we've seen how an application can use the echo server to manage its real-time messages let's go ahead and deploy some real-time middleware to process these messages in transit so first back in our chat demo app we'll switch to the angry channel and here when we publish a message we expect it to be transformed capitalized with exclamation points added but we can see that's not the case in order to process our messages in transit we need to deploy echo functions recall that this echo functions directory was created when we ran echoinnet in it we have a handful of demo functions that are designed to go along with our demo applications and help a developer become familiar with creating this real-time middleware we'll check out the demo angry function here and you can see that it has a specific file structure and format so that it can be deployed to aws lambda you can see here that our demo angry function simply takes the message payload capitalizes the text and adds a few exclamation points so now that we've seen how these functions work let's go back to our cli tool and deploy them so with our cli tool we can change to the echo functions directory and we can check the status of our functions and we see here that none of them are deployed we can easily deploy them by running the echo deploy command and what this does is deploys those functions to aws lambda where they can run alongside of our server we'll run the status command again here and we can see that those functions have been deployed so there's one more thing we have to do we need to run updateassociations.json and this is a file that the server uses in order to know which functions are associated with which channels we'll go into a little more detail on associations.json later so back in our chat demo let's see if these deployed echo functions work and they do we see that our real-time messages are being processed in transit note that we didn't have to refresh the browser and we didn't have to update any client-side code or any server-side code instead we use echo functions on our local machine and deploy them to aws lambda to do the processing so there are many benefits to implementing the real-time middleware in this way and we'll get into that later but for now it's apparent that echo functions make this easy to create deploy update and destroy these lambdas so now let's go see how these deployed echo functions work within our infrastructure we can see on the right the echo functions that have been deployed to aws lambda when a client sends a message on the angry channel the server gets it and sends the message to the angry lambda for processing and then sends it back out to subscribed clients the same happens on the backwards channel and the robot channel the server knows which lambdas are associated with which channels using that associations.json file that we mentioned earlier so now that we've seen what echo is and how it works i'll turn it over to dory who's going to talk about the engineering challenges that we faced while building echo thanks drew the engineering challenges we faced while building echo fell into three categories the first was how to implement echo functions a real-time middleware specifically what technology we used the second challenge was how to manage the data for linking specific echo functions with real-time messages and the last was how to make sure that echo could scale up as load and demand increased which alex will explain so let's start with the first engineering challenge implementing echo functions we needed to figure out where to handle message processing where do we put our real-time middleware we're definitely not going to put it on the echo client because that introduces security concerns and performance problems but we could put it on the echo server however the echo server would have to be redeployed every time the middleware was updated we'd also be coupling various unrelated pieces of business logic that would need to scale up and down based on independent needs furthermore we'd like to keep our separation of concerns and let the echo server just manage real-time connections we could put echo functions on a server dedicated to message processing it's still within our real-time service but separate from the echo server however we'd introduce all of the same problems from putting it on the echo server we'd be redeploying the server for every update and coupling unrelated pieces of logic another possibility would be to use serverless functions serverless functions allow us to break up business logic into individual pieces that can scale independently imagine we have a chat app that is using the echo server and filtering out profanity from all of its messages we also have a geolocation-based app that needs to hydrate real-time messages with directions obtained from the google maps api these two apps are both routing messages through the echo server but their needs are unrelated they have bursty traffic at different times if we use serverless functions as our real-time middleware we can scale the profanity filtering up without affecting the directions processing and vice versa serverless functions also provide flexibility they can be reused across multiple apps when functions are updated or added the rest of the real-time service is not affected so what exactly are serverless functions serverless functions are pieces of code that are managed by a cloud provider which is responsible for dynamically allocating resources to execute that code serverless functions are modular and reusable they are independently scalable they spin up on demand they are ephemeral and they are easy to package and deploy however they can't do heavy lifting there are maximums for length of compute and size of payload they add complexity to your infrastructure they live on servers with other people's code they have a cold start and can take longer to execute if spinning up for the first time and they can be harder to test and debug but let's go back to our use case which is many publishers and many subscribers needing to process messages in transit on demand without interdependency or a need to keep track of state our goal was to provide a flexible framework to accommodate changing business needs for these reasons we thought serverless functions were a good fit for our real-time middleware and as will mentioned before this also happens to be the way that abele and pubnub both handle message processing in their services now let's move on to the second engineering challenge how to manage echo functions once we determined where our real-time middleware would live we needed to figure out how to manage it specifically linking middleware with real-time messages since clients publish and subscribe to channels it made sense to link specific channels with specific echo functions so if you're making that chat app that uses a profanity filter you can create a channel and have all messages published to that channel be processed through the profanity filter all subscribers to that channel will receive the processed message at this point we wondered about the possibility of needing to use more than one echo function to process a message for example what if you now need to translate that same message in your chat up to another language you can chain the echo functions so that the processed message from the profanity filter will pass through the language translation function before returning to the subscriber the next piece to managing middleware was deciding how to store channel middleware associations we decided on using a json file here is a sample of our file associations.json it is organized by applications each application has an array of channels and each of those channels contains an array of echo functions to be used for that channel echo will process the message using all of the specified echo functions in order before returning the processed message to the subscribers the json file lives on an s3 bucket which is an aws cloud storage service the developer would be responsible for manually updating it locally and then uploading it with the echo cli tool we decided to just cache the association's data on the server since it didn't change very often but we needed to figure out how to update the server nodes when a change was made to the json file we looked at two ways for pushing the data to the echo server the first was to use the aws service cloud watch to send a message through sns another aws service notifying the echo server that a new set of data was available to load the second was to update the echo server directly at the same time that we upload the new json file to the s3 this would involve sending a put request to the echo server with the json file as the payload we could just add this behind the scenes in our cli tool when the developer uses the echo update command and this was the option we chose since it didn't add any complexity to our infrastructure now i'm going to show you a little demo of how to chain echo functions first we're going to create a new echo function we'll call it demo emojify this is going to create a new folder in the echo functions directory and we'll open up the index.js file to write our message processing logic for this function we'll add an angry emoji before and after the message text and then we'll return the processed message using the cli tool we deploy the new echo function to aws and we can see that that was successful now we need to edit our associations.json file we're going to add demo emojify to our angry channel right after the echo function called demo angry the final step is to update echo with our new associations.json file using the update command as i mentioned before the associations.json file will be uploaded to the s3 as well as sent in a put request directly to the echo server let's take a look and see echo function chaining in action in our demo chat app let's see what happens when we publish a message to the angry channel as you can see that was successful it capitalized the message using the first echo function and added angry emojis using the second before it returned the message to the subscribers and with that i'll hand it over to alex to talk about our final engineering challenge thank you dory so the last of our engineering challenges that we want to mention relates to how we set up echo to scale horizontally we wanted echo to be able to scale up and down as needed and of course some of this was achieved by choosing the appropriate infrastructure and policies on aws the main part of echo that needed to be able to scale were the echo servers we needed to support a flexible number of users connecting to the real-time service as well as an increased volume of messages being published in order to be able to scale flexibly a pretty attractive option for horizontal scaling was to package up our server application as a docker container and then use aws's fargate service to scale those server tasks up and down according to how tax the particular task instance became now fargate scales according to rules that take into account how much cpu and memory each container is using it's not always completely transparent to use but it did handle our core problem that we were trying to solve of wanting to horizontally scale our echo server functionality but there were some other additional problems we had to sort out our first challenge when scaling up to multiple instances was getting our clients to establish websocket connections our application load balancer is going to take incoming connections and pass them on to the next server node in a rotating list of available server beds establishing a websocket connection is a two-part handshake using http requests with a default configuration of our load balancer though the first part of that handshake gets routed to one server node and the second gets help routed to another we weren't able to establish our websocket connections when we first tried out our infrastructure on aws for this reason given that we're using fargate though the solution to this problem was to add some configuration to our cdk deployment code we needed to enable sticky sessions as a policy for our managed server instances and then each echo client could be routed to the same server instance it was initially assigned and we could successfully establish websocket connections once we had established these websocket connections we encountered a new challenge messages being published to separate servers weren't being broadcast to all of our subscribers if we have two instances of our echo server the load balancer is going to connect one user to server instance a as you can see here on the top and the other to server instance b below in this scenario they are both subscribed to the same channel so they can chat with each other alice has a websocket connection to server a and when she publishes her message server a receives it and publishes that message to the channel so that all subscribers will receive it however only the websockets connected with server a will get that message so bob won't receive it since he's connected to server b in order to solve this problem we use the socket io redis adapter library this library uses a redis instance hosted on aws's elastic service to broadcast events to all of the socket i o server nodes alice's message published to server node a is automatically emitted out all of the subscribers even though some of them are connected to other servers with this infrastructure setup and with sticky sessions enabled we did some load testing using artillery.io to validate some of our main use cases our first test scenario was that we wanted to make sure we were able to sustain reasonably high volumes of messages published through the echo server to this end we tested and learned that echo is able to sustain 50 000 messages sent per minute each of those messages is also in turn transformed by lambda functions so that's our serverless middleware and for our test this amounted to a total of half a million messages and lambda function invocation was sent over the course of 10 minutes during the test aws elastic container service spun up two additional echo server containers to deal with this extra load for our second test scenario we wanted to make sure that we were able to support many subscribers receiving messages echo is able to sustain six hundred thousand messages received per minute published to a single channel we were really happy with these numbers and actually these loads didn't max out our server capacities or cause failures so we probably could have kept increasing the load even further but it didn't seem like our use cases demanded that a final engineering challenge we encountered was figuring out how to synchronize state between all of our echo server instances we needed to ensure that all of these server instances had the latest version of the associations.json data which pairs channels with the echo functions that will execute on all associated messages passing through when updates are made to the associations.json file we let the echo server know by sending a put request with the new association's data as the payload however again we have a problem the request will be routed to just one of our echo server instances we need to be able to notify all of the echo server instances with the updated data as you can see from the animation our put request does update one of these server container instances but this update isn't shared with the others and our solution to this was to use the standard redis package the server that receives the message publishes the file to the redis elastic cache cluster and all the other server instances in turn are subscribed to the redis cluster and receive a copy of the new association's data this is what allowed us to keep our server instances in sync and share the association's data among all of them and that's echo an open source framework allowing developers to easily add real-time infrastructure and in-transit message processing to web applications and by this point i hope we have shown you how flexible echo is to work with the possibilities available to you are many as you can see from some of the examples above the combination of a real-time server with serverless functions as a kind of middleware for in-transit processing and messages offers a rich palette of options we look forward to hearing what you build with echo you can test drive our code and demo applications by visiting our github repository and our case study will be available on our webpage soon as well and with that we welcome any questions you might have okay our first question came in what was the biggest challenge building echo for each of you i can go ahead and answer that i found that the biggest challenge came when we deployed we started working with the aws infrastructure and debugging problems that arose was really challenging so often what would happen is our server instances would just start dying and we'd have to figure out what the problem was and it was a team effort because sometimes i remember one time it was something in the cdk code and another time it had to do with the echo client and another time it was the echo server so um so that was a challenging part of the development process i found i think for me the most challenging but also one of the most fun uh challenges we tackled was figuring out how to update that association's data in all of the server instances and if you think about it's kind of a weird challenge because we're storing that in memory so we're not like hitting a database every time it's like actually just stored in a variable and so figuring out how to do that on demand was pretty tricky and we tried a ton of different things and at one point we had like echo client installed on echo server and it was kind of crazy um so i think our final solution of um using that whole put end point to redis subscription thing was pretty elegant and seemed to work really well so that was a really fun one to tackle yeah for me um it wasn't the biggest challenge but i just thought it was an interesting challenge when we first started building echo we had to build the echo server and the echo client and it it's like we mentioned it's pretty easy to build a real-time application with a library like socket io but we had to figure out how to build a platform that would enable other developers to build real-time applications using our platform and so that was just a way of thinking about building software that that was was completely new to me so it was an interesting challenge i think for me the biggest challenge uh since i was working a lot on the infrastructure part was actually just dealing with some of the aws documentation for cdk which um in parts was like really opaque and difficult to find exactly what you wanted and you know you ended up having to read just like literally everything to find something buried deep in a forum pose that was available nowhere else so yeah a lot of kind of line by line reading like reams of cdk documentation i think was was the big challenge that i found uh our next challen uh question um comes from uh well i didn't give the name but um what was your favorite most favorite or most rewarding part of building echo so for me i think it was um we split our project eventually up into four parts where we all went we worked synchro synchronously for a while and then we we split up and i worked on the cli tool and that was a really interesting rewarding process because at first i just had no idea how to do something like that and it had to do a lot it had to use cdk to or the cdk code to deploy our infrastructure work with the amazon web services sdk send requests to the server and you know manage echo functions so there was so much behind it and it seemed like this insurmountable thing to build and then you know just step by step learn learning by doing um it wound up not actually being that crazy and we found a good library to do it and it was just a matter of working with aws sdk and using javascript code to make that all happen thanks for building my oh sorry go for now uh from my perspective um i think i really enjoyed the kind of ideation part uh before we started building echo kind of generating ideas for the project we went got to go down all sorts of rabbit holes that um that had come up during the earlier bits of capstone um yeah i really enjoyed that reading up on just coming up with different ideas uh and of course i think like working with um with my teammates uh that was a really kind of edifying part of the project i feel like we spent a lot of time together what i really enjoyed i remember um i sort of was getting to a point after we had split up where i was sort of ready to transition into some other bits of the project and i did a lot of the initial work on that simple little chat demo that we used throughout this presentation and i remember when i downloaded the cli code from npm and like install that on my machine and use it to like deploy lambdas and actually like build this app and it was pretty mind-blowing like it felt like a real thing all of a sudden um it was cool because i realized like in that moment my brain totally flipped over where now it went from like what are the bugs we have to solve and all of a sudden it switched into like what can i build with this tool and that was definitely this like super super gratifying moment that um that i don't know if i've encountered with any other projects i'd built before this so it's definitely that fun turning point uh yeah i echo all of that echo the the teamwork part was really great um and i also enjoyed uh working with the um aws infrastructure and getting to experience what it was like to build something that we had only learned about conceptually i thought that was really gratifying so next question what did the mvp of echo look like and or how did you begin going about building it we used to joke about our we called it our bvp our baby viable product but um we started with a simple um websocket server and uh and a client i don't know if anyone else wants to add to that yeah it was pretty like it was just like our demo said like the very first first like proof of concept was pretty quick to set up because it was just a little express app with the soccer i o library um so that was something we were able to get up and running pretty quickly and then just having like just in in our actual application code we just added a few like fake middleware things to act on the messages so the proof concept happened pretty quickly and then we slowly began the trudge of like actually flushing out a real kind of production version of it all so this next question uh asks uh whether it was smooth sailing working with aws i guess i'll take that um probably related to my previous answer like it wasn't always smooth sailing there's a lot of kind of magic that goes on with deploying stuff particularly when you're using aws's cloud development kit um and uh i think people my other teammates will remember that was i think maybe a week or so where i just then kind of banging my head against the wall um trying to to get this particular configuration to be applied to our infrastructure and we could do it manually but we can do it with our deployment code so it definitely wasn't smooth sailing uh it's really nice when you know what you need to do and you know the specific little bit of snippet of code or the property that turns something on and off but until that point it often got frustrating just to add to that um the some of the parts were really easy working with the sdk but the really painful parts seemed to involve the permissions um in using different services that needed to work together another question was seeing the load testing results as gratifying as i imagined so the short answer to that question is yes it was um it was really cool the load testing was definitely one of my favorite parts of the project and what was really neat about it was that we had all spent weeks and weeks building this this tool but then when we started load testing it we were essentially using the tools so it was really impressive to see you know alex mentioned that one test where we set up 50 000 connections and started firing them all at the echo server which then was um hitting those lambdas that middleware and we wound up over the course of 100 seconds um hitting 50 or 500 000 lambdas and 500 000 messages and so it was just really cool to see how it actually worked and how impressive it was once we're all finished um on the question why did you choose the domain of real-time and more specifically real-time middleware any reason in particular or just because it seemed interesting so we first started looking at a web hooks project and that kind of follows that data push model that will was talking about where a server's automatically pushing data to another server and that sort of led us to this real-time space we we found this company pubnub that um you know offered these real-time services so we thought real time was would be a cool place to go and then we realized that there was already an existing capstone project a really cool project called river that had already built a real-time service and this was a drop-in service that developers could use to add real-time to their existing application and so we wanted to kind of take that a step further so river was to publish messages to many subscribers and we wanted our service to handle that mini pub sub model where you have many publishers and many subscribers and um when we dug a little deeper we found several problems within that space that were really interesting but we came across this real-time middleware and the use cases behind it were really cool and so we just decided to go in that direction with our project this next question relates to what features would you like to add to echo going forward with that like so we had um obviously we kind of uh had some trade-offs and things that we focused on during the project uh but things that we wanted to add include message persistence so allowing the messages to be stored somewhere so that if i don't know if someone has a dodgy internet connection that then echo can send them whatever messages they missed while they were offline uh we really wanted to add encryption um kind of end-to-end encryption for the messages and the echo server wouldn't need to be uh dealing with anyone's actual data and so it could be encrypted in transit um and we wanted to kind of handle in-order delivery of messages which at the moment we prioritize um getting the messages to the users or the clients really fast um and with these lambda functions you can imagine that at certain times if certain lambda functions take a while to compute perhaps or take a little bit longer than another you might get messages being delivered out of order this is actually a trade-off which all of the major players in the space papanov and abele um they all kind of hand off to the developer and they say this isn't really our problem you have to deal with this yourself um yeah it seems like a really juicy problem um that would be really nice to add one other question has anyone else used this open source software if so how many are they i can tell you that it's basically just being us since i think everyone here is basically the first people who've been using uh or hearing about uh echo and kind of finished the project relatively recently but it's it's ready for people to use and one final question unveiling of echo so if any of you guys watching want to use it feel free to and let us know how it goes so one final question how different would a task like researching planning building echo be if you hadn't attended capstone i that's a hard one to answer i feel like there was so much that i learned in capstone that prepared me for understanding the problem space and how to approach it um i think it would be it how different um yeah it would be very different because there was just a lot of knowledge that we had before even approaching it i think also so much of it is like there was no magic magic like red sphere formula that was bestowed upon us in capstone or anything but there was a lot of information that just helped us avoid pitfalls and then also there was a lot of great resources and people that kind of challenged our ideas and made sure that we were thinking about things critically and finding engineering challenges that would be kind of compelling for um for actual like working engineers and not just interesting fun ideas we had and so i think um it's like there isn't any single piece out there but just a lot of these things helped us avoid just spinning our wheels or going into weird rabbit holes that were just kind of fruitless endeavors and things so it's like just everything was 10 more directed and 10 smoother and 10 more kind of validated and i feel like that all adds up to a pretty big difference at the end of the day and with that i think we're out of questions so thank you very much uh all for for showing up um we know that capstone presentations can often feel a little bit out of reach when you're working your way through core but we hope you we've at least given you a taste for some of the things that you can build uh using echo some of those demo footage uh we'd love to hear if of course if anyone ends up building anything using echo and with that thank you all once again 