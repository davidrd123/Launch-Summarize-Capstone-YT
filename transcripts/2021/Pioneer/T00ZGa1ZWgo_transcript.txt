hi everybody welcome and thank you for joining us today my name is laura and myself along with my colleagues kyle the doo jimmy zheng and elizabeth tackett are the creators of pioneer and pioneer is a self-hosted feature flag management tool so let's take a look at the topics that we're going to be covering today and first we'll be looking into what kind of problems does pioneer solve and this is going to involve looking at the problems that are associated when a organization wants to add new features into their deployed application and then jimmy is going to take us through some of the solutions to those problems and he's going to introduce the concept of feature flags next elizabeth is going to introduce you to our application pioneer she's going to show you how a user can interact with our application and she's going to take you through pioneer's architecture then kyle is going to give an insight into some of the technical decisions and engineering challenges that we faced while building pioneer and finally i'm going to touch on some of the ideas that we have for future work of the project so before we get started we just want to clarify what we mean when we discuss adding new features in this presentation because adding new features is a really broad term it can refer to something as simple as just adding a navigation menu bar to a ui or it could be something as significant as making a fundamental change to the application's architecture and these are the kind of changes we want you to keep in mind throughout this presentation specifically when we refer to adding new features we are referring to an organization that has a monolith and they want to add the new features that are required to migrate to a microservices architecture and to get a better understanding of the challenges facing an organization that wishes to make such an architectural change we'd like to introduce you to our hypothetical company called harvest delivery harvest delivery is a mid-sized retailer that provides an online grocery shopping service and in the scenario harvest delivery has grown to a size which means they're starting to see a strain on their current monolithic architecture some of the strains that they're starting to see with their monoliths come from the fact that they have tightly coupled code and in this situation when a change is made to one part of the code base multiple other components also need to be updated this can slow development and it can lead to the creation of multiple bugs that are really difficult to track down also harvest delivery is seeing increased traffic and they would like the ability to horizontally scale some of their application components in an individual manner and this just isn't possible with a monolith finally harvest delivery is experiencing issues with availability with a current monolith any bug that causes one of the logical components to fail for example the form that's required to register new users will cause the entire application to be taken down offline extracting some of the application components into microservices can help keep such outages isolated and it means that only users attempting to use the affected microservice will be impacted so because of these challenges harvest delivery wishes to extract some of their logical components out of the monolith into into separate microservices let's say harvest delivery wants to add three microservices to their application which are called a shopping cart a payment processing and a live customer service chat function now this type of migration is commonly performed by by organizations and is referred to as the strangler fig pattern which is a team that was coined by martin fowler now making these kind of organizational changes aren't going to be straightforward it's actually going to be a lot of work for the development team and it's going to be made all the more challenging because there are some other requirements that they need to meet the most important of which is that they need to minimize the amount of downtime the amount of time sorry that the harvest delivery webpage is offline and this is because downtime can cause a loss in revenue and it can cause damage to the company's reputation also the development team doesn't want to roll out any of the new microservices to 100 of their users straight away they want to have the ability to roll out microservice to a specified subset of users say 10 of their user base then they want to see how that microservice performs in production before gradually rolling the microservice out to an increasing number of users finally harvest delivery is going to have three different teams developing each of the microservices that they're adding to their application so they want the ability to control the rollout of these three microservices in an independent manner so a challenge that all teams have to face when they're adding new features to an application is how to deploy the updated code and the problem is that the deployment process can be time-consuming and it can be error-prone and in the worst-case scenario an issue in deployment can cause application downtime and as we've discussed that's something that harvest delivery really wants to avoid now there are a wide variety of deployment approaches used by different companies but if we look at either end of the spectrum we can generalize one deployment approach as being slow but safe and in this deployment pipeline multiple integration tests are performed the advantage of this pipeline is that it minimizes the risk of any issues arising in production but the disadvantage is that it can be really slow performing this kind of deployment approach can take anything from a few minutes to a few hours and for development teams that deploy multiple times every day this type of approach can be a real bottleneck to development the other end of the spectrum is a quick but risky deployment approach and this pipeline can involve little or even no integration tests the advantage is this pipeline enables teams to work in a highly agile manner but the disadvantage is that it increases the likelihood that bugs will occur in production now both of these deployment approaches have disadvantages and it would be really beneficial if an organization had a way of managing the rollout of new features from within the deployed application itself this would mean that teams employing the slow but safe deployment approach could save time by minimizing the number of times their pipeline would need to be run and for teams using the quick but risky approach they would benefit from having the ability to switch off a feature that was causing a problem in the deployed application so now that we've looked at some of the challenges facing a team that's adding microservices to their application jimmy is going to discuss some of the potential solutions thank you laura so there are many deployment strategies for migrating from monoliths to microservices one reasonable fit for the harvest delivered use case is the canary deployment strategy and we will go more in depth in the next few slides canary deployment is where you have your original deployment which is monolith only and your new deployment model with the microservice run side by side simultaneously a low bouncer will allow you to configure the routing traffic from the public internet now initially 95 traffic is directed to the original deployment and 5 gets sent to the new deployment or the canary deployment and that's because you don't want all of your initial user base to be exposed to the canary deployment because you're not sure if there's going to be some bugs or issues with that deployment but as the engineering team gains confidence in the canary deployment because it's been running for a while without some significant issues they will start routing traffic more and more to the canary until receives 100 of all traffic let's examine how harvest might actually use this deployment strategy to extract out three microservices from their monolith so one option is to extract and deploy these microservices sequentially and we'll call these three microservices a b and c for convenience so initially the original deployment would be modeled with only and the canary deployment would be the partially extracted monolith and extracted microservice aid and 95 traffic gets directed to the original while five percent gets directed to the canary as time passes the engineering team gains confidence in the canary deployment and now monolith and microservice a will be the new original deployment for the application now they'll repeat this process sequentially to extract out microservice fee and also microservice c now we have an application with a partially migrating monolith and three extract microservices this deployment strategy however is not very agile for certain rollback cases if a microservice were to go down let's examine how the engineering team might respond to some of these situations when certain microservices have issues so let's say microservice c were to experience issues this will force the engineering team to roll back microservices in their deployment ideally they need a rollback version where it's just monolith and microservice a and b luckily they could just switch back to the previous version because that was already deployed previously so it's simple for that case however what if microservice a would or break in that case they would want to roll back to a version where it was monolith but only microservice b and c that version was never created because every previous version had a microservice a due to the sequential nature of the deployment so at this point they have two options they must either refactor the application code so that it only has microservice bmc and that takes time and engineering effort and they want a quick rollback so more likely if they do not have time to spin up that version they would have to roll back all the way to the original monolith and that's the only one that does not have the defective microservice a however there was nothing wrong with microservice b and c and now you're just excluding them from active deployment and you're missing out on valuable monitoring data so this approach clearly lacks granularity and control for individually managing the active states of the microservices because they're all coupled together to the sequential nature of the deployment so a nice solution to this would be to have every combination of microservice a b and c created beforehand so that let's say microservice a were now to go down this case so microservice a were to go down in this case the engineering team could simply redirect to a pre-deployed version of monolith plus microservice vc as shown here so this approach does cover granularity of control but this would clearly be very inefficient to account for every combination especially as more microservices are extracted and to give further perspective with four microservices it will require a total of 15 deployments to account for every combination so we can see there are many downsides to using this deployment approach for harvest while it does have percentage rollout one immediate downside is the complexity coming from introducing additional infrastructure to your existing application like the load balancer and all the extra deployment environments in addition the first option which was a sequential deployment that did not allow for granular control section option was to pre-deploy all combination of microservices to allow for granular control but that easily becomes infeasible to address these issues there should be a strategy in which the application code is engineered to handle the microservice switch rather than the load balancer now we introduce the concept of feature flags as an alternative solution to canary deployment this design pattern solves the previously mentioned problems because first of all it allows you to toggle independently and toggle states of multiple flags allowing for granular control and each flag can be thought of representing the active state of one microservice so flag a could represent active state microservice a and this toppling can be done without deployment downtime which will be later explained in addition this deployment strategy of feature flags minimizes interference with its existing infrastructure because as we've seen canary deployment is a solution at the infrastructure level feature flags is a solution at the application code level it only requires embedding an sdk into the existing code base without the need for an extra environment or load balancer finally it still has the benefits of percentage rollout and this can be adjusted through a ui rather than being configured through a load balancer so to give a quick high-level overview of how it works pretend you have your monolith and your microservice extracted from that monolith initially a request comes in from the internet the app will handle that request and it will handle it by referencing an sdk this sdk will check for whether or not a flag is toggled on and this flag would represent the active state of microservice a so let's say the flag is toggled on the app referencing the sdk will now route the request to microservice a if the flag is toggled off it will execute internal monolith code as represented by service a to further emphasize the efficiency and convenience of future flags let's go back to the example where microservice a went down now on the left the engineer only needs to toggle off the flag corresponding to microservice a and let's say microservice a went down so the engineer only needs to toggle it off sdk will be notified of the change so that future requests instead of going to microservice a will now route to service a the internal monolith code instead and especially important to note that this will not affect the activity of other microservices to go more in depth as to what a feature of flag is it can be thought of as a key and a boolean value like a key value pair in the dictionary data structure they are used in the code base as an if statement where there are two possible choices and the boolean value of the flag determines the flow control so as you can see the get feature method is passed in a key name which is can which can be thought of as the active state of microservice a and if that returns true we execute the new feature which would be routing the request to microservice a else we execute the original code which can be thought of as the internal monolith's code now let's talk about the options that company has if they wanted to adopt this workflow they first have the option of creating and maintaining their own feature flag rule set this carries the obvious overhead costs of the time and engineering manpower required to test and build a solution from scratch another option is to use third-party solutions proprietary software include launch darkling cloudbees open source software include feature hub and unleash let's examine these two sets of options in more depth and compare them with our solution for a small and medium-sized company like harvest it's especially important to consider accessibility or ease of setting up because harvest has a small engineering team and also affordability because they are on a tight budget enterprise solutions such as launch darkly are closed source command of monetary costs the company using them typically these solutions provide far more features and require far more configuration and company required for the purpose of introducing new microservices so that's launched darkly and solutions such as feature hub while open source and thus flexible still offer a more complex set of features this complexity requires additional time and effort to configure appropriately furthermore the complex code base may be more difficult to modify for harvest custom needs all these considerations led us to develop pioneer which fits the use case of harvest the best elizabeth will now present a more in-depth look on pioneer thanks jimmy so now i'm going to discuss the details of our feature flag management tool pioneer first i'm going to introduce pioneer and we'll take a look at pioneer system architecture next we're going to go a bit deeper and dive into each element of pioneer's architecture to discuss the role that each component plays finally we'll briefly discuss out-of-the-box usage of pioneer afterwards kyle's going to take over and dive a bit deeper into the engineering decisions that we were challenged with when building pioneer pioneer is a self-hosted open source feature flag management tool it's specifically intended for small to medium sized organizations are looking to transition from a monolith to a microservices architecture pioneer enables users to roll out individual microservices to a specified subset of users without the need for extensive configuration or additional infrastructure such as a load balancer you've heard us mention several times already that pioneer is a self-hosted application let's briefly touch on the benefits that this affords pioneers users firstly it means that the user can deploy pioneer on their infrastructure of choice whether that's on their own aws vpc a digital ocean droplet or their own on-prem server distributing pioneer as an open source and self-hosted application also means that users of pioneer can fully adapt the application to their own unique needs increasing flexibility if the out-of-the-box configuration isn't a match for a user's requirements they have the freedom to change whatever isn't working for them or to add whatever components might suit them better for example if necessary users can spin up additional instances of scout or add a cache we're now going to go over pioneers architecture from a high level pioneer is composed of multiple components called compass not jet stream and scout all of these components are run in a docker network i'd like to point out here in this diagram that knots is a third-party tool compass is a react application built by the pioneer team and it serves as the dashboard for flag management scout is a node.js application also built by the pioneer team and it serves as the distributor of flag data pioneer communicates with a user's application via a pioneer sdk which is embedded within the user applications code base let's now take a look at each of the components in the role that they play compass is pioneer's primary application for managing feature flags the front end of the application provides a user interface that allows users to view create update and delete feature flags each flag has a title an optional description an assigned rollout percentage and may be toggled on or off with a single click changes made to a flag will be published to knots and received by scout once the updated flag data is pushed out to connected sdk clients by scout the application's behavior will change to reflect the update no redeployment is necessary all that's needed to turn a new service on or off or update its current rollout percentage happens right here on the compass dashboard you may recall that when jimmy spoke about using canary deployments as an alternate strategy to roll out new features a load balancer was required in order to direct the appropriate percentage of users to a new feature when using pioneer to introduce new features or services there's no load balancer required the feature flag's current rollout percentage is set as an attribute of the flag and is transmitted to connected sdk clients along with all other flag data the sdk code includes the necessary logic to serve a particular feature to the percentage of users specified for that flag users may also use the compass dashboard to view event logs regarding the flag's history all updates made to a flag are preserved here for future reference under the account tab of the compass dashboard users can view and manage the valid sdk key needed to connect sdks as clients of scout users can also choose to invalidate the current sdk key and generate a new one next we're going to discuss the role that nat's jet stream plays in transmitting feature flag data from compass to scout but first what is it nat's jet stream is a third party open source message streaming service now it's is lightweight and easy to get started with pioneer utilizes a not stepstream server to facilitate communication between the compass and scout servers due to its ability to provide asynchronous fault tolerant messaging with guaranteed delivery and kyle's going to talk a little bit more about why we chose nat specifically in a moment mats offers a few different messaging patterns the pattern used for pioneer is a publish subscribe messaging pattern when communicating via a published subscribe pattern the subscriber acknowledges receipt of a message but it's not expected to reply and this is a perfect fit for our use case in which compass publishes updated feature flag data to nats and that stores the most recently published data in memory until the subscriber scout acknowledges receipt of the data scout is a daemon that the pioneer team built to act as the interface between compass and the sdk embedded in a client's application you can think of scout as being the distributor of flag data a persistent http connection is formed between scout and sdk clients it is through this http connection that scout sends feature flag data as a server sent event also called sse pioneer currently offers server-side sdks in three languages nodejs ruby and golang the user should install the appropriate sdk in their application code and after doing so the sdk can request to connect to scout as an sse client by providing scout's server address and a valid sdk key the sdk will then automatically receive feature flag updates each time a change is made via the compass dashboard the sdk stores the current feature flag data in memory and uses it to evaluate flags all three of our sdks also integrate with google analytics to aid users in collecting analytics events related to their new features and we're going to discuss now how to get started quickly with pioneer out of the box uh first uh pioneer should be cloned from the github repository and then the user should navigate into the pioneer directory next the user should run docker compose up now all components of pioneer's architecture will be running kyle will discuss the logic behind why we chose to use docker in the next portion of the presentation as discussed previously once a user has pioneer up and running they can create and modify feature flags using the compass dashboard each time a change is made via compass the updated flag data is transmitted from pioneer to the user application compass first publishes the updated flag data to nats and scout which serves as a subscriber to nuts will then receive and acknowledge the message and distribute the updated flag data to sdk clients via sse you can see that changes made on the compass dashboard are enough to influence your deployed applications behavior in real time granular control over the rollout of new microservices is just a click away allowing engineering teams to avoid the lengthy and error-prone process of redeployment when changes need to be made note that in order to evaluate feature flags in a user's code the user will need to install the appropriate sdk in their code base this can be done with a single command and on this slide we see examples of the sdk installation command for each of our three sdks within a user's application the feature flags are evaluated within a conditional statement in order to determine the flow of code execution remember feature flags are evaluated at the code level there is no need for a load balance or balancer or an additional deployed environment when using feature flags let's harken back to our harvest delivery hypothetical one of the logical components that harvest delivery plans to extract out into a microservice is their payment processor here in the code example on this slide we see what a conditional statement evaluating the payment processor flag might look like in harvest delivery's code base the payment processor flag could be toggled on toggled off or have its rollout percentage updated all without any changes being made to this code there is no redeployment or additional engineering work necessary in order to see the change reflected in the behavior of the application because feature flags are controlled in such a granular manner any changes made to the status of the payment processor flag will not impact any other feature flags such as a flag for an inventory catalog for example it's really as simple as that and now i'm going to pass things over to kyle and he will be discussing the engineering decisions and technical challenges that we dealt with while building pioneer thanks liz while building pioneer there were several key design decisions that we made which involve careful consideration of their benefits and trade-offs i'll go over those decisions now the largest implementation decisions we'll take a look at had to do with the following questions first how to communicate feature flight data from pioneer to users applications next whether to use direct communication between application components or a message broker also how to effectively design server-side sdks that can implement gradual feature releases additionally how to format feature flag data for transmission and lastly how to best ensure cross-platform performance and flexibility when designing pioneer we thought about how to communicate future flag data between scout and connect connected sdks in users applications we considered several options for how to best do this first we considered web sockets but we found that they were not the best fit websockets provide a persistent connection between a client and server however they're intended for bi-directional communication in our case we only needed to communicate flag updates in a uni-directional manner from scout to connected sdks polling was another option we considered this involves periodically sending an http request to a server to check for new data however this approach would not provide the user application with updated flag data in real time and would result in unnecessary network traffic next we thought about web hooks which are event driven unlike pola you can think of web hooks as being automated messages that are sent when something happens however using web hooks to provide updates to the user application would require that the user's application server expose an additional endpoint for http requests to be sent to we were looking for a solution that would send updates in an event-driven manner without interfering with the user's application we settled on using server sent events to provide flag data updates to the sdk sse connections are persistent http connections over which the server can send data the server sent events model of communication means that when something happens on the server updates will automatically be sent to all connected sse clients ssc allows for near real-time unidirectional communication from scout to connected sdks one additional consideration we had to make after deciding to work with sse connections between scout and the sdks was that of secured how tightly did we want to lock down the ability to open an sse connection with scout to request and receive the organization's feature flag data on one hand we could leave the connections totally open any sdk could connect to scout provided they had the correct endpoint to send a request to this would make the integration of sdks into the user's application quite easy the only sdk configuration needed would be to embed scout's address then the application would be able to request and receive rule sets anytime it was fired up however this would mean loosening security protocols on scout to make the flag data more accessible with no extra steps for authorization a malicious party could open an sse connection with scout then just like any legitimate sdk they could also start receiving flag data on the other hand we could add additional security to scout to lock down ssc connections more tightly if we added a form of authorization the connecting sdk would have to provide a valid key of some kind to be cleared prior to obtaining any flag data this would provide an additional layer of security between an incoming connection to scout and the organization's flag data however this would mean additional configuration for the user as they would then have to integrate and manage the keys for authorization it would also mean additional complexity for pioneer having to generate manage and validate these keys ultimately we chose to authorize all sdks requesting to connect to scout as an sse client this authorization will prevent malicious agents from gaining access to feature flag data sdk clients initiate an sse connection with scout by sending an http request to scouts forward slash features endpoint before serving feature flag data provided by compass scout will verify that the sdk attempting to connect has provided a valid sdk key in the authorization header of the request if the sdk key is deemed valid scout will open the sse connection it will then request the full rule set from compass through nats and once received transmit feature flag data back to the sdk subsequent updates will then be sent to the authorized sdks via the sse connection in the end we decided that the additional complexity of managing sdk key generation and validation was well worth the extra layer of security for the end user's data with the line of communication in place that would transmit changes to flag data in near real time from compass down to the sdks embedded in the user's application we could then focus on how we could build the server-side sdks to make them as easy to integrate and intuitive to use as possible while giving them the capabilities necessary for our use case namely the ability to implement percentage based rollouts as we've previously discussed solutions such as canary deployment are at the infrastructure level and use a load balancer to determine the percentage of users receiving the new feature whereas feature flags function at the application level with pioneer the logic of the percentage roll app strategy is handled by the sdk in the user's application code to determine if an individual user such as a harvest delivery customer should receive the feature flag rule the pioneer sdk requires some context about the user this context is simply a unique identifier assigned to an application user in our hypothetical you can think of this user as one of harvest delivery's customers logging into their service to do some shopping and their context might be their customer id to make use of the client context and the percentage rollout of the flag the sdk client must be passed to this context using a built-in method this will signal that all flags should be evaluated using the provided user's context when the feature flag is evaluated the user context is then passed into a hashing algorithm we created which will determine whether the specific user context falls within the associated rollout percentage for that flag if the context falls within the percentage the flag will evaluate to true and presumably the client will be routed to the microservice otherwise it will evaluate to false and they will be routed to the monolith service while the inclusion of this strategy does add complexity to the integration of the sdk we felt that the added complexity was minimal and the ability to route percentages of users to a microservice was a worthwhile trade-off now after deciding how to transmit updated flag data we needed to decide what the format of these messages should be having settled on sending the rule sets as json objects we wondered whether sending the whole rule set would provide any advantages over sending only updated sections of the rule set we decided that pioneer should publish the entire flag data rule set each time an update to a flag has been made we also considered sending only the data related to the flag that was updated in order to reduce the size of the data being transmitted but this came with its own considerations the biggest drawback of transmitting flag updates in a piecemeal manner is that an sdk could miss a flag data update from scout due to net network issues impacting the ssc connection this would result in an sdk evaluating flags using outdated feature flag data and the discrepancy would persist until the next change was made to that particular flag in order to ensure that all sdks have the most up-to-date flag data at all times we decided to transmit the whole rules and because pioneer is intended for small to mid-sized organizations we reason that the size of data being transmitted was acceptable for example a rule set with 100 distinct flags has a size of only about 20 kilobytes which should be manageable for modern networks lastly let's go over how we answered the question of how to best ensure cross-platform performance and flexibility as we noted previously when discussing pioneers architecture the main components gnats scout and compass are each in their own docker container together they run in a docker network we chose to dockerize pioneer because containerization falls in line with the flexibility and control provided to users by offering pioneer as a self-hosted service regardless of where users deploy pioneer the behavior of the application will remain consistent across different platforms without the need for additional configuration so now that we have an understanding of what decisions were involved in making pioneer what it is today we can think about how we can continue evolving pioneers as we move forward laura will now bring us through a few ideas the team has about how we might do so thank you kyle so currently with pioneer a single instance of pioneer can only support a single application so in the future pioneer could be expanded to support multiple applications by allowing for multiple distinct rule sets additionally currently the rollout strategy offered by pioneer is just a simple percentage rollout additional roll-out strategies that may be developed in the future could identify users internal to the organization a predetermined group of beta testers or as a particular segment of the market and this would allow for more tailored feedback on the performance of an added microservice the last item for future development is flag exploration the pioneer is meant to be used for a transition to adding a new microservice the conditional logic related to a feature flag should not live in the user's applications code base indefinitely allowing developers to set an expiration date on a feature flag would assist in defining a clear testing or rollout window for a for adding this new feature or microservice so this is our team thank you so much for joining us today if you'd like to get any more information on our project you can visit our case study for a detailed write-up or visit our github repository and we'd now like to open up the floor to any questions okay we have a first question from brandon does pioneer handle updating a microservice if so how would that work i can take that one so um the idea behind pioneer is that you have to actually have the update already deployed to your code so you have to have the two switches the if else statement already embedded in the code and the pioneer allows you to toggle between those two states but if you have to update them microservice in and of itself you still have to redeploy it okay so next question mark asks what were the challenges you faced with setting up container to container communication uh yeah i can answer that one and so there is a fair amount of configuration involved when you're running things within a docker network it's actually not too bad one of the decisions that we made um was to take was to extract some of the variables into a dot env file and this meant it would provide just a single place where if somebody was modifying the application to their own need for their own use they could just modify the env file rather than having to go through the application and like all different parts of of pioneer components and finding all the places that they had to kind of change those docker configurations so it actually wasn't too much of a challenge in the end it's just kind of normal things that were associated with working with docker next question how did you end up choosing future flags as your project topic um if nobody else wants to jump in we actually discussed like quite a few different ideas and i think we ended up like each of us coming up with a different idea for a project topic and feature flags just sounded like a really fun interesting thing to to work on and there hadn't really been any other capstone projects in the space previously and so we thought it would be like a really interesting space to start working in okay lena says amazing project pioneer team and what was your favorite challenge working through this project i guess that's that can be a question for everyone i don't know if the rest of my team are having issues with audio i guess i'll go first um yeah there were loads of challenges working with this project to be honest i don't think that there was like one individual component that was like really straightforward each component had like a different challenge associated with it and also we're a very distributed team um like between myself and kyle there's like a six hour time difference and so that definitely introduced some like novel challenges that it was really great to get experience with working in such a distributed team yeah personally um i worked on the sdk part so it was an interesting challenge um trying to get the percentage rollouts working as i was dealing with a really nested set of modules these modules all had to talk with each other in order to get the parts of the sdk working together that was a fun challenge and uh i'll go ahead and echo laura's uh answer here i think that one of the biggest challenges um in the project itself was was kind of like the work around it and learning to work as a team functioning asynchronously across you know four different time zones um you know which brought its own challenges okay next question mark asks would there be problems if you had a proxy like nginx for that communication um not sure mark if you want to follow up the clarification um yeah he's asking about uh communication containers container to container communication that was his previous question so what were the challenges you faced with setting up container to gain container communication and then the follow-up question is would there be problems if you had a proxy like nginx for that communication um well we envisaged that all of the the docker net docker containers running in a docker network would actually be running like on the same server so we don't and kind of envisage that situation where you would have a proxy in between those kind of microservices to communicate with one another and if you did do that it would involve more configuration than we have out of the box it um like it is something that's possible but it's not something that we've kind of accommodated for in the development of pioneer okay graham asks does the compass ui handle collaboration for example if i'm working with my team and i host my docker containers publicly does it provide any form of authentication to prevent anyone with the address from accessing the ui no it doesn't simply um i mean because you're supposed to be like self-hosted and the idea is that only people who can access who have the access to that to that address and can access the ui like that's kind of the only security we've got in terms of the ui collaboration really okay really great job guys and i'm sure you covered this but i missed where does the code that determines which service traffic gets sent to live in other words where in a pioneer user's architecture does the five percent of traffic get routed one way and the 95 percent gets routed the other way uh i could answer that so the pioneer user has a back-end architecture and they might run on a framework like express so if you use express or if you just created a simple back-end you have these routes like app.get or app dot post and that's where the app handles the requests from the internet so that's where the user for pioneer the pioneer user embeds an sdk in there and that's where you put your if else statement and that's where the traffic gets routed one way or the next hopefully that answers your question and once again great job on the project i'm curious to know how you divided up the project tasks did each one of you have separate areas of the code based control and or did you work in collaboration across the code base so i think the short answer is we all can worked on everything when we were first starting the project i think we all initially took a chunk um and we did our code spikes tested things out and then once we were ready to move on and start prototyping and connecting all the all of the dots we all kind of worked on the pieces and stages um together so that we could all become more familiar with the operation and how everything was functioning yeah i would also like to mention that uh the pairwise coding i think kyle and i did a lot of pairwise coding i felt like i got a boost of productivity from that so that was also a pretty helpful um collaboration strategy in our team yeah i'll let go that jimmy and i did a lot of pair coding and we did some like even larger group sessions where all four of us would come in if there was like one really core piece um you know for like how scout was functioning as that's you know the distributor of all the of the flag data we would all kind of get together and just work through a couple of the core pieces if if there were any issues with it and that proved pretty helpful and getting stuff done but also i think helping us all understand how everything was working and fitting together okay awesome so it seems like there are no more questions so any final words thank you very much for everybody who joined us today we appreciate it thank you all for joining uh your questions and feedback are great and um apologies for any technical difficulties thanks for bearing with us yeah something was about to go wrong but yeah thanks for your patience and thanks for your attention we really appreciate it excellent work you 